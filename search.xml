<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据结构与算法之排序]]></title>
    <url>%2F2019%2F03%2F01%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[排序就是按照某种逻辑顺序将一组对象重新排列的过程，这篇博客就对常见的排序算法进行总结，包括：冒泡排序、选择排序、插入排序、希尔排序、归并排序、快速排序、堆排序。 冒泡排序冒泡排序通过比较相邻的元素大小来完成排序。这里定义比较边界，也就是进行大小比较的边界。对于长度为n的数组，第一趟的比较边界为[0,n-1]，也就是说从a[0]开始，相邻元素两两比较大小，如果满足条件就进行交换，否则继续比较，一直到最后一个比较的元素为a[n-1]为止，此时第一趟排序完成；每一次排序完后最大元素沉入底部，比较边界变成[0,n-2]。对于长度为n的序列，最多需要n趟完成排序，所以冒泡排序就由两层循环构成，最外层循环用于控制排序的趟数，最内层循环用于比较相邻数字的大小并在本趟排序完成时更新比较边界。 在排序后期可能数组已经有序了而算法却还在一趟趟的比较数组元素大小，可以引入一个标记，如果在一趟排序中，数组元素没有发生过交换说明数组已经有序，跳出循环即可。 冒泡排序的时间复杂度为O(n^2),辅助空间为O(1),属于原地排序。 选择排序基本思想很简单：首先找到数组中最小的那个元素，然后和数组中第一个元素交换位置；然后在剩下的元素中找到最小的元素，将它与数组的第二个元素交换位置；如重复直到整个数组排序好。 对于长度为N的数组，选择排序需要大约N^2/2次比较和N次交换，辅助空间也是O(1),属于原地排序。 插入排序插入排序将数组分为有序部分和无序部分，与选择排序一样索引左边的都是有序的，为了给更小的元素腾出空间，他们都可能会被移动，当索引到达数组右端的时候，数组就排序完成了。 插入排序对一个很大且其中元素已经有序（或接近有序）的数组进行排序会比对随机顺序的数组或是逆序数组进行排序要快得多。 插入排序平均需要~N^2/4次比较和~N^2/4次交换，最坏情况下需要~N^2/2次比较和~N^2/2次交换，最好情况下需要N-1次比较和0次交换。 希尔排序对于大规模乱序数组，插入排序很慢，因为它只会交换相邻的元素，因此元素需要一点一点地从一端移动到另一端。希尔排序改进了插入排序，交换不相邻的元素以对数组局部进行排序，并最终用插入排序将局部有序数组排序。 本质上来说，希尔排序就是把数列进行分组(不停使用插入排序)，直至从宏观上看起来有序，最后插入排序起来就容易了(无须多次移位或交换）。下图为来自网上的一个图解例子： 希尔排序适合于中等大小的数组且不需要额外的内存空间，因为采取了分治策略，平均时间复杂度为O(NlgN)。 归并排序归并排序将两个有序的数组归并成一个更大的有序数组，所以在排序的时候将一个数组地跪地分成两半进行分别排序，然后将结果归并起来。归并排序由两个过程完成：有序表的合并和排序的递归实现。 将待排序序列分为A和B两部分，如果A和B都是有序的，只需要调用有序序列的合并算法mergeArray就完成了排序，可是A和B不是有序的，再分别将A和B一分为二，直至最终的序列只有一个元素，我们认为只有一个元素的序列是有序的，合并这些序列，就得到了新的有序序列，然后返回给上层调用者，上上层调用这再合并这些序列，得到更长的有序序列，这就是递归形式的归并排序，示意图如下图所示： 快速排序快速排序是冒泡排序的改进版，也是最好的一种内排序。快速排序也是一种分治的排序算法，它将一个数组分成两个子数组，将两部分独立地进行排序。与归并排序不同的是：归并排序将数组分成两个数组进行排序后归并成一个有序数组；快速排序则是当两个子数组都有序之后整个数组也就有序了。其主要步骤以下面一个例子为例： 设置两个变量i、j，排序开始的时候：i=0，j=n-1； 第一个数组值作为比较值，首先保存到temp中，即temp=A[0]； 然后j– ,向前搜索,找到小于temp后,因为s[i]的值保存在temp中,所以直接赋值,s[i]=s[j] 然后i++,向后搜索,找到大于temp后,因为s[j]的值保存在第2步的s[i]中,所以直接赋值,s[j]=s[i],然后j–,避免死循环 重复第3、4步，直到i=j,最后将temp值返回s[i]中 然后采用“二分”的思想,以i为分界线,拆分成两个数组 s[0,i-1]、s[i+1,n-1]又开始排序 快速排序空间复杂度为O(NlgN)。 堆排序堆排序基于优先队列数据结构，高效地实现删除最大元素和元素插入操作。 堆的定义当一棵二叉树的没个节点都大于其子节点的时候，称之为堆有序，其根节点即是最大节点。具体实现就是将二叉树的节点按照层级顺序放入数组，根节点在1，它的子节点在2,3，而子节点的子节点在4,5,6,7，以此类推。 堆的上浮和下沉操作都可以使得堆有序化。 堆排序堆排序主要为两个阶段：构造一个堆有序的数组使得最大元素位于开头，构建堆的目的就是使以每个节点作为根节点的树都满足堆的定义，因此从堆（完全二叉树）的最下侧非叶子节点开始构建初始堆，根据堆的性质，这个节点的索引是⌊n/2⌋。从下向上，一直到堆顶节点也满足堆的定义，表示完成堆的初始化；堆的下沉排序，将堆中最大元素删除，然后放入堆缩小后数组中空出的位置。 堆排序是现有的唯一同时最优利用时间和空间的排序算法，在最坏的情况下也能保证~2NlgN次比较和恒定的额外空间。 各排序算法比较 参考《算法（第4版》 https://www.cnblogs.com/lifexy/p/7597276.html https://www.cnblogs.com/lz3018/p/5742255.html https://www.cnblogs.com/beli/p/6297741.html]]></content>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法之查找]]></title>
    <url>%2F2019%2F02%2F26%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E4%B9%8B%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[查找是针对符号表（有时也称之为字典或者索引）存储的键(key)值(value)信息，按照指定的键来查找信息，在这里就对常见的查找算法以及实现高效查找的符号表数据结构进行介绍。 顺序查找顺序查找是在无序队列中找出与关键字相同的数的具体位置，原理是让关键字与队列中的数逐个比较，知道找出与给定关键字相同的数为止。 二分查找二分查找针对的是有序的符号表，如果是无序的首先就要进行排序操作。其基本思想很简单，首先将key和中间键比较，如果相等则返回其索引；如果小于中间键则在左半部分同样取中间键进行比较；大于则在右半部分取中间键进行比较。 **在N个键的有序符号表中进行二分查找最多需要（logN+1）次比较），算法复杂度为O(logN).** 分块查找分块查找是二分查找和顺序查找的一种改进，分块查找要求索引表是有序的，对于块内节点没有排序要求（块内无序，块间有序），因此特别适合节点动态变换的情况。这种带索引表的分块有序表查找性能取决于两步查找时间之和：第一步可以采用简单书序查找或者是二分查找查找索引表；第二部对于块之内只能顺序查找。 假设索引表有n个元素，每块含有s个元素，平均查找长度为(n/s+s)/2+1,时间复杂度为O(n)~O(lgn). 二叉查找树二叉查找树（Binary Search Tree）每个节点都含有一个可比较大小的键，每个节点都含有两个链接（有点类似于链表的扩展），基本定义为： class Node{ Key key; // 键 Value val; // 值 Node left,right; // 指向子树的链接 int N; // 以该节点为根的子数节点总数 } 具有的一条最重要的性质为：每个节点的键都大于左子树的任意节点键值，并且小于右子树任意节点键值。 查找 在二叉查找树中查找，可以采用递归的方法：如果树是空的，则查找未命中；如果被查找键和根节点的键相等，则查找命中；否则就递归地再适当的子树中查找，如果被查找的键较小就选择左子树，较大就选择右子树。 插入插入操作和查找类似：如果树是空的，就返回含有该键值对的新节点；如果被查找的键小于根节点的键，就继续在左子树插入该键，否则在右子树插入该键。 删除从二叉树中删除一个元素如图3.2.13，总结来说，就是在被删除元素的右子树中不断检索左子树，作为后继节点替换被删除元素，从而达到删除对应元素的目的。 性能分析二叉查找树实现良好的性能依赖于其中键的分布足够随机以能够消除长路径。最坏的情况下，N个节点都存在于一个查找路径上，查找增长数量级为N，平均查找2lnN=1.39lgN. 平衡查找树平衡查找树含有N个节点，且能保持树高为~lgN,这样就能保证所有查找在lgN次内比较结束。 2-3查找树一棵2-3查找树由以下节点组成： 2-节点，含有一个键和两个链接，左链接的子树小于该节点，有链接的子树大于该节点。 3-节点，含有两个个键和三个链接，除左右链接外，还有一个中链接，指向键都位于两个键之间的树。 因为包括3节点，所以可以保持平衡性，即任意一条路径长度都相同，在这种情况下，插入算法都是局部变换，除了相关的节点和链接之外，不必修改其他节点。在一棵大小为N的2-3树种，查找和插入操作访问的节点不超过lgN个。 红黑二叉查找树红黑二叉查找树的思想是用标准的二叉查找树（完全由2-节点构成）和一些额外的信息（替换3-节点）。树种包括两种链接：红链接将两个2-节点链接构成一个3-节点，黑链接即是2-3树中的普通链接。 红黑树是满足下列条件的二叉查找树“ 红链接均为左链接； 没有任何节点同时和两条红链接相接； 树是完美黑色平衡的，任意空链接到根节点的路径上的黑链接数量相同。 某些插入操作之后可能出现右红链接或者两条连续的红链接，这时候就需要进行旋转，以保证红黑树的有序性和完美平衡性。 如果左右节点均为红色，需要进行颜色转换： 一个完整的红黑树构造轨迹如图3.3.24： 散列表散列表（也称之为哈希表）将键作为数组索引，从而可以快速访问任意键的值。散列表的算法主要分为两步：用散列函数（哈希函数）将键转化为数组的索引；针对多个键散列到同一个索引值的情况，处理碰撞冲突。直接定址与解决冲突是哈希表的两大特点，其思想很简单，如果所有的键都是整数，那么就可以使用一个简单的无序数组来实现：将键作为索引，值即为其对应的值，这样就可以快速访问任意键的值。散列表是一个在时间和空间上做出权衡的经典例子。如果没有内存限制，那么可以直接将键作为数组的索引。那么所有的查找时间复杂度为O(1)；如果没有时间限制，那么我们可以使用无序数组并进行顺序查找，这样只需要很少的内存。哈希表使用了适度的时间和空间来在这两个极端之间找到了平衡。只需要调整散列函数函数算法即可在时间和空间上做出取舍。 基于拉链法的散列表基于拉链法的散列表采用链表的数据结构，数组中元素为链表，将散列值相同的键值保存在一个链表中。 基于线性探测法的散列表这种方法会用一个比较大一点的并行数组来保存键值对，一个保存键，一个保存值，解决碰撞的策略也是极其简单粗暴：当碰撞发生时（一个散列表的值已经被另一个不同的键占用），直接检查散列表的下一位置（索引值加1），不同则继续查找（到数组结尾时折回开头），直到找到该键或者遇到一个空元素，这时保存值。 Hash（key） = key % 10（表长）；89放入9的位置；18放入8的位置；49与89冲突，往后加到尾了就再回到头，0的位置为空放入；58与18冲突，往后加有89，再加有49，再加就放入1的位置；9与89冲突一直加到2的位置放入。Hash（key） + 0，Hash（key）+1，…… 参考《算法（第4版》，本篇博客大部分图的出于此书。 https://blog.csdn.net/sayhello_world/article/details/77200009 https://blog.csdn.net/simplehap/article/details/70577454]]></content>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构之链表]]></title>
    <url>%2F2019%2F02%2F21%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B9%8B%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[定义链表由一系列的不必在内存中连续的结构组成，每一个结构包括节点（数据域）和指向该节点之后节点的指针（指针域）构成。 struct Node{ int value; Node *next; } 上面即是一种典型的单向链表，还有一种双向链表，除了数据域之外，还包括分别指向上一个节点和下一个节点的指针；如果让链表最后一个节点指向第一个节点，就构成了循环链表。 一些例子 插入节点在p之后插入值为i的节点 void insert(Node *p, int i){ Node* node = new Node; node-&gt;value = i; node-&gt;next = p-&gt;next; p-&gt;next = node; } 删除节点删除某个节点p时，只需要用p后一个节点覆盖p当前节点： void delete(NOde *p){ p-&gt;value = p-&gt;next-&gt;value; p-&gt;next = p-&gt;next-&gt;next; } 找出倒数第k个节点采用两个指针p1,p2，p1先走k步，然后p1和p2一起走，当p1到达节点终点时，p2即指向倒数第k个节点。 Node* findk(Node* head, int k){ Node *p1 = head; Node *p2 = head; for(int i=0;i&lt;k;i++){ if(p1==NULL) return NULL; p1=p1-&gt;next; } while(p1-&gt;next !=NULL &amp;&amp; p2-&gt;next != NULL){ p1=p1-&gt;next; p2=p2-&gt;next; } return p2; } 同样的道理，如果要找出链表的中间节点，可以令p1和p2分别以前进2步、前进1步的速度遍历，当p1到达节点终点时，p2即指向终点节点。 判断是否有环直观的判断是，存在环路的时候，一直遍历都不会遇到NULL节点，但是由于不知道链表的长度吗，所以采用这种判断不知道多久才能终止。转化成一个追及问题，如果有环，那么两个遍历速度不一致的指针一定会相遇，采用类似上面，有两个指针pslow，pfast,pslow每次走一步，pfast每次走两步，若是有环，pfast就能追上pslow，否则pfast会碰到NULL。 bool isLoop(Node* head){ if(head==NULL) return false; Node* pfast = head; Node* pslow = head; while(pfast!=NULL){ if(pfast-&gt;next==NULL) return false; pslow = pslow-&gt;next; pfast = pfast-&gt;next-&gt;next; if(pfast==pslow) return true; } return false; } 反向遍历可以采用先将链表存在栈中，然后先进后出即为反向遍历： void reverse(Node* head){ stack&lt;Node*&gt; nodestack; Node* p = head; while(p!=NULL){ nodestack.push(p); p=p-&gt;next; } while(!nodestack.empty()){ cout&lt;&lt;nodestack.top().value&lt;&lt;endl; nodestack.pop(); } } 或者是采用递归的方法： void reverse(Node* head){ if(head!=NULL){ if(head-&gt;next!=NULL){ reverse(head-&gt;next); } cout&lt;&lt;head-&gt;value&lt;&lt;endl; } } 链表反转采用就地反转法，有一篇博客讲的很清楚https://www.cnblogs.com/byrhuangqiang/p/4311336.html，这里就转载一下人家的方法，主要思路就是把当前链表的下一个节点PCur插入到头结点dummy的下一个节点中，就地反转。dummy-&gt;1-&gt;2-&gt;3-&gt;4-&gt;5的就地反转过程：dummy-&gt;2-&gt;1-&gt;3-&gt;4-&gt;5dummy-&gt;3-&gt;2-&gt;1-&gt;4-&gt;5dummy-&gt;4&gt;-3-&gt;2-&gt;1-&gt;5dummy-&gt;5-&gt;4-&gt;3-&gt;2-&gt;1 初始状态为： pCur指向每一次需要反转的节点，将prev对应的节点连接到下一个需要反转的节点，将pCur连接的当前需要反转的节点作为插入到dummy之后，即移到了头部，调整pCur指向下一个需要反转的节点，这样循环直到下一个需要反转的节点为NULL，其动态过程如下图： Node* reverseList(Node* head){ if(head==NULL) return head; Node* dummy = new Node; dummy-&gt;next = head; Node* prev = dummy-&gt;next; Node* pCur = prev-&gt;next; while(pCur!=NULL){ prev-&gt;next = pCur-&gt;next; pCur-&gt;next = dummy-&gt;next; dummy-&gt;next = pCur; pCur = prev-&gt;next; } return dummy-&gt;next; } 链表相交两个链表相交，则相交之后必重合，从交点到末尾节点均相同。那么如果两个链表p1，p2相交的话，首先假设获得链表的长度分别为m，n，那么让较长的先走|m-n|步，再同步走的话，如果两个链表相交，那么p1，p2指针必定会相撞。 参考 https://www.cnblogs.com/byrhuangqiang/p/4311336.htmlhttps://www.cnblogs.com/byonecry/p/4458821.html]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CornerNet:将目标检测转为关键点预测]]></title>
    <url>%2F2018%2F09%2F26%2FCornerNet-%E5%B0%86%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E8%BD%AC%E4%B8%BA%E5%85%B3%E9%94%AE%E7%82%B9%E9%A2%84%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[论文链接：https://arxiv.org/abs/1808.01244代码链接：https://github.com/umich-vl/CornerNet CornerNet是ECCV2018上的一篇文章，与以往的Anchor机制的目标检测方法不同，这篇文章借鉴了人体关键点检测的思路，将目标检测转为关键点检测（Dectecting Objects as Paired Keypoints），是一种不一样的新思路，阅读了这篇文章，做个笔记。 Introduction目前目标检测算法的主要思路还是设置大量的Anchor作为预选框，通过训练的方式获取最后的bounding box，这样就带来两个问题： 大量的Anchor只有少部分和gt有比较大的overlap，从而带来正负样本巨大的不均衡的问题，减慢训练过程 Anchor的设置本身也是需要超参数的(形状、个数怎么设置)，在multi-scale的时候会更加明显。 作者因此提出了一种新的one-stage解决方法，将目标检测转为一堆关键点检测，the top-left corner 和bottom-right corner，使用卷积神经网络来为一个类别预测heatmap获取top-left corners,同样预测另一个heatmap获取bottom-right corners,还预测embedding vector对顶点进行分组，确定是否属于同一个目标，如下图所示。 另一个创新点是提出了corner pooling，一种为了更好地获取corner的新的pooling layer。以top-left corner pooling 为例，如下图所示对每个channel，分别提取特征图的水平和垂直方向的最大值，然后求和。 论文认为corner pooling之所以有效，是因为（1）目标定位框的中心难以确定，和边界框的4条边相关，但是每个顶点只与边界框的两条边相关，所以corner 更容易提取。（2）顶点更有效提供离散的边界空间，实用O(wh)顶点可以表示O(w2h2) anchor boxes。 CornetNetCornerNet使用CNNs来预测两组heatmaps为每个物品类别来表示corner的位置，使用embedding vector来表示corner是否属于同一个物品，同时为了产生更加紧密的bounding box，也预测了offset。通过heatmap, embedding vector，offsets,通过后处理的方法就可以获得最后的bounding box。作者提出的算法总体框架如下图所示： 使用了hourglass network作为backbone network，紧接的两个模块分别用于预测top-left corners和bottom-right corners，每一个模块有独立的corner pooling，然后得到heatmaps, embeddings, offsets. Detecting Corners论文预测了两组heatmap，每一个heatmap包含C channels(C是目标类别，不包括background),每一个channel是二进制mask，表示相应的corner位置。 对于每个顶点，只有一个groun truth，其他位置都是负样本。在训练过程中为了减少负样本数量，在每个gt顶点设定的半径r区域内都是正样本，如上图所示，半径r的确定根据所学的Iou决定。使用unnormalized 2D Gaussian来减少的半径r范围内的loss，基本思想就是构造高斯函数，中心就是gt位置，离这个中心越远衰减得越厉害，即： pcij表示类别为c，坐标是（i,j）的预测热点图，ycij表示相应位置的ground-truth，是经过2D Gaussian的输出值，用来调整权值，论文提出变体Focal loss表示检测目标的损失函数： 由于采样过程中的量化带来的misaligment，预测offset来调整corner的位置： 训练中用smooth L1 Loss来计算： Grouping Corner这个部分是用来决定一对corner是否来自同一object。具体的做法就是对卷积特征进行embedding（1x1的conv），得到corner的embedding vector，我们希望同属于同一个object的一对 corner的距离尽可能小，不属于的距离尽可能大！所以有两个loss，push loss和pull loss，从名字上来说，pull吧同一个目标的corner拉近，push把不同目标的推远。 etk,elk分别是属于 top-left corner和botto-right corner的embedding，ek是他们的平均值，△在论文中设置为1. Corner Pooling 为了检测某一个点是否是corner，需要从行和列分别检查，以top-left这个点为例，计算过程分为三部分： 从上到下做max pooling 从右到左做max pooling 然后合并（相加）如下图中，从下往上计算，每一列都能得到一个单调非递减的结果，相当于对corner的先验做了编码。对于object来说，如果要去找最上边的位置，需要从下到上检查这一列的最大值，最大值的位置是corner的可能存在的位置。 实际计算公式为： 这样整个预测框架如下图所示： Predict details 在corner heatmap上用3x3的max poolings做NMS，选择top 100的top-left和top 100的bottom-right 通过预测的offset来调整位置 计算top-left和bottom-right的embedding 的L1 distance，筛掉距离大于0.5或者是不属于同一类别的一对corner。 计算top-left和bottom-right的score的平均值作为最终的score。]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mask R-CNN论文+源码阅读笔记]]></title>
    <url>%2F2018%2F09%2F20%2FMask%20R-CNN%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[论文链接：https://arxiv.org/abs/1703.06870源码链接：https://github.com/matterport/Mask_RCNN之前一直在做目标检测这块，最近了解了一下实例分割，其实是目标检测更细致的任务，在图像中做到像素级的分割，包括目标检测和准确的像素分割，所以说是结合了之前目标检测的任务（classification and localization），以及语义分割（将像素点分类到特定的所属类别），首先拜读的就是17年何凯明大神的论文Mask R-CNN，并且阅读了keras版本的实现代码，在此做一个学习笔记， IntroductionMask R-CNN是在faster R-CNN的classification branch和bounding box regression branch基础上，增加了一个segmentation mask branch，以像素到像素的方法来预测分割掩码（segmentation mask），如下图所示。 Faster R-CNN由于RoI pooling，没有办法做到输入和输出之间的像素到像素的对齐(pixel-to-pixel)，为了解决这个问题，Mask R-CNN提出了一个RoiAlign层，可以极大地提高掩码的准确率；同时解耦掩码预测和分类预测，为每个类都独立地预测二进制掩码，这样不会跨类别竞争。最终运行速度可达5 FPS左右。 Mask R-CNNMask R-CNN和faster R-CNN类似，具有两个阶段，第一阶段是RPN，第二阶段出了预测类别和检测框的偏移外，还能够为每个RoI输出二进制掩码，这三个输出都是并行输出的。此外对每一个RoI提出了multi task：L=Lcls+Lbox+LmaskLcls和Lbox和之前faster RCNN中定义的一样，掩码分支对于每个RoI的输出维度为Km2，即K个分辨率为m×m的二进制掩码，每个类别一个，K为类别数量。对每个像素应用sigmod，Lmask为平均二进制交叉熵损失，对于真实类别为k的RoI，仅在第k个掩码上计算Lmask，其他掩码输出不计入损失。 Mask Representation掩码用来表述目标在图片中的像素位置，在mask R-CNN中通过卷积的方法，提供了像素到像素的对应来解决。具体来说，使用FCN的方法为每一个RoI预测一个m x m的掩码，与使用FC层预测掩码的方式不同，全卷积的方法需要更少的参数，预测也会更加准确。这种像素到像素的行为需要RoI特征，为了更好地与原图进行对齐，来准确地对应原图的像素关系，这里就提出了一个很关键的模块，RoIAlign层。 RoIAlign这个网络层主要是为了更好地与原图像素进行对齐，对之前faster R-CNN使用RoI Pooling操作中两次量化造成的区域不匹配(mis-aligment)问题进行了改进，所以在这里就不得不提一下RoI的局限性，借鉴了一篇博客的详细介绍。 RoI pooling的局限性Faster R-CNN的网络框架 由上图可以看到，RoI pooling位于RPN、Feature map和classification and regression之间，针对RPN输出的RoI，将其resize到统一的大小，首先将RoI映射到feature map对应的位置，将映射的区域划分为k x k个单元，对每个单元进行maxpooling，这样就得到统一大小k x k的输出了,期间就存在两次量化的过程 将候选框量化为整数点坐标值 将量化后的边界区域分割成k x k个单元（bin),对每一个单元的边界进行量化。 RoIPooling 采用的是 INTER_NEAREST（即最近邻插值） ，即在resize时，对于 缩放后坐标不能刚好为整数 的情况，采用了 粗暴的四舍五入，相当于选取离目标点最近的点。，经过这样两次量化就出现了边界不匹配的问题了(misaligment),候选框和最开始回归出来的已经有很大偏差了。 RoIAlignMask R-CNN将最邻近插值换成了双线性插值，这样就有了RoIAlign，主要流程为： 遍历每一个候选区域，保持浮点数边界不做量化。 将候选区域分割成k x k个单元，每个单元的边界也不做量化。 在每个单元中计算固定四个坐标位置，用双线性内插的方法计算出这四个位置的值，然后进行最大池化操作。 第三步的操作，论文也说的很清楚，这个固定位置指的是每一个单元(bin)中按照固定规则确定的位置，比如，如果采样点数是1，那么就是这个单元的中心点。如果采样点数是4，那么就是把这个单元平均分割成四个小方块以后它们分别的中心点。显然这些采样点的坐标通常是浮点数，所以需要使用插值的方法得到它的像素值。下图的例子中，虚线为特征图，实线为RoI，这里假设RoI分割成2 x 2的单元，在每个单元换分为4个小方块后，每个小方块的中心作为采样点，即图中的点，但是这些点的坐标一般来说是浮点数，采用双线性插值的方法来获得像素值，这样就不存在量化过程，很好地解决了misAligment问题。 Network ArchitectureMask R-CNN使用”网络-深度-特征输出层”的方式命名底下层卷积网络。我们评估了深度为50或101层的ResNet25和ResNeXt26网络。使用ResNet的Faster R-CNN从第四阶段的最终卷积层提取特征，我们称之为C4。例如，使用ResNet-50的下层网络由ResNet-50-C4表示。Mask R-CNN扩展了 ResNet和FPN中提出的Faster R-CNN的上层网络。详细信息如下图所示：（上层网络架构：我们扩展了两种现有的Faster R-CNN上层网络架构，分别添加了一个掩码分支。图中数字表示分辨率和通道数，箭头表示卷积、反卷积或全连接层（可以通过上下文推断，卷积减小维度，反卷积增加维度。）所有的卷积都是3×3的，除了输出层，是1×1的。反卷积是2×2的，步进为2，,隐藏层使用ReLU。左中，“res5”表示ResNet的第五阶段，简单起见，我们修改了第一个卷积操作，使用7×7，步长为1的RoI代替14×14，步长为2的RoI25。右图中的“×4”表示堆叠的4个连续的卷积。） 代码阅读主要参考来自于csdn一篇博客，借用他的图。 backbone network使用resnet101作为特征提取网络，生成金字塔网络，并在每层提取特征。 # Build the shared convolutional layers. # Bottom-up Layers # Returns a list of the last layers of each stage, 5 in total. # Don&apos;t create the thead (stage 5), so we pick the 4th item in the list. if callable(config.BACKBONE): _, C2, C3, C4, C5 = config.BACKBONE(input_image, stage5=True, train_bn=config.TRAIN_BN) else: _, C2, C3, C4, C5 = resnet_graph(input_image, config.BACKBONE, stage5=True, train_bn=config.TRAIN_BN) # Top-down Layers # TODO: add assert to varify feature map sizes match what&apos;s in config # FPN：把底层的特征和高层的特征进行融合，便于细致检测。 # 这里P5=C5，然后P4=P5+C4,P2 P3类似，最终得到rpn_feature_maps，注意这里多了个P6,其仅是由P5下采样获得。 P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name=&apos;fpn_c5p5&apos;)(C5) P4 = KL.Add(name=&quot;fpn_p4add&quot;)([ KL.UpSampling2D(size=(2, 2), name=&quot;fpn_p5upsampled&quot;)(P5), KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name=&apos;fpn_c4p4&apos;)(C4)]) P3 = KL.Add(name=&quot;fpn_p3add&quot;)([ KL.UpSampling2D(size=(2, 2), name=&quot;fpn_p4upsampled&quot;)(P4), KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name=&apos;fpn_c3p3&apos;)(C3)]) P2 = KL.Add(name=&quot;fpn_p2add&quot;)([ KL.UpSampling2D(size=(2, 2), name=&quot;fpn_p3upsampled&quot;)(P3), KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name=&apos;fpn_c2p2&apos;)(C2)]) # Attach 3x3 conv to all P layers to get the final feature maps. P2 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=&quot;SAME&quot;, name=&quot;fpn_p2&quot;)(P2) P3 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=&quot;SAME&quot;, name=&quot;fpn_p3&quot;)(P3) P4 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=&quot;SAME&quot;, name=&quot;fpn_p4&quot;)(P4) P5 = KL.Conv2D(config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding=&quot;SAME&quot;, name=&quot;fpn_p5&quot;)(P5) # P6 is used for the 5th anchor scale in RPN. Generated by # subsampling from P5 with stride of 2. P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name=&quot;fpn_p6&quot;)(P5) # Note that P6 is used in RPN, but not in the classifier heads. rpn_feature_maps = [P2, P3, P4, P5, P6] mrcnn_feature_maps = [P2, P3, P4, P5] Anchor在前面金字塔特征图的基础上，生成anchor # Anchors # 如果是训练的情况，就在金字塔特征图上生成Anchor if mode == &quot;training&quot;: # 在金字塔特征图上以每个像素为中心，以配置文件的anchor大小为宽高生成anchor # 根据特征图相应原图缩小的比例，还原到原始的输入图片上，即得到的是anchor在原始图片上的坐标 # 获得结果为(N,[y1,x1,y2,x2]) anchors = self.get_anchors(config.IMAGE_SHAPE) # Duplicate across the batch dimension because Keras requires it # TODO: can this be optimized to avoid duplicating the anchors? anchors = np.broadcast_to(anchors, (config.BATCH_SIZE,) + anchors.shape) # A hack to get around Keras&apos;s bad support for constants anchors = KL.Lambda(lambda x: tf.Variable(anchors), name=&quot;anchors&quot;)(input_image) else: # 如果是Inference就是输入的Anchor anchors = input_anchors RPN Model将金字塔特征图输入到RPN中，得到网络的分类（前景和背景两类）和bbox的回归值。 # RPN Model # RPN主要实现2个功能： # 1 &gt; box的前景色和背景色的分类 # 2 &gt; box框体的回归修正 rpn = build_rpn_model(config.RPN_ANCHOR_STRIDE, len(config.RPN_ANCHOR_RATIOS), config.TOP_DOWN_PYRAMID_SIZE) # Loop through pyramid layers layer_outputs = [] # list of lists for p in rpn_feature_maps: layer_outputs.append(rpn([p])) # Concatenate layer outputs # Convert from list of lists of level outputs to list of lists # of outputs across levels. # e.g. [[a1, b1, c1], [a2, b2, c2]] =&gt; [[a1, a2], [b1, b2], [c1, c2]] output_names = [&quot;rpn_class_logits&quot;, &quot;rpn_class&quot;, &quot;rpn_bbox&quot;] outputs = list(zip(*layer_outputs)) outputs = [KL.Concatenate(axis=1, name=n)(list(o)) for o, n in zip(outputs, output_names)] # rpn_class_logits: [batch, H * W * anchors_per_location, 2] Anchor classifier logits(before softmax) # rpn_probs: [batch, H * W * anchors_per_location, 2] Anchor classifier probabilities. # rpn_bbox: [batch, H * W * anchors_per_location, (dy, dx, log(dh), log(dw))] Deltas to be applied to anchors. rpn_class_logits, rpn_class, rpn_bbox = outputs 其中RPN网络也用keras做了实现，Builds a Keras model of the Region Proposal Network.It wraps the RPN graph so it can be used multiple times with shared weights. # Shared convolutional base of the RPN shared = KL.Conv2D(512, (3, 3), padding=&apos;same&apos;, activation=&apos;relu&apos;, strides=anchor_stride, name=&apos;rpn_conv_shared&apos;)(feature_map) # Anchor Score. [batch, height, width, anchors per location * 2]. x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding=&apos;valid&apos;, activation=&apos;linear&apos;, name=&apos;rpn_class_raw&apos;)(shared) # Reshape to [batch, anchors, 2] rpn_class_logits = KL.Lambda( lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x) # Softmax on last dimension of BG/FG. rpn_probs = KL.Activation( &quot;softmax&quot;, name=&quot;rpn_class_xxx&quot;)(rpn_class_logits) # Bounding box refinement. [batch, H, W, anchors per location * depth] # where depth is [x, y, log(w), log(h)] x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding=&quot;valid&quot;, activation=&apos;linear&apos;, name=&apos;rpn_bbox_pred&apos;)(shared) # Reshape to [batch, anchors, 4] rpn_bbox = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x) return [rpn_class_logits, rpn_probs, rpn_bbox] 代码主要实现是，在特征图上，用kernel_size为所需输出个数（如对分类，为2 * anchors_per_location），stride为1的卷积在特征图上进行卷积，得到RPN的输出。 Generate proposals这部分网络主要是用来对anchor进行筛选，所谓proposal，主要步骤为： # Box Scores. Use the foreground class confidence. [Batch, num_rois, 1] scores = inputs[0][:, :, 1] # Box deltas [batch, num_rois, 4] deltas = inputs[1] deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, [1, 1, 4]) # Anchors anchors = inputs[2] # Improve performance by trimming to top anchors by score # and doing the rest on the smaller subset. pre_nms_limit = tf.minimum(self.config.PRE_NMS_LIMIT, tf.shape(anchors)[1]) ix = tf.nn.top_k(scores, pre_nms_limit, sorted=True, name=&quot;top_anchors&quot;).indices scores = utils.batch_slice([scores, ix], lambda x, y: tf.gather(x, y), self.config.IMAGES_PER_GPU) deltas = utils.batch_slice([deltas, ix], lambda x, y: tf.gather(x, y), self.config.IMAGES_PER_GPU) pre_nms_anchors = utils.batch_slice([anchors, ix], lambda a, x: tf.gather(a, x), self.config.IMAGES_PER_GPU, names=[&quot;pre_nms_anchors&quot;]) # Apply deltas to anchors to get refined anchors. # [batch, N, (y1, x1, y2, x2)] boxes = utils.batch_slice([pre_nms_anchors, deltas], lambda x, y: apply_box_deltas_graph(x, y), self.config.IMAGES_PER_GPU, names=[&quot;refined_anchors&quot;]) # Clip to image boundaries. Since we&apos;re in normalized coordinates, # clip to 0..1 range. [batch, N, (y1, x1, y2, x2)] window = np.array([0, 0, 1, 1], dtype=np.float32) boxes = utils.batch_slice(boxes, lambda x: clip_boxes_graph(x, window), self.config.IMAGES_PER_GPU, names=[&quot;refined_anchors_clipped&quot;]) # Filter out small boxes # According to Xinlei Chen&apos;s paper, this reduces detection accuracy # for small objects, so we&apos;re skipping it. # Non-max suppression def nms(boxes, scores): indices = tf.image.non_max_suppression( boxes, scores, self.proposal_count, self.nms_threshold, name=&quot;rpn_non_max_suppression&quot;) proposals = tf.gather(boxes, indices) # Pad if needed padding = tf.maximum(self.proposal_count - tf.shape(proposals)[0], 0) proposals = tf.pad(proposals, [(0, padding), (0, 0)]) return proposals proposals = utils.batch_slice([boxes, scores], nms, self.config.IMAGES_PER_GPU) return proposals 按score得分排序，取前6000个 将rpn的输出应用到anchors进行修正 舍弃修正后边框超过归一化的0-1区间内的 用非极大值抑制的方法获取最后的anchor Generate detection target训练的时候计算loss需要有target，这一步就是对剩下的anchor产生detection target，以便后续计算loss。主要计算的步骤为： 计算proposal和gt_box之间的iou值，大于0.5则被认为是正样本，小于0.5，并且和crow box相交不大的为负样本 对负样本进行采样，保证正样本占有33%的比例，保证正负样本平衡 根据正样本和那个gt_box的iou最大来给正样本分配gt_box和gt_max,以便计算偏差 fpn classifier graph &amp;fpn mask graph这部分为分类网络，当然还有一个并行的mask分支，分类使用的是mrcnn_feature_map，即前面的P2、P3、P4、P5。基本思路是先经过ROIAlign层（取代了RoIPooling），再经过两层卷积后连接两个全连接层分别输出class和box。fpn_mask_graph也是类似，针对mask部分，只不过不同的是，前者经过PyramidROIAlign得到的特征图是7x7大小的，二，而后者经过PyramidROIAlign得到的特征图大小是14x14. Lossloss包括5个部分组成，分别是rpn网络的两个损失：rpn_class_loss，计算前景和背景分类损失；rpn_bbox_loss，计算rpn_box损失,以及输出的class，box和mask的损失计算。 # Losses rpn_class_loss = KL.Lambda(lambda x: rpn_class_loss_graph(*x), name=&quot;rpn_class_loss&quot;)( [input_rpn_match, rpn_class_logits]) rpn_bbox_loss = KL.Lambda(lambda x: rpn_bbox_loss_graph(config, *x), name=&quot;rpn_bbox_loss&quot;)( [input_rpn_bbox, input_rpn_match, rpn_bbox]) class_loss = KL.Lambda(lambda x: mrcnn_class_loss_graph(*x), name=&quot;mrcnn_class_loss&quot;)( [target_class_ids, mrcnn_class_logits, active_class_ids]) bbox_loss = KL.Lambda(lambda x: mrcnn_bbox_loss_graph(*x), name=&quot;mrcnn_bbox_loss&quot;)( [target_bbox, target_class_ids, mrcnn_bbox]) mask_loss = KL.Lambda(lambda x: mrcnn_mask_loss_graph(*x), name=&quot;mrcnn_mask_loss&quot;)( [target_mask, target_class_ids, mrcnn_mask]) PyramidROIAlignPyramidROIAlign输入时金字塔特征图，所以首先需要确认来自于哪一层，作者的计算方法采用如下公式 这里k0=4，从对应特征图中去除坐标对应区域，利用双线性插值进行pooling，这里作者依据论文中的，虽然没有采用论文中的4个点采样的方法，但是采用了论文中提到的也非常有效的1个点采样的方法，而tf.crop_and_resize这个函数crops and resizes an image and handles the bilinear interpolation，所以用这个进行了实现。 # Crop boxes [batch, num_boxes, (y1, x1, y2, x2)] in normalized coords boxes = inputs[0] # Image meta # Holds details about the image. See compose_image_meta() image_meta = inputs[1] # Feature Maps. List of feature maps from different level of the # feature pyramid. Each is [batch, height, width, channels] feature_maps = inputs[2:] # Assign each ROI to a level in the pyramid based on the ROI area. y1, x1, y2, x2 = tf.split(boxes, 4, axis=2) h = y2 - y1 w = x2 - x1 # Use shape of first image. Images in a batch must have the same size. image_shape = parse_image_meta_graph(image_meta)[&apos;image_shape&apos;][0] # Equation 1 in the Feature Pyramid Networks paper. Account for # the fact that our coordinates are normalized here. # e.g. a 224x224 ROI (in pixels) maps to P4 image_area = tf.cast(image_shape[0] * image_shape[1], tf.float32) roi_level = log2_graph(tf.sqrt(h * w) / (224.0 / tf.sqrt(image_area))) roi_level = tf.minimum(5, tf.maximum( 2, 4 + tf.cast(tf.round(roi_level), tf.int32))) roi_level = tf.squeeze(roi_level, 2) # Loop through levels and apply ROI pooling to each. P2 to P5. pooled = [] box_to_level = [] for i, level in enumerate(range(2, 6)): ix = tf.where(tf.equal(roi_level, level)) level_boxes = tf.gather_nd(boxes, ix) # Box indices for crop_and_resize. box_indices = tf.cast(ix[:, 0], tf.int32) # Keep track of which box is mapped to which level box_to_level.append(ix) # Stop gradient propogation to ROI proposals level_boxes = tf.stop_gradient(level_boxes) box_indices = tf.stop_gradient(box_indices) # Crop and Resize # From Mask R-CNN paper: &quot;We sample four regular locations, so # that we can evaluate either max or average pooling. In fact, # interpolating only a single value at each bin center (without # pooling) is nearly as effective.&quot; # # Here we use the simplified approach of a single value per bin, # which is how it&apos;s done in tf.crop_and_resize() # Result: [batch * num_boxes, pool_height, pool_width, channels] pooled.append(tf.image.crop_and_resize( feature_maps[i], level_boxes, box_indices, self.pool_shape, method=&quot;bilinear&quot;)) # Pack pooled features into one tensor pooled = tf.concat(pooled, axis=0) # Pack box_to_level mapping into one array and add another # column representing the order of pooled boxes box_to_level = tf.concat(box_to_level, axis=0) box_range = tf.expand_dims(tf.range(tf.shape(box_to_level)[0]), 1) box_to_level = tf.concat([tf.cast(box_to_level, tf.int32), box_range], axis=1) # Rearrange pooled features to match the order of the original boxes # Sort box_to_level by batch then box index # TF doesn&apos;t have a way to sort by two columns, so merge them and sort. sorting_tensor = box_to_level[:, 0] * 100000 + box_to_level[:, 1] ix = tf.nn.top_k(sorting_tensor, k=tf.shape( box_to_level)[0]).indices[::-1] ix = tf.gather(box_to_level[:, 2], ix) pooled = tf.gather(pooled, ix) # Re-add the batch dimension pooled = tf.expand_dims(pooled, 0) return pooled build_rpn_targets从loss可以看到，训练的时候，rpn的loss输入需要有target，代码中为rpn_match和rpn_box,计算方法主要也是根据金字塔的给定anchors和gt_box的iou，此处阈值为0.7，来确定postive和negative，并分配对应的gt_box来计算delta。 &quot;&quot;&quot;Given the anchors and GT boxes, compute overlaps and identify positive anchors and deltas to refine them to match their corresponding GT boxes. anchors: [num_anchors, (y1, x1, y2, x2)] gt_class_ids: [num_gt_boxes] Integer class IDs. gt_boxes: [num_gt_boxes, (y1, x1, y2, x2)] Returns: rpn_match: [N] (int32) matches between anchors and GT boxes. 1 = positive anchor, -1 = negative anchor, 0 = neutral rpn_bbox: [N, (dy, dx, log(dh), log(dw))] Anchor bbox deltas. &quot;&quot;&quot; # RPN Match: 1 = positive anchor, -1 = negative anchor, 0 = neutral rpn_match = np.zeros([anchors.shape[0]], dtype=np.int32) # RPN bounding boxes: [max anchors per image, (dy, dx, log(dh), log(dw))] rpn_bbox = np.zeros((config.RPN_TRAIN_ANCHORS_PER_IMAGE, 4)) # Handle COCO crowds # A crowd box in COCO is a bounding box around several instances. Exclude # them from training. A crowd box is given a negative class ID. crowd_ix = np.where(gt_class_ids &lt; 0)[0] if crowd_ix.shape[0] &gt; 0: # Filter out crowds from ground truth class IDs and boxes non_crowd_ix = np.where(gt_class_ids &gt; 0)[0] crowd_boxes = gt_boxes[crowd_ix] gt_class_ids = gt_class_ids[non_crowd_ix] gt_boxes = gt_boxes[non_crowd_ix] # Compute overlaps with crowd boxes [anchors, crowds] crowd_overlaps = utils.compute_overlaps(anchors, crowd_boxes) crowd_iou_max = np.amax(crowd_overlaps, axis=1) no_crowd_bool = (crowd_iou_max &lt; 0.001) else: # All anchors don&apos;t intersect a crowd no_crowd_bool = np.ones([anchors.shape[0]], dtype=bool) # Compute overlaps [num_anchors, num_gt_boxes] overlaps = utils.compute_overlaps(anchors, gt_boxes) # Match anchors to GT Boxes # If an anchor overlaps a GT box with IoU &gt;= 0.7 then it&apos;s positive. # If an anchor overlaps a GT box with IoU &lt; 0.3 then it&apos;s negative. # Neutral anchors are those that don&apos;t match the conditions above, # and they don&apos;t influence the loss function. # However, don&apos;t keep any GT box unmatched (rare, but happens). Instead, # match it to the closest anchor (even if its max IoU is &lt; 0.3). # # 1. Set negative anchors first. They get overwritten below if a GT box is # matched to them. Skip boxes in crowd areas. anchor_iou_argmax = np.argmax(overlaps, axis=1) anchor_iou_max = overlaps[np.arange(overlaps.shape[0]), anchor_iou_argmax] rpn_match[(anchor_iou_max &lt; 0.3) &amp; (no_crowd_bool)] = -1 # 2. Set an anchor for each GT box (regardless of IoU value). # TODO: If multiple anchors have the same IoU match all of them gt_iou_argmax = np.argmax(overlaps, axis=0) rpn_match[gt_iou_argmax] = 1 # 3. Set anchors with high overlap as positive. rpn_match[anchor_iou_max &gt;= 0.7] = 1 # Subsample to balance positive and negative anchors # Don&apos;t let positives be more than half the anchors ids = np.where(rpn_match == 1)[0] extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE // 2) if extra &gt; 0: # Reset the extra ones to neutral ids = np.random.choice(ids, extra, replace=False) rpn_match[ids] = 0 # Same for negative proposals ids = np.where(rpn_match == -1)[0] extra = len(ids) - (config.RPN_TRAIN_ANCHORS_PER_IMAGE - np.sum(rpn_match == 1)) if extra &gt; 0: # Rest the extra ones to neutral ids = np.random.choice(ids, extra, replace=False) rpn_match[ids] = 0 # For positive anchors, compute shift and scale needed to transform them # to match the corresponding GT boxes. ids = np.where(rpn_match == 1)[0] ix = 0 # index into rpn_bbox # TODO: use box_refinement() rather than duplicating the code here for i, a in zip(ids, anchors[ids]): # Closest gt box (it might have IoU &lt; 0.7) gt = gt_boxes[anchor_iou_argmax[i]] # Convert coordinates to center plus width/height. # GT Box gt_h = gt[2] - gt[0] gt_w = gt[3] - gt[1] gt_center_y = gt[0] + 0.5 * gt_h gt_center_x = gt[1] + 0.5 * gt_w # Anchor a_h = a[2] - a[0] a_w = a[3] - a[1] a_center_y = a[0] + 0.5 * a_h a_center_x = a[1] + 0.5 * a_w # Compute the bbox refinement that the RPN should predict. rpn_bbox[ix] = [ (gt_center_y - a_center_y) / a_h, (gt_center_x - a_center_x) / a_w, np.log(gt_h / a_h), np.log(gt_w / a_w), ] # Normalize rpn_bbox[ix] /= config.RPN_BBOX_STD_DEV ix += 1 return rpn_match, rpn_bbox train可以看到,计算RPN的时候的RPN loss和分类loss其实原始的输入都需要gt_box，只不过训练好之后，分类loss是在RPN的基础上。作者代码将RPN和后面的faster RCNN部分以及增加的mask 分支一起训练，所以在训练代码中加了下面一段： # Stop gradient propogation to ROI proposals level_boxes = tf.stop_gradient(level_boxes) box_indices = tf.stop_gradient(box_indices) 引用官方的解释，主要是为了不让两部分互相影响。If we don’t stop the gradients, TensorFlow will try to compute the gradients all the way back to the code that generates the anchor box refinement. But we already handle learning the anchor refinement in the RPN, so we don’t want to influence that with additional gradients from stage 2. So, the sooner we stop it, the more unnecessary computation we avoid. Further, it’s not clear (at least I haven’t looked into it) how the gradients calculation back through crop_and_resize works.]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>CV</tag>
        <tag>实例分割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synthesize image for Chinese text recognition]]></title>
    <url>%2F2018%2F09%2F12%2FSynthesize%20image%20for%20Chinese%20text%20recognition%2F</url>
    <content type="text"><![CDATA[文本识别数据集需要大量的数据，特别是对于中文来说，中文字相对英文26个字母来说，更加复杂，数量多得多，所以需要有体量比较大的数据集才能训练得到不错的效果，目前也有一些合成的方法，VGG组就提出SynthText方法合成自然场景下的文本图片，github上有作者给出的官方代码，也有国内大神改写的中文版本代码。但是生成的速度非常慢，而且生成机制有点复杂，总是报错，短时间内还没解决。我的需求场景仅仅是识别文字，并没有涉及到检测部分，所以不需要完整的场景图片，所以提出一种方法来合成中文文本图片用于文本识别，分享一下实现思路。 主要思路借鉴了SynthText的方法，而且包括语料库、图像背景图、字体、以及色彩模型文件，都是来源于@JarveeLee的中文版代码中的文件。 读取语料库，此处来源为一些童话故事txt， 随机取一段字符串，满足所需长度，再随机选择字体、字号大小 在提供的背景图中，随机取一张图，计算裁剪图的Lab值标准差（标准差越小图像色彩分布就不会太过丰富、太过花哨），小于设定的阈值则再根据字体字号计算出的文本尺寸，在原图上进行随机裁剪，可以以一定概率使文本在最终图片中有一定偏移；可以以一定概率随机产生竖直文本。 通过聚类的方法，分析裁剪后图的色彩分布，在色彩模型提供的色彩库中选择与当前裁剪图像色彩偏差大的作为文本颜色，这样最终构成合成图片 构建方法主要实现代码只有一个文件，其他都是合成需要的文件，合成命令： python gen_dataset.py newsgroup:文本来源的语料models/colors_new.cp:从III-5K数据集学习到的色彩模型fonts：包含合成时所需字体所需图片bg_img来源于VGG组合成synth_80k时所用的图片集 bg_img.tar.gz [8.9G]：压缩的图像文件（需要使用使用imnames.cp中的过滤），链接http://zeus.robots.ox.ac.uk/textspot/static/db/bg_img.tar.gz imnames.cp[180K]：已过滤文件的名称，即，这些文件不包含文本,链接：http://zeus.robots.ox.ac.uk/textspot/static/db/imnames.cp 一些实现结果样例 详细实现代码可参见个人github。]]></content>
      <tags>
        <tag>OCR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow输入数据处理框架]]></title>
    <url>%2F2018%2F07%2F25%2FTensorflow%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Tensoflow提供了一种统一的数据格式来存储数据，这个格式就是TFrecords，基于TFrecords我们构建一个完整的TensorFlow输入数据处理框架，以COCO数据集为例，介绍了COCO数据集的TFrecords文件制作，以及读取解析的过程，以此来介绍一个构建文件处理框架的过程。 TFrecords格式介绍TFrecords是一种二进制文件，通过tf.train.Example Protocol Buffer的格式存储数据，以下的代码给出了tf.train.Example的定义。 message Example { Features features = 1; }; message Features { map&lt;string, Feature&gt; feature = 1; }; message Feature { oneof kind { BytesList bytes_list = 1; FloatList float_list = 2; Int64List int64_list = 3; } }; tf.train.Example包含了一个从属性名称到取值的字典，其中属性名称为一个字符串，属性取值可以是字符串(BytesList)，实数列表(FloatList)或者整数列表(Int64List），比如将解码前的图像存为一个字符串，将lable存为整数列表，或者将bounding box存为实数列表。 COCO数据集的TFrecords文件制作COCO数据集是微软做的一个比较大的数据集，可以用来做图像的recognition、segmentation、captioning，我用来做物体检测识别。官方也提供了API操作数据集（https://github.com/cocodataset/cocoapi）。根据链接介绍下载安装python的API后，就可以开始Tfrecords的文件制作了。 from pycocotools.coco import COCO import tensorflow as tf import numpy as np from PIL import Image from time import time import os dataDir=&apos;/home/zju/lkj/data/COCO Dataset&apos; dataType=&apos;train2017&apos; annFile=&apos;{}/annotations/instances_{}.json&apos;.format(dataDir,dataType) classes = [&apos;backpack&apos;, &apos;umbrella&apos;, &apos;handbag&apos;, &apos;tie&apos;, &apos;suitcase&apos;, &apos;bottle&apos;, &apos;wine glass&apos;, &apos;cup&apos;, &apos;fork&apos;, &apos;knife&apos;, &apos;spoon&apos;, &apos;bowl&apos;, &apos;banana&apos;, &apos;apple&apos;, &apos;sandwich&apos;, &apos;orange&apos;, &apos;broccoli&apos;, &apos;carrot&apos;, &apos;hot dog&apos;, &apos;donut&apos;, &apos;cake&apos;, &apos;chair&apos;, &apos;couch&apos;, &apos;potted plant&apos;, &apos;bed&apos;, &apos;dining table&apos;, &apos;toilet&apos;, &apos;tv&apos;, &apos;laptop&apos;, &apos;mouse&apos;, &apos;remote&apos;, &apos;keyboard&apos;, &apos;cell phone&apos;, &apos;microwave&apos;, &apos;oven&apos;, &apos;toaster&apos;, &apos;sink&apos;, &apos;refrigerator&apos;, &apos;book&apos;, &apos;clock&apos;, &apos;vase&apos;, &apos;scissors&apos;, &apos;teddy bear&apos;, &apos;hair drier&apos;, &apos;toothbrush&apos;] # initialize COCO api for instance annotations coco = COCO(annFile) classesId = coco.getCatIds(classes) imgIds = coco.getImgIds() img_filters=[] for imgId in imgIds: Anns = coco.loadAnns(coco.getAnnIds(imgIds=imgId)) annIds = list(map(lambda x:x[&apos;category_id&apos;],Anns)) for annId in annIds: if annId in classesId: img_filters.append(imgId) img_filters = set(img_filters) # 归一化 # size: 图片大小 # box：[x,y,w,h] # return 归一化结果 def convert(size,box): dw = 1./size[0] dh = 1./size[1] x = box[0]+box[2]/2.0 y = box[1]+box[3]/2.0 x = x*dw w = box[2]*dw y = y*dh h = box[3]*dh return [x,y,w,h] def convert_img(img_id): img_id_str = str(img_id).zfill(12) img_path = &apos;{}/{}/{}.jpg&apos;.format(dataDir, dataType, img_id_str) image = Image.open(img_path) resized_image = image.resize((416, 416), Image.BICUBIC) image_data = np.array(resized_image, dtype=&apos;float32&apos;) / 255 if image_data.size != 519168: # 不为3通道 return False img_raw = image_data.tobytes() return img_raw def convert_annotation(image_id): img_info = coco.loadImgs(image_id)[0] # 读入的是照片的详细信息，而非图像信息, 返回的是list，只有1个id输入时，取0 w = int(img_info[&apos;width&apos;]) h = int(img_info[&apos;height&apos;]) bboxes = [] Anns = coco.loadAnns(ids=coco.getAnnIds(imgIds=image_id)) i = 0 for Ann in Anns: if i&gt;29: break iscrowd = Ann[&apos;iscrowd&apos;] if iscrowd == 1: continue if Ann[&apos;category_id&apos;] not in classesId: continue cls_id = classesId.index(Ann[&apos;category_id&apos;]) # 取新的编号 bbox = Ann[&apos;bbox&apos;] bb = convert((w, h), bbox) + [cls_id] bboxes.extend(bb) i = i + 1 if len(bboxes) &lt; 30*5: bboxes = bboxes + [0, 0, 0, 0, 0]*(30-int(len(bboxes)/5)) return np.array(bboxes, dtype=np.float32).flatten().tolist() filename = os.path.join(&apos;train2017&apos;+&apos;.tfrecords&apos;) writer = tf.python_io.TFRecordWriter(filename) i=0 start = time() for imgId in img_filters: xywhc = convert_annotation(imgId) img_raw = convert_img(imgId) if img_raw: example = tf.train.Example(features=tf.train.Features(feature={ &apos;xywhc&apos;: tf.train.Feature(float_list=tf.train.FloatList(value=xywhc)), &apos;img&apos;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])), })) writer.write(example.SerializeToString()) # 显示制作进度，剩余时间 if i%100==99: t = time()-start print(i,&apos;t={:0.4f}s/100 step&apos;.format(t),&apos; left time={:0.4f}s&apos;.format((len(img_filters)-i)*t/100)) start = time() i = i+1 print(&apos;Done!&apos;) writer.close() 下面分段对代码进行介绍，这个数据制作是应用于物品检查与分割，并且只有部分物品，所以在程序开头有classes列举（总共45种，完整的COCO数据集包含91种）。COCO数据集中混有灰度图，所以在reshape的时候会一直报错，刚开始还一直想不清楚为什么，后来遍历原始数据集才发现有灰度图的存在，所以reshape成416*416*3会报错,所以程序有一个判断是否为3通道： image = Image.open(img_path) resized_image = image.resize((416, 416), Image.BICUBIC) image_data = np.array(resized_image, dtype=&apos;float32&apos;) / 255 if image_data.size != 519168: # 不为3通道 return False 图像读取后转换成字符串(BytesList): img_raw = image_data.tobytes() bounding box转换成实数列表(FloatList): return np.array(bboxes, dtype=np.float32).flatten().tolist() 基于此，核心的构建部分为： example = tf.train.Example(features=tf.train.Features(feature={ &apos;xywhc&apos;: tf.train.Feature(float_list=tf.train.FloatList(value=xywhc)), &apos;img&apos;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])), })) writer.write(example.SerializeToString()) TFrecords文件读取解析对应构建时候的数据格式，进行解析，可以加一些程序对于读取后的图像文件的一些进一步处理，比如图像增强 def parser(example): features = { &apos;xywhc&apos;: tf.FixedLenFeature([150], tf.float32), &apos;img&apos;: tf.FixedLenFeature((), tf.string)} feats = tf.parse_single_example(example, features) coord = feats[&apos;xywhc&apos;] coord = tf.reshape(coord, [30, 5]) img = tf.decode_raw(feats[&apos;img&apos;], tf.float32) img = tf.reshape(img, [416, 416, 3]) img = tf.image.resize_images(img, [cfg.train.image_resized, cfg.train.image_resized]) rnd = tf.less(tf.random_uniform(shape=[], minval=0, maxval=2), 1) # 添加对于读取后的图像文件的一些进一步处理，图像增强 def flip_img_coord(_img, _coord): zeros = tf.constant([[0, 0, 0, 0, 0]]*30, tf.float32) img_flipped = tf.image.flip_left_right(_img) idx_invalid = tf.reduce_all(tf.equal(coord, 0), axis=-1) coord_temp = tf.concat([tf.minimum(tf.maximum(1 - _coord[:, :1], 0), 1), _coord[:, 1:]], axis=-1) coord_flipped = tf.where(idx_invalid, zeros, coord_temp) return img_flipped, coord_flipped img, coord = tf.cond(rnd, lambda: (tf.identity(img), tf.identity(coord)), lambda: flip_img_coord(img, coord)) img = tf.image.random_hue(img, max_delta=0.1) img = tf.image.random_contrast(img, lower=0.8, upper=1.2) img = tf.image.random_brightness(img, max_delta=0.1) img = tf.image.random_saturation(img, lower=0.8, upper=1.2) img = tf.minimum(img, 1.0) img = tf.maximum(img, 0.0) return img, coord 然后构建一个data_pipeline来作为训练数据的输入框架： def data_pipeline(file_tfrecords, batch_size): dt = tf.data.TFRecordDataset(file_tfrecords) dt = dt.map(parser, num_parallel_calls=4) dt = dt.prefetch(batch_size) dt = dt.shuffle(buffer_size=20*batch_size) dt = dt.repeat() dt = dt.batch(batch_size) iterator = dt.make_one_shot_iterator() imgs, true_boxes = iterator.get_next() return imgs, true_boxes 测试一下整个数据输入模块： file_path = &apos;train2007.tfrecords&apos; imgs, true_boxes = data_pipeline(file_path, cfg.batch_size) sess = tf.Session() imgs_, true_boxes_ = sess.run([imgs, true_boxes]) print(imgs_.shape, true_boxes_.shape) for imgs_i, boxes_ in zip(imgs_, true_boxes_): valid = (np.sum(boxes_, axis=-1) &gt; 0).tolist() print([cfg.names[int(idx)] for idx in boxes_[:, 4][valid].tolist()]) plt.figure() plt.imshow(imgs_i) plt.show()]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[表扬一下pycharm]]></title>
    <url>%2F2018%2F07%2F07%2F%E8%A1%A8%E6%89%AC%E4%B8%80%E4%B8%8Bpycharm%2F</url>
    <content type="text"><![CDATA[难得写一篇记录心情博客，表扬一下pycharm，拯救了一下我从大喜到大悲的悲伤，再回到大喜的刺激，其实就是发现了pycharm的一个记录修改过程的功能。 炼丹过程中参数修改频繁，还忘了备份已经效果比较好的参数，结果改的调不回去了，本来还有个理想的结果，现在越来越差，真实欲哭无泪，直到发现了上面的那个功能，pycharm是真的优秀，按这样点开，就能发现一天的修改过程，如下图 可以点开看到修改历史，和现有版本进行对比，还可以导出修改历史。嗯，真的是良心IDE，特此表扬，以资鼓励。]]></content>
      <tags>
        <tag>杂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目标检测网络之YOLO学习笔记]]></title>
    <url>%2F2018%2F06%2F15%2F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%BD%91%E7%BB%9C%E4%B9%8BYOLO%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[YOLO是一种全新的，与R-CNN思想截然不同的目标检测的方法。R-CNN系列网络是通过proposal region产生可能包含目标物体的bounding box，再通分类器判断是否包含物品以及物品类别，用regression对bounding的坐标、大小进行修正。YOLO则是一种end to end的方式，用一个神经网络，实现了预测出bounding box 的坐标、box中包含物体的置信度和物体的probabilities，因此检测速度更快，训练相对更加简单，当然相对来说也带来一些其他缺点。 YOLO项目主页地址YOLO1 论文YOLO2 论文YOLO3 论文 YOLO v1YOLO使用来自整张图片的feature map来预测bounding box和class，因此可以保持较高的精度。YOLO将整张图片分成S×S的网格，如果一个目标的中心落入到网格单元中，那么这个网格单元负责这个目标的检测。 每个网格单元预测B个bounding box和confidence score，confidence score反应了box包含目标的可信度，论文中将可confidence score定义为： ，因此，如果没有目标存在confidence score为0，否则应该为IOU(intersection over union)，即真实框和预测框的交集部分。所以每个bounding box的预测值包括(x,y,w,h.confidence score). (x,y)表示预测的box中心相对于网格单元的的位置，(w,h)是用整个图片大小进行归一化的宽度和高度，另外，针对C个类别，每个类别需要预测一个条件概率，即： 最终得到box中包含某个特定物品的概率为： 整个过程如下图所示。 总结来说，YOLO网络将检测问题转换成regression，首先将整张图片转换成S×S的网格，并且每个网格单元预测B个边界框，这些边界框的(x,y,w,h,confidence score)以及C个类别概率,这些预测被编码为S×S×(B*5+C)的张量。 Network DesignYOLO1的网络结构设计借鉴了GoodLeNet模型，包含了24个卷积层和2个全连接层，YOLO未使用inception module，而是使用1x1卷积层和）3x3卷积层简单替代，交替出现的1x1卷积层实现了跨通道信息融合以及通道数目降低。 Training 使用 ImageNet 1000 类数据训练YOLO网络的前20个卷积层+1个average池化层+1个全连接层。 用上面得到的前20个卷积层网络参数来初始化YOLO模型前20个卷积层的网络参数，加入后面的4层卷积层以及2层全连接层进行detection的训练，detection通常需要有细密纹理的视觉信息,所以为提高图像精度，在训练检测模型时，将输入图像分辨率从224 × 224 resize到448x448。 最后一层预测类概率和边界框坐标。我们通过图像宽度和高度来规范(w,h)，使它们落在0和1之间。我们将边界框(x,y)坐标参数化为特定网格单元位置的偏移量，所以它们边界也在0和1之间。 LossYOLO1的误差计算对于分类误差和定位误差用了不同的权重，对包含与不包含物品的box的误差权重也进行了区分。具体来说，论文中增加了边界框坐标预测损失，并减少了不包含目标边界框的置信度预测损失，使用两个参数λcoord和λnoobj来完成这个工作，论文中设置了λcoord=5和λnoobj=0.5。另一个问题是平方和误差权重在大框和小框中进行了区分。相同的误差下，小框误差的重要性肯定更好，论文中用了一个很巧妙的方法，直接预测边界框宽度和高度的平方根，而不是宽度和高度。根据y=x^1/2的函数就可以知道，函数斜率是随着x的增大而减小的，这样就可以提高小框的误差权重，真的巧妙。YOLO每个网格单元预测多个box。在训练时，每个目标我们只需要一个box来负责，选定的原则是与真实框具有最大的IOU。 ShortcomingYOLO对边界框预测强加空间约束，因为每个网格单元只预测两个盒子，只能有一个类别。这个空间约束限制了我们的模型可以预测的邻近目标的数量，因此在小物品的检测上比较局限。 YOLO v2为提高物体定位精准性和召回率，YOLO2对网络结构的设计进行了改进，输出层使用卷积层替代YOLO的全连接层，联合使用coco物体检测标注数据和imagenet物体分类标注数据训练物体检测模型。相比YOLO，YOLO9000在识别种类、精度、速度、和定位准确性等方面都有大大提升。 BetterBatch NormalizationYOLO2取消了dropout，在所有的卷积层中加入Batch Normalization。 High Resolution ClassifierYOLO2将ImageNet以448×448 的分辨率微调最初的分类网络，迭代10 epochs。 Convolutional With Anchor Boxes借鉴faster R-CNN的思想，引入anchor box，取消全连接层来进行预测，改用卷积层作为预测层对anchor box的offset和confidence进行预测。去除了一个池化层，使得输出特征具有更高的分辨率，将图片输入尺寸resize为416而非448，使得特征图大小为奇数，所以有一个中心单元格。目标，特别是大目标，倾向于占据图像的中心，所以在中心有一个单一的位置可以很好的预测这些目标，而不是四个位置都在中心附近。YOLO的卷积层将图像下采样32倍，所以通过使用输入图像416，我们得到13×13的输出特征图。同时，使用anchor box进行预测的时候，解耦空间位置预测与类别预测，对每个anchor box都预测object和class，仍然沿用YOLO1，目标检测仍然是预测proposed box和ground truth的IOU，类别预测（class predictions）仍然是存在object下的条件概率。 Dimension ClustersYOLO2不再采用手动挑选的box尺寸，而是对训练集的box尺寸进行k-means聚类，因为聚类的目的是想要更好的IOU，所以聚类的距离使用下列公式： 对不同的k值采用k-means聚类算法，即对数据集的ground truth聚类，在VOC和COCO数据集上的bounding box得到的结果如下图： 根据上图，k=5的时候，模型的复杂度和IOU能够得到一个不错的trade off。 Direct location prediction对于位置坐标，YOLO2没有采用R-CNN的预测偏移，而是仍然类似于YOLO1中的，他预测相对于网格单元的位置坐标，将ground truth也限制在0-1之间，使用logistic activation 来实现。网络为每个边界框预测tx，ty，th，tw和to这5个坐标。如果网格单元从图像的左上角偏移（Cx，Cy），给定的anchor的宽度，高度分比为Pw，Ph那么预测结果为： Fine-Grained Features在13×13特征图上检测可以很容易检测到大目标，从更小粒度的特征图中可以更好地检测小物体，YOLO2添加一个passthrough layer从前一层26×26的特征图进行融合。传递层通过将相邻特征堆叠到不同的通道而不是堆叠到空间位置，将较高分辨率特征与低分辨率特征相连，类似于ResNet中的标识映射。这将26×26×512特征映射转换为13×13×2048特征映射，其可以与原始特征连接。 Multi-Scale Training添加anchor box后，YOLO2将分辨率更改为416×416。然而，由于模型只使用卷积层和池化层，它可以在运行中调整大小。为了使YOLOv2能够在不同大小的图像上运行，相比于固定输入图像大小，YOLO2每隔几次迭代更改网络。每迭代10个batch网络随机选择一个新的图像尺寸大小。因为模型以32的因子下采样，YOLO2从以下32的倍数中抽取：{320,352，…，608}。因此，最小的选项是320×320，最大的是608×608.调整网络的大小，并继续训练。这种训练方法迫使网络学习在各种输入维度上很好地预测。这意味着相同的网络可以预测不同分辨率的检测。网络在更小的尺寸下运行更快，因此YOLO2在速度和精度之间提供了一个简单的折衷。 FasterDarknet-19YOLO2大多数3×3的过滤器，并在每个池化步骤后将通道数量加倍，使用全局平均池进行预测，使用1×1滤波器以压缩3×3卷积之间的特征，最终模型，称为Darknet-19，有19卷积层和5个最大池化层，详见下图。 Training for classification使用Darknet19在标准ImageNet 1000类分类数据集上训练，在训练期间，使用数据增强技巧。 Training for detection为了训练检测器，修改上面的网络，移除最后的卷积层，添加3个3×3卷积层，最后增加1×1卷积层，其输出为我们需要的检测维度，如对于VOC数据集，预测5个box，每个具有5个坐标，每个box20个类，因此125个过滤器。还添加了从最后的3×3×512层到第二到最后的卷积层的传递层passthrough layer，使得模型可以使用细粒度特征。 Stronger构建了一种分层分类模型（WordTree），提出了一种关于分类和检测数据的联合训练机制。 ImageNet数据量更大，用于训练分类，COCO和VOC用于训练检测，ImageN对应分类有9000多种，COCO只有80种对应目标检测，通过wordTree来combine，来自分类的图片只计算分类的loss，来自检测集的图片计算完整的loss。 YOLO v3YOLO3 对于YOLO2有了一些改进，总的来说有几点：加深了网络，用了上采样，残差网络，多尺度预测，下面详细说明。 Bounding Box Prediction坐标预测仍然沿用YOLO2的，yolov3对每个bounding box预测四个坐标值(tx, ty, tw, th)，对于预测的cell根据图像左上角的偏移(cx, cy)，以及之前得到bounding box的宽和高pw, ph可以对bounding box按如下的方式进行预测： 训练的时候，loss的计算采用sum of squared error loss（平方和距离误差损失），yolov3对每个bounding box通过逻辑回归预测一个物体的得分，如果预测的这个bounding box与真实的边框值大部分重合且比其他所有预测的要好，那么这个值就为1.如果overlap没有达到一个阈值（yolov3中这里设定的阈值是0.5），那么这个预测的bounding box将会被忽略。YOLO3论文中使用的阈值是0.5.每个object只会分配一个bounding box，所以对应没有分配有ground truth object的box，其坐标损失和预测损失不需要计入，只需考虑objectness loss。If a bounding box prior is not assigned to a ground truth object it incurs no loss for coordinate or class predictions, only objectness. Class Prediction每个框预测分类，bounding box使用多标签分类（multi-label classification）。论文中说没有使用softmax分类，只是使用了简单的逻辑回归进行分类，采用的二值交叉熵损失（binary cross-entropy loss）。Each box predicts the classes the bounding box may contain using multilabel classification. We do not use a softmax as we have found it is unnecessary for good performance, instead we simply use independent logistic classifiers. During training we use binary cross-entropy loss for the class predictions.This formulation helps when we move to more complex domains like the Open Images Dataset. In this dataset there are many overlapping labels (i.e. Woman and Person). Using a softmax imposes the assumption that each box has exactly one class which is often not the case. A multilabel approach better models the data. Predictions Across ScalesYOLO3在三种不同尺度来预测box，应用一个类似于特征金字塔网络（feature pyramid network）上提取特征，如下图： 对于第一个scale的预测，即base feature extractor，最后预测得到一个3-d tensor，包含bounding box,objectness,class prediction.比如在COCO数据集中有80类物品，每一个scale预测3个box，所以tensor得到为（N×N×[3*(4+1+80)]）。next scale，从上一步2 layer previous的feature map中进行上采样，然后从特征提取网络中的取earlier feature 与上采样后的进行合并，得到更多信息的语义，以及从earlier feature map可以得到更细粒度的特征。最后的scale采用前述类似的方法进行。可能实际代码更能体现这个过程，如下：三种跨尺度预测 predict boxes at 3 different scales &apos;&apos;&apos; def build(self, feat_ex, res18, res10): self.conv52 = self.conv_layer(feat_ex, 1, 1, 1024, 512, True, &apos;conv_head_52&apos;) # 13x512 self.conv53 = self.conv_layer(self.conv52, 3, 1, 512, 1024, True, &apos;conv_head_53&apos;) # 13x1024 self.conv54 = self.conv_layer(self.conv53, 1, 1, 1024, 512, True, &apos;conv_head_54&apos;) # 13x512 self.conv55 = self.conv_layer(self.conv54, 3, 1, 512, 1024, True, &apos;conv_head_55&apos;) # 13x1024 self.conv56 = self.conv_layer(self.conv55, 1, 1, 1024, 512, True, &apos;conv_head_56&apos;) # 13x512 self.conv57 = self.conv_layer(self.conv56, 3, 1, 512, 1024, True, &apos;conv_head_57&apos;) # 13x1024 self.conv58 = self.conv_layer(self.conv57, 1, 1, 1024, 75, False, &apos;conv_head_58&apos;) # 13x75 # follow yolo layer mask = 6,7,8 self.conv59 = self.conv_layer(self.conv56, 1, 1, 512, 256, True, &apos;conv_head_59&apos;) # 13x256 size = tf.shape(self.conv59)[1] self.upsample0 = tf.image.resize_nearest_neighbor(self.conv59, [2*size, 2*size], # 上采样 name=&apos;upsample_0&apos;) # 26x256 self.route0 = tf.concat([self.upsample0, res18], axis=-1, name=&apos;route_0&apos;) # 26x768 self.conv60 = self.conv_layer(self.route0, 1, 1, 768, 256, True, &apos;conv_head_60&apos;) # 26x256 self.conv61 = self.conv_layer(self.conv60, 3, 1, 256, 512, True, &apos;conv_head_61&apos;) # 26x512 self.conv62 = self.conv_layer(self.conv61, 1, 1, 512, 256, True, &apos;conv_head_62&apos;) # 26x256 self.conv63 = self.conv_layer(self.conv62, 3, 1, 256, 512, True, &apos;conv_head_63&apos;) # 26x512 self.conv64 = self.conv_layer(self.conv63, 1, 1, 512, 256, True, &apos;conv_head_64&apos;) # 26x256 self.conv65 = self.conv_layer(self.conv64, 3, 1, 256, 512, True, &apos;conv_head_65&apos;) # 26x512 self.conv66 = self.conv_layer(self.conv65, 1, 1, 512, 75, False, &apos;conv_head_66&apos;) # 26x75 # follow yolo layer mask = 3,4,5 self.conv67 = self.conv_layer(self.conv64, 1, 1, 256, 128, True, &apos;conv_head_67&apos;) # 26x128 size = tf.shape(self.conv67)[1] self.upsample1 = tf.image.resize_nearest_neighbor(self.conv67, [2 * size, 2 * size], name=&apos;upsample_1&apos;) # 52x128 self.route1 = tf.concat([self.upsample1, res10], axis=-1, name=&apos;route_1&apos;) # 52x384 self.conv68 = self.conv_layer(self.route1, 1, 1, 384, 128, True, &apos;conv_head_68&apos;) # 52x128 self.conv69 = self.conv_layer(self.conv68, 3, 1, 128, 256, True, &apos;conv_head_69&apos;) # 52x256 self.conv70 = self.conv_layer(self.conv69, 1, 1, 256, 128, True, &apos;conv_head_70&apos;) # 52x128 self.conv71 = self.conv_layer(self.conv70, 3, 1, 128, 256, True, &apos;conv_head_71&apos;) # 52x256 self.conv72 = self.conv_layer(self.conv71, 1, 1, 256, 128, True, &apos;conv_head_72&apos;) # 52x128 self.conv73 = self.conv_layer(self.conv72, 3, 1, 128, 256, True, &apos;conv_head_73&apos;) # 52x256 self.conv74 = self.conv_layer(self.conv73, 1, 1, 256, 75, False, &apos;conv_head_74&apos;) # 52x75 # follow yolo layer mask = 0,1,2 return self.conv74, self.conv66, self.conv58 上面是最后的预测部分，需要输入的三个特征从Darknet-53网络中得到的，输出地方做了注释，Darknet-53网络结构如下： def build(self, img, istraining, decay_bn=0.99): self.phase_train = istraining self.decay_bn = decay_bn self.conv0 = self.conv_layer(bottom=img, size=3, stride=1, in_channels=3, # 416x3 out_channels=32, name=&apos;conv_0&apos;) # 416x32 self.conv1 = self.conv_layer(bottom=self.conv0, size=3, stride=2, in_channels=32, out_channels=64, name=&apos;conv_1&apos;) # 208x64 self.conv2 = self.conv_layer(bottom=self.conv1, size=1, stride=1, in_channels=64, out_channels=32, name=&apos;conv_2&apos;) # 208x32 self.conv3 = self.conv_layer(bottom=self.conv2, size=3, stride=1, in_channels=32, out_channels=64, name=&apos;conv_3&apos;) # 208x64 self.res0 = self.conv3 + self.conv1 # 208x64 self.conv4 = self.conv_layer(bottom=self.res0, size=3, stride=2, in_channels=64, out_channels=128, name=&apos;conv_4&apos;) # 104x128 self.conv5 = self.conv_layer(bottom=self.conv4, size=1, stride=1, in_channels=128, out_channels=64, name=&apos;conv_5&apos;) # 104x64 self.conv6 = self.conv_layer(bottom=self.conv5, size=3, stride=1, in_channels=64, out_channels=128, name=&apos;conv_6&apos;) # 104x128 self.res1 = self.conv6 + self.conv4 # 128 # 104x128 self.conv7 = self.conv_layer(bottom=self.res1, size=1, stride=1, in_channels=128, out_channels=64, name=&apos;conv_7&apos;) # 104x64 self.conv8 = self.conv_layer(bottom=self.conv7, size=3, stride=1, in_channels=64, out_channels=128, name=&apos;conv_8&apos;) # 104x128 self.res2 = self.conv8 + self.res1 # 128 # 104x128 self.conv9 = self.conv_layer(bottom=self.res2, size=3, stride=2, in_channels=128, out_channels=256, name=&apos;conv_9&apos;) # 52x256 self.conv10 = self.conv_layer(bottom=self.conv9, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_10&apos;) # 52x128 self.conv11 = self.conv_layer(bottom=self.conv10, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_11&apos;) # 52x256 self.res3 = self.conv11 + self.conv9 # 52x256 self.conv12 = self.conv_layer(bottom=self.res3, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_12&apos;) # 52x128 self.conv13 = self.conv_layer(bottom=self.conv12, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_13&apos;) # 52x256 self.res4 = self.conv13 + self.res3 # 52x256 self.conv14 = self.conv_layer(bottom=self.res4, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_14&apos;) # 52x128 self.conv15 = self.conv_layer(bottom=self.conv14, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_15&apos;) # 52x256 self.res5 = self.conv15 + self.res4 # 52x256 self.conv16 = self.conv_layer(bottom=self.res5, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_16&apos;) # 52x128 self.conv17 = self.conv_layer(bottom=self.conv16, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_17&apos;) # 52x256 self.res6 = self.conv17 + self.res5 # 52x256 self.conv18 = self.conv_layer(bottom=self.res6, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_18&apos;) # 52x128 self.conv19 = self.conv_layer(bottom=self.conv18, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_19&apos;) # 52x256 self.res7 = self.conv19 + self.res6 # 52x256 self.conv20 = self.conv_layer(bottom=self.res7, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_20&apos;) # 52x128 self.conv21 = self.conv_layer(bottom=self.conv20, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_21&apos;) # 52x256 self.res8 = self.conv21 + self.res7 # 52x256 self.conv22 = self.conv_layer(bottom=self.res8, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_22&apos;) # 52x128 self.conv23 = self.conv_layer(bottom=self.conv22, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_23&apos;) # 52x256 self.res9 = self.conv23 + self.res8 # 52x256 self.conv24 = self.conv_layer(bottom=self.res9, size=1, stride=1, in_channels=256, out_channels=128, name=&apos;conv_24&apos;) # 52x128 self.conv25 = self.conv_layer(bottom=self.conv24, size=3, stride=1, in_channels=128, out_channels=256, name=&apos;conv_25&apos;) # 52x256 self.res10 = self.conv25 + self.res9 # 52x256 一个输出的特征尺度 self.conv26 = self.conv_layer(bottom=self.res10, size=3, stride=2, in_channels=256, out_channels=512, name=&apos;conv_26&apos;) # 26x512 self.conv27 = self.conv_layer(bottom=self.conv26, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_27&apos;) # 26x256 self.conv28 = self.conv_layer(bottom=self.conv27, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_28&apos;) # 26x512 self.res11 = self.conv28 + self.conv26 # 26x512 self.conv29 = self.conv_layer(bottom=self.res11, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_29&apos;) # 26x256 self.conv30 = self.conv_layer(bottom=self.conv29, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_30&apos;) # 26x512 self.res12 = self.conv30 + self.res11 # 26x512 self.conv31 = self.conv_layer(bottom=self.res12, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_31&apos;) # 26x256 self.conv32 = self.conv_layer(bottom=self.conv31, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_32&apos;) # 26x512 self.res13 = self.conv32 + self.res12 # 26x512 self.conv33 = self.conv_layer(bottom=self.res13, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_33&apos;) # 26x256 self.conv34 = self.conv_layer(bottom=self.conv33, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_34&apos;) # 26x512 self.res14 = self.conv34 + self.res13 # 26x512 self.conv35 = self.conv_layer(bottom=self.res14, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_35&apos;) # 26x256 self.conv36 = self.conv_layer(bottom=self.conv35, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_36&apos;) # 26x512 self.res15 = self.conv36 + self.res14 # 26x512 self.conv37 = self.conv_layer(bottom=self.res15, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_37&apos;) # 26x256 self.conv38 = self.conv_layer(bottom=self.conv37, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_38&apos;) # 26x512 self.res16 = self.conv38 + self.res15 # 26x512 self.conv39 = self.conv_layer(bottom=self.res16, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_39&apos;) # 26x256 self.conv40 = self.conv_layer(bottom=self.conv39, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_40&apos;) # 26x512 self.res17 = self.conv40 + self.res16 # 26x512 self.conv41 = self.conv_layer(bottom=self.res17, size=1, stride=1, in_channels=512, out_channels=256, name=&apos;conv_41&apos;) # 26x256 self.conv42 = self.conv_layer(bottom=self.conv41, size=3, stride=1, in_channels=256, out_channels=512, name=&apos;conv_42&apos;) # 26x512 self.res18 = self.conv42 + self.res17 # 26x512，一个输出的特征尺度 self.conv43 = self.conv_layer(bottom=self.res18, size=3, stride=2, in_channels=512, out_channels=1024, name=&apos;conv_43&apos;) # 13x1024 self.conv44 = self.conv_layer(bottom=self.conv43, size=1, stride=1, in_channels=1024, out_channels=512, name=&apos;conv_44&apos;) # 13x512 self.conv45 = self.conv_layer(bottom=self.conv44, size=3, stride=1, in_channels=512, out_channels=1024, name=&apos;conv_45&apos;) # 13x1024 self.res19 = self.conv45 + self.conv43 # 13x1024 self.conv46 = self.conv_layer(bottom=self.res19, size=1, stride=1, in_channels=1024, out_channels=512, name=&apos;conv_46&apos;) # 13x512 self.conv47 = self.conv_layer(bottom=self.conv44, size=3, stride=1, in_channels=512, out_channels=1024, name=&apos;conv_47&apos;) # 13x1024 self.res20 = self.conv47 + self.res19 # 13x1024 self.conv48 = self.conv_layer(bottom=self.res20, size=1, stride=1, in_channels=1024, out_channels=512, name=&apos;conv_48&apos;) # 13x512 self.conv49 = self.conv_layer(bottom=self.conv48, size=3, stride=1, in_channels=512, out_channels=1024, name=&apos;conv_49&apos;) # 13x1024 self.res21 = self.conv49 + self.res20 # 13x1024 self.conv50 = self.conv_layer(bottom=self.res21, size=1, stride=1, in_channels=1024, out_channels=512, name=&apos;conv_50&apos;) # 13x512 self.conv51 = self.conv_layer(bottom=self.conv50, size=3, stride=1, in_channels=512, out_channels=1024, name=&apos;conv_51&apos;) # 13x1024 self.res23 = self.conv51 + self.res21 # 13x1024 return self.res23 # 最后输出特征 同样采用k-means聚类的到anchor box的尺寸。选取了9种，3中不同的scale：(10×13); (16×30); (33×23); (30×61); (62×45); (59×119); (116 × 90); (156 × 198); (373 × 326). Feature ExtractorYOLO3的新的更深的网络，Darknet-53，实现细节可参见上面的代码]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PCL的python库安装for Ubuntu16.04]]></title>
    <url>%2F2018%2F05%2F11%2FPCL%E7%9A%84python%E5%BA%93%E5%AE%89%E8%A3%85for-Ubuntu16-04%2F</url>
    <content type="text"><![CDATA[PCL（Point Cloud Library）是包含各种点云算法的大型跨平台开源C++编程库，是吸纳了大量点云相关算法，包括点云获取、滤波、分割、特征提取、曲面重建以及可视化等各种算法，然而现在我主要使用的是python语言，网上目前又有公布的python_pcl实现库python_pcl实现库 ，然而针对Ubuntu16.04按照官方给的方法没有能够实现安装，踩了无数坑之后，博客记录一种简单且成功安装的方法。 PCL安装不用编译源码，一行命令直接apt安装，顺带安装各种依赖的乱七八糟的库 sudo apt-get install libpcl-dev 再安装一些pcl可视化等软件包 sudo apt-get install pcl_tools 安装 python_pcl首先下载python_pcl源文件 git clone https://github.com/strawlab/python-pcl.git 编译、安装 python setup.py build_ext -i python setup.py install 在此之前常出现的一个编译问题是cython版本问题，所以在执行上一步之前首先： pip install cython==0.25.2 解决常出现的链接失败的问题由于我的默认python为anaconda3的python，可能是anaconda3自带的链接库的问题，所以出现了如下错误： ./lib/libgomp.so.1: version `GOMP_4.0&apos; not found (required by /home/lkj/anaconda3/lib/python3.5/site-packages/xgboost-0.6-py3.5.egg/xgboost/libxgboost.so) 上面的意思是anaconda3/lib/libgomp.so.1中没有‘GOMP_4.0’，这个可以使用strings命令查看libgomp.so.1这个文件，显示并无4.0版本，因此寻找其他路径的链接库替代，用locate命令搜索系统中所有的libgomp.so.1，得到：然后用strings查看这些文件信息， /usr/lib/x86_64-linux-gnu/libgomp.so.1 |grep GOMP 发现x86_64-linux-gnu/libgomp.so.1包含GOMP_4.0因此可以删掉原有的libgomp.so.1，重新做一个新的链接。 ln -s /usr/lib/x86_64-linux-gnu/libgomp.so.1 libgomp.so.1 然后再次在python里面import pcl,又提示libstdc++.so.6出现类似的问题，对上述做类似处理，如果还有链接库的问题，也可以用同样的方法处理,至此实现了python的pcl库安装。]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于深度学习的目标检测技术学习笔记(R-CNN系列)]]></title>
    <url>%2F2018%2F04%2F20%2F%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0(R-CNN%E7%B3%BB%E5%88%97)%2F</url>
    <content type="text"><![CDATA[图像的目标检测（object detection）主要包括两个任务，一是要标注出目标物体的位置（localization），而是要识别出目标物体的类别（classification）。通俗来说，就是解决图像中多个目标在哪里，是什么的一个问题。这个问题的涉及，主要是目前参加了天池大赛的一个目标识别方面的问题，所以阅读了一些相关方面的文献，在此做一个学习总结，主要来介绍R-CNN（Regions with CNN features）系列的算法。 传统的目标检测算法一般是基于滑动窗口选中图中的某一部分作为候选区域，然后提取候选区域的特征，利用分类器（如常见的SVM)进行识别。2014年提出的region proposal+CNN代替传统目标检测使用的滑动窗口+特征工程的方法，设计了R-CNN算法，开启了基于深度学习的目标检测的大门。 R-CNN R-CNN算法流程为： 输入图像，根据SS（selective search）算法提取2000个左右的region proposal（候选框） 将候选框crop/wrap为固定大小后输入CNN中，得到固定维度的输出特征 对提取的CNN特征，利用SVM分类器分类得到对应类别 边界回归（bouding-box regression），用线性回归模型修正候选框的位置 R-CNN使得识别的精度和速度都有了提升，但是也存在很大问题，每次候选框都需要经过CNN操作，计算量很大，有很多重复计算；训练步骤繁多。 Fast R-CNNR-CNN需要每次将候选框resize到固定大小作为CNN输入，这样有很多重复计算。SPP-net的主要思想是去掉了原始图像上的crop/warp等操作，换成了在卷积特征上的空间金字塔池化层（Spatial Pyramid Pooling，SPP）。 SPP Net对整幅图像只进行一次CNN操作得到特征图，这样原图中的每一个候选框都对应于特征图上大小不同的某一区域，通过SPP可以将这些不同大小的区域映射为相同的维度，作为之后的输入，这样就能保证只进行一次CNN操作了。SPP包含一种可伸缩的池化层，输出固定尺寸特征。 基于SPP的思想，Fast R-CNN加入了一个ROI Pooling，将不同大小输入映射到一个固定大小的输出。R-CNN之前的操作是目标识别（classification）以及边界回归（bouding-box regression）分开进行。Fast R-CNN做的改进就是将这两个过程合并在一起，这两个任务共享CNN特征图，即成为了一个multi-task模型。 多任务自然对应multi-loss，损失函数包括分类误差以及边框回归误差。Lcls为分类误差： 分类误差只考虑对应的类别被正确分类到的概率，即Pl为label对应的概率，当Pl=1时，Loss为0，即正确分类的概率越大，loss越小。 Lreg为边框回归误差： 对预测的边框四个位置描述参数与真实分类对应边框的四个参数偏差进行评估作为损失函数，g函数为smooth L1函数，这样对于噪声点不敏感，鲁棒性强，在|x|&gt;1时，变为线性，降低噪声影响。 这样加权得到的最终损失函数为： foreground理解为前景，即对应有目标物体，这个时候需要考虑边框回归误差；background为背景，没有包含目标物品，所以不需考虑边框回归误差。 Faster R-CNNFaster R-CNN对Fast R-CNN又进行了改进，使得Faster。主要是将候选框的选取也引入到网络中，代替了之前SS选取候选框的方式，即引入了RPN（Region Proposal Network），将找候选框的工作也交给了神经网络了。 提到RPN网络，就不能不说anchors，即锚点，对应的是一组矩形框，在实际中有3种形状width:height = [1:1, 1:2, 2:1]，对应3种尺寸，所以共计9个矩形框。 这个矩形框对应的是原始输入图像里面的，并非是卷积特征图上的。即对卷积特征图上每一个点，可以对应原始图上的一个anchors，为其配备9个框作为原始检测框，当然一开始肯定是不准确的，可以在后续的bounding box regression修正检测框位置。 为了生成区域建议框，在最后一个共享的卷积层输出的卷积特征映射上滑动小网络，这个网络全连接到输入卷积特征映射的nxn的空间窗口上。每个滑动窗口映射到一个低维向量上（对于ZF最后卷积层的输出是256channel，即生成256张特征图，所以小网络滑窗在特征图上的点生成向量是256-d，对于VGG是512-d，每个特征映射的一个滑动窗口对应一个数值）。这个向量输出给两个同级的全连接的层——包围盒回归层（reg）和包围盒分类层（cls）。论文中n=3，由于小网络是滑动窗口的形式，所以全连接的层（nxn的）被所有空间位置共享（指所有位置用来计算内积的nxn的层参数相同）。这种结构实现为nxn的卷积层，后接两个同级的1x1的卷积层（分别对应reg和cls）。在每一个滑动窗口的位置，我们同时预测k个区域建议，所以reg层有4k个输出，即k个box的坐标编码。cls层输出2k个得分，即对每个建议框是目标/非目标的估计概率（为简单起见，是用二类的softmax层实现的cls层，还可以用logistic回归来生成k个得分）。k个建议框被相应的k个称为anchor的box参数化。每个anchor以当前滑动窗口中心为中心，并对应一种尺度和长宽比，我们使用3种尺度和3种长宽比，这样在每一个滑动位置就有k=9个anchor。对于大小为WxH（典型值约2,400）的卷积特征映射，总共有WHk个anchor。 Faster R-CNN的损失函数为： 这里，i是一个mini-batch中anchor的索引，Pi是anchor i是目标的预测概率。如果anchor为正，Pi 就是1，如果anchor为负，Pi 就是0。ti是一个向量，表示预测的包围盒的4个参数化坐标，ti是与正anchor对应的GT（groundtruth）包围盒的坐标向量。Pi Lreg这一项意味着只有正anchor（Pi =1）才有回归损失，其他情况就没有（Pi =0）。cls层和reg层的输出分别由{pi}和{ti}组成，这两项分别由Ncls和Nreg*以及一个平衡权重λ归一化。边框回归损失函数，用采取类似fast R-CNN介绍的方法。具体地，学习的时候，对于四个参数进行如下处理： x，y，w，h指的是包围盒中心的（x,y）坐标、宽、高。变量x，xa，x* 分别指预测的包围盒、anchor的包围盒、GT的包围盒（对y，w，h也是一样）的x坐标，可以理解为从anchor包围盒到附近的GT包围盒的包围盒回归。 Fast R-CNN训练依赖于固定的目标建议框，而Faster R-CNN中的卷积层是共享的，所以RPN和Fast R-CNN都不能独立训练，论文中提出的是4步训练算法，通过交替优化来学习共享的特征。 训练RPN，该网络用ImageNet预训练的模型初始化，并端到端微调用于区域建议任务。 利用第一步的RPN生成的建议框，由Fast R-CNN训练一个单独的检测网络，这个检测网络同样是由ImageNet预训练的模型初始化的，这时候两个网络还没有共享卷积层。 用检测网络初始化RPN训练，但我们固定共享的卷积层，并且只微调RPN独有的层，现在两个网络共享卷积层了。 保持共享的卷积层固定，微调Fast R-CNN的fc层。这样，两个网络共享相同的卷积层，构成一个统一的网络。]]></content>
      <tags>
        <tag>深度学习</tag>
        <tag>目标检测</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NHD自动登陆签到脚本]]></title>
    <url>%2F2018%2F03%2F05%2FNHD%E8%87%AA%E5%8A%A8%E7%99%BB%E9%99%86%E7%AD%BE%E5%88%B0%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[到现在做过很多爬虫的小玩意，今天用爬虫来做一个更实际的东西。学校内部有个电影资源分享网站NHD，虽然说是免费下载，但是需要消耗魔力值，魔力值可以通过每天签到获得，连续签到的话每天得到的魔力值数量是可观的，但是有时候会忘了签到，因此写了一个小程序来实现每天自动登陆NHD并实现自动签到。 首先还是老套路，先用浏览器实现一遍登陆以及签到过程，用谷歌浏览器的开发者模式获取这过程中的信息。可以看到首次登陆之后，response的header有set-cookie字段 而后这个服务器返回的set-cookie字段的值在下一次会话中又出现了 其实总体思路还是很简单的，与之前的爬虫不同，这次需要用户登陆，所以是POST方法，并将用户名和密码以data参数代入，登陆之后服务器会返回cookie来标识用户。因为http是一种无状态协议，用户首次访问web站点的时候，服务器对用户一无所知。而Cookie就像是服务器给每个来访问的用户贴的标签，而这些标签就是对来访问的客户端的独有的身份的一个标识，这里就如同每个人的身份证一样，带着你的个人信息。而当一个客户端第一次连接过来的时候，服务端就会给他打一个标签，这里就如同给你发了一个身份证，所以之后的访问服务器再带上这个cookie就标识了该账户，具体流程网上找到一张很好的图可以解释。 这样的话，只需要第一次输入密码，后面浏览器再次访问只要带上这个服务器返回的cookie，服务器就可以知道是该账户在访问，所以python程序也模拟该过程。利用request库中的session对象来创建类似于图中的过程，session对象会保存访问过程中的cookie用于之后对服务器的继续访问。 url = &apos;http://www.nexushd.org/takelogin.php&apos; #登陆界面 a = session.post(url=url, cookies=cookies, headers=headers, data=data) #这里的cookie是浏览器首次访问的使用的cookie，之后服务器 #设置的cookie会保存在session对象中 time.sleep(2) url2 = &apos;http://www.nexushd.org/signin.php&apos; #签到界面 b = session.get(url=url2, headers=headers) time.sleep(2) url3 = &apos;http://www.nexushd.org/signin.php?&apos; qiandao = {&apos;action&apos;:&apos;post&apos;,&apos;content&apos;:&apos;lalala2333&apos;} #签到信息随便填，lalala2333 r = session.post(url=url3, headers=headers, data=qiandao) 而后就是一个判断是否登陆成功的程序，依然使用BeautifulSoup来解析，得到已签到之后退出循环，并将日志信息记录到日志文件。 r = session.post(url=url3, headers=headers, data=qiandao) r = BeautifulSoup(r.content,&apos;lxml&apos;) message1 = r.find_all(&apos;a&apos;,{&apos;href&apos;:&quot;signin.php&quot;})[0].contents[0] message2 = r.find_all(&apos;h2&apos;)[0].getText() if message2 == &apos;签到成功&apos;: f = codecs.open(&apos;logging.txt&apos;, &apos;a&apos;, encoding=&apos;utf-8&apos;) str = time.strftime(&apos;%Y-%m-%d %H:%M:%S&apos;, time.localtime(time.time())) + &apos;-----签到成功&apos; + &apos;\n&apos; f.write(str) # 记录日志信息到日志文件 f.close() print(r.find_all(&apos;span&apos;, {&apos;class&apos;: &apos;medium&apos;})[0].getText()) print(r.find_all(&apos;td&apos;, {&apos;class&apos;: &apos;text&apos;})[-1].getText().split(&apos;。&apos;)[0]) break elif message1 == &apos;已签到&apos;: #如果已经签到 print(&apos;已经签到过了哦&apos;) break if maxtry &lt; 30: print(&apos;签到失败，第&apos;+str(maxtry+1)+&apos;次重试&apos;) maxtry = maxtry+1 time.sleep(5) else: print(&quot;自动签到失败，请手动签到，或者检查网络连接&quot;) break 为了能够开机自动运行程序，将该程序添加至windows启动运行。代码中读取在配置文件中的账户信息，并且通过读取上一次签到成功时间来判断是否成功签到过。 maxtry=0 #记录重试次数 f = codecs.open(&apos;profile.txt&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) #读取配置文件，包含账户及密码 line=f.readline() f.close() username = line.split()[0] #你的用户名 password = line.split()[1] #你的密码 data = {&apos;username&apos;: username, &apos;password&apos;:password} flag = True day_now = time.localtime(time.time()).tm_mday f = codecs.open(&apos;logging.txt&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) lines = f.readlines() f.close() #######更换账户登陆时，最好清除以前账户的日志信息 try: #如果第一次使用可能没有签到记录 day_log = int(lines[-1].split()[0].split(&apos;-&apos;)[-1]) except: day_log=33 day_log = int(lines[-1].split()[0].split(&apos;-&apos;)[-1]) if day_now == day_log: print(username+&apos;今天签到过了哦&apos;) flag = False 将配置文件profile.txt和日志文件logging.txt以及代码qiandao.py放入windows的启动运行的文件夹，这个文件夹可以通过在cmd窗口下输入 shell:Startup 打开 在这个启动文件夹下写一个bat脚本来运行python代码 D: cd D:\simulation file\pyCharm\python3\qiandao python qiandao.py pause 至此就完整实现了电脑开机自动登陆签到NHD啦。效果如下测试结果： 完整代码详见个人github了。]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我从崖边跌落]]></title>
    <url>%2F2018%2F02%2F12%2F%E6%88%91%E4%BB%8E%E5%B4%96%E8%BE%B9%E8%B7%8C%E8%90%BD%2F</url>
    <content type="text"><![CDATA[我从崖边跌落落入星空辽阔银河不清不浊不知何以摆脱 谢春花《我从崖边跌落》]]></content>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电影推荐系统构建]]></title>
    <url>%2F2018%2F01%2F11%2F%E7%94%B5%E5%BD%B1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[很久没有更新博客了，最近刚做完数据挖掘的大作业，选了一个电影数据集挖掘的课题，做了一个推荐系统，在这里简单地记录一下。电影推荐系统数据集来源于kaggle上的MovieLens完整的45,000条数据，电影数据包括2017年7月前发布的电影，包括270,000个用户的超过26,000,000条评论，以及从GroupLens官方网站获得的评分。基于此电影数据集，完成下面的数据挖掘目标。• 电影数据集处理及可视化分析• 基于用户投票的推荐算法• 基于内容的推荐算法• 基于协同过滤的推荐算法• 数据库技术的应用• 简单的电影推荐网站构建当然这次代码也有很大程度上参考了这个数据集下的大佬分享的kernel，提供了许多不错的精致代码。 数据集介绍及分析movies_metadata.csv: 电影基本信息描述文件，包括 45000部电影的演员、工作人员、情节关键字、预算、收入、海报、发布日期、语言、制作公司、国家、TMDB投票计数和平均投票信息.keywords.csv: 包含电影的关键词信息，每条数据为json格式.。credits.csv: 演员和电影工作人员的信息，每条数据为json格式。links.csv: 包含所有电影TMDB IDs和IMDB IDs 对应信息。links_small.csv: 9,000部电影的TMDB IDs和IMDB IDs 对应信息.rating.csv:用户对于所有电影的打分，1-5。ratings_small.csv: 电影打分子集，700个用户对于9,000部电影的100,000个评分。针对电影的情况，首先我们看一下电影的平均投票分布，如下图所示，由图中可以看出，电影集中分布在6分左右，也是比较符合实际情况，一般的电影居多，高分电影以及烂片数量相对较少。 %matplotlib inline import pandas as pd import numpy as np import warnings warnings.filterwarnings(&apos;ignore&apos;) import matplotlib.pyplot as plt import seaborn as sns df = pd.read_csv(&apos;movies_metadata.csv&apos;) df[&apos;vote_average&apos;] = df[&apos;vote_average&apos;].replace(0, np.nan) sns.distplot(df[&apos;vote_average&apos;].fillna(df[&apos;vote_average&apos;].median())) df[&apos;year&apos;] = pd.to_datetime(df[&apos;release_date&apos;], errors=&apos;coerce&apos;).apply(lambda x: str(x).split(&apos;-&apos;)[0] if x != np.nan else np.nan) year_gen = pd.DataFrame(df[&apos;year&apos;].value_counts()).reset_index() year_gen.columns = [&apos;year&apos;, &apos;counts&apos;] year_gen.drop([87,135,],inplace=True) year_gen[&apos;year&apos;]=year_gen[&apos;year&apos;].astype(&apos;int&apos;) plt.plot(year_gen.year,year_gen.counts) 从上图中的电影分布可以看出，从1880年左右以来，电影的数量基本上是逐年增长的趋势，特别是进入21实际以来，增长速度很快（出现一段下降是因为2017年的完整数据收集不完整）。下面再分析数据集中的电影的区域分布，利用一个比较强的可视化工具plotly，画出电影数量的区域分布，因为美国的电影产出相对其他国家高出太多，所以画图是先忽略了美国，这样画其他国家的数量之间的比较才会更加明显。 data = [ dict( type = &apos;choropleth&apos;, locations = con_df[&apos;country&apos;], locationmode = &apos;country names&apos;, z = con_df[&apos;num_movies&apos;], text = con_df[&apos;country&apos;], colorscale = [[0,&apos;rgb(255, 255, 255)&apos;],[1,&apos;rgb(255, 0, 0)&apos;]], autocolorscale = False, reversescale = False, marker = dict( line = dict ( color = &apos;rgb(180,180,180)&apos;, width = 0.5 ) ), colorbar = dict( autotick = False, tickprefix = &apos;&apos;, title = &apos;数量图例&apos;), ) ] layout = dict( title = &apos;电影数据集中电影数量分布（除美国外）&apos;, geo = dict( showframe = False, showcoastlines = False, projection = dict( type = &apos;Mercator&apos; ) ) ) fig = dict( data=data, layout=layout ) py.iplot( fig, validate=False, filename=&apos;d3-world-map&apos; ) plt.figure(figsize=(12,5)) sns.barplot(x=&apos;country&apos;, y=&apos;num_movies&apos;, data=country) plt.show() ####除去美国外，英国。法国、德国、意大利，亚洲的日本和印度，北美的巴西 推荐系统构建在这次推荐系统的构建中，我们采用了三种算法来构建我们的推荐系统，基于这三种算法，包括基于用户投票的推荐算法、基于内容的推荐算法和协同过滤推荐算法，根据这些算法，最终来构建我们的电影推荐系统。 基于用户投票的推荐算法作为国际知名的权威点评网站，在他们大名鼎鼎的TOP250榜单中，采用的就是贝叶斯算法，其公式如下： 其中，WR为加权得分，R为该电影的用户投票平均得分，V为该电影的投票人数，m为最低评分个数，C为所有电影的平均得分。这个算法的提出基于这样一个现实问题：热门电影与冷门电影的平均得分，是否真的可比？举例来说，一部好莱坞大片有10000个观众投票，一部小成本的文艺片只有100个观众投票。这两者的投票结果，怎么比较？如果使用”威尔逊区间”，后者的得分将被大幅拉低，这样处理是否公平，能不能反映它们真正的质量？一个合理的思路是，如果要比较两部电影的好坏，至少应该请同样多的观众观看和评分。既然文艺片的观众人数偏少，那么应该设法为它增加一些观众。 根据这个思路，这个算法相当于给每部电影增加了m个选票，并且每个评分为平均得分C，然后用现有观众的投票进行修正，即v*R/(v+m)部分，使得得分更加接近于真实情况。这种算法由于给每部电影增加了m个选票，拉近了不同电影之间投票人数的差异，使得投票人数较少的电影也有可能名列前茅。 这个算法借鉴了“贝叶斯推断”的思想，既然不知道投票结果，那就预先估计一个值，然后不断用新的信息修正，使它接近于正确值。在式子中，m可以看作是先验概率，每一次新的投票都是一个调整因子，使总体平均分不断向该项目的真实投票结果靠近。投票人数越多，该项目的”贝叶斯平均”就越接近算术平均，对排名的影响就越小。因此这种方法可以让投票较少的项目，能够得到相对公平的排名。 我们针对所有电影，类似于IMDB我们计算出了TOP250，下图为基于贝叶斯统计的用户投票排名算法得出的所有电影的TOP250中选取出的TOP10，其中电影名红色的为实际IMDB中进入TOP10的电影，可以看出有3部电影存在于IMDB的TOP10，绿色标注的电影为TOP11-15的电影，有3部。总的来说，贝叶斯统计得出的排名还是比较接近于IMDB的排名，但是由于我们的算法考虑的因素较少，所以还是有一定的区别。 进一步的，我们从电影数据集中，根据电影的genre属性值中，分离出电影所属的不同属性，所有电影的类型分布（TOP10）如下图所示 可以看出，电影数据集中戏剧、喜剧、恐怖片、爱情片等数量较多，依次数量排名.针对数量超过3000的电影，我们也采取类似的方式计算了TOP250，部分电影类型的TOP10在下图中给出。 基于内容的推荐算法基于投票排名的推荐算法给每个用户都是一样推荐按照TOP排名得出的电影，而不会根据特定的观众喜欢的电影去推荐相似的电影。为了能够给用户推荐相似的电影，我们首先需要对电影之间的相似性进行衡量，主要应用到电影的描述数据来完成基于内容的推荐，主要的实现过程包括：• 对电影的关键词、描述信息、标语、主角、导演信息的提取• 对上述信息进行词干提取• 对上述信息进行特征抽取，转换成词向量• 考虑评分情况，结合相似度完成推荐首先我们对于电影的相关描述信息进行一个大致分析，制作了词云对所有电影的情况概览。 df[&apos;title&apos;] = df[&apos;title&apos;].astype(&apos;str&apos;) df[&apos;overview&apos;] = df[&apos;overview&apos;].astype(&apos;str&apos;) title_corpus = &apos; &apos;.join(df[&apos;title&apos;]) overview_corpus = &apos; &apos;.join(df[&apos;overview&apos;]) from wordcloud import WordCloud, STOPWORDS title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color=&apos;white&apos;, height=2000, width=4000).generate(title_corpus) plt.figure(figsize=(16,8)) plt.imshow(title_wordcloud) plt.axis(&apos;off&apos;) plt.show() overview_wordcloud = WordCloud(stopwords=STOPWORDS, background_color=&apos;white&apos;, height=2000, width=4000).generate(overview_corpus) plt.figure(figsize=(16,8)) plt.imshow(overview_wordcloud) plt.axis(&apos;off&apos;) plt.show() 上面两幅图分别是电影的标题和电影简述画出的词云，可以看到电影标题中Love、Girl、Man、Life，Love作为最高频的词，毕竟大多数电影都有爱情这条线。在电影的简述中，find、life、one是最高频的词，可以给我们反映大多数电影的主题。 在获得电影的关键词、描述信息、标语、主角、导演信息之后，我们需要对这些信息进行词干提取。在语言形态学和信息检索里，词干提取是去除词缀得到词根的过程，即得到单词最一般的写法。计算机科学领域有很多词干提取的相应算法，我们使用了一个面向英语的词干提取器stemming，使用Python的NLTK库的stemming算法，实现的效果为要识别字符串“cats”、“catlike”和“catty”提取出词根“cat”；“stemmer”、“stemming”和“stemmed”提取出词根“stem”。 from nltk.stem.snowball import SnowballStemmer stemmer = SnowballStemmer(&apos;english&apos;) #英语的词干提取 下一步需要将提取词干后的文档进行向量化处理，采用的是sklearn中的Countvectorizer。根据语料库中的词频排序从高到低进行选择，词汇表的最大含量由vocabsize超参数来指定，超参数minDF，则指定词汇表中的词语至少要在多少个不同文档中出现次数，产生文档关于词语的稀疏表示，在fitting过程中，countvectorizer将根据语料库中的词频排序选出前vocabsize个词，输出词向量。 count = CountVectorizer(analyzer=&apos;word&apos;,ngram_range=(1, 2),min_df=0, stop_words=&apos;english&apos;) count_matrix = count.fit_transform(smd[&apos;soup&apos;]) #基于词向量统计的矩阵 当然，基于内容的推荐算法还需要考虑到电影的评分，不然仅仅根据电影之间的相似度，很有可能就会出现给观众推荐很相似的电影，但却是“烂片”的这种情况，基于这种考虑，以电影《The Godfather》（教父）以及《The Lord of the Rings: The Return of the King》（指环王：王者归来）为例，推荐的相应10部电影结果如下图所示。 可以看到，都推荐了同类型的电影，比如针对教父推荐了一些剧情、犯罪电影，而针对指环王推荐了一些动作、奇幻类的电影，而且这两部电影都有其他续集，比如针对《教父1》推荐了其续集《教父2》及《教父3》也都相应地推荐了，推荐的电影也都是高分电影. 协同过滤推荐从应用的场景来看，基于内容的推荐算法更多地适用于用户根据关键字或者电影名字来搜索相应的电影，然后推荐系统来进行相应的推荐。基于需求个性角度来看，基于内容的推荐算法还不够个人化，用户需要的是更加符合个人偏好的推荐结果，可以根据用户之前的打分情况，更有针对性地推荐一些可能喜欢的电影，这种情况下，应用的最多的就是协同过滤算法。 协同过滤通过用户和产品及用户的偏好信息产生推荐策略，最基本的策略有两种：一种是找到具有类似品味的人所喜欢的物品；另一种是从一个人喜欢的物品中找出类似的物品，即基于用户的推荐技术（User CF）和基于物品的推荐技术（Item CF）。在我们这个应用场景中，有大量的电影信息，但是用户已经打分的电影只占总量很少的一部分，将用户打分和电影信息构成一个矩阵，那么这个矩阵会存在严重的稀疏性，经过计算大约在1.5%左右，基于这种考虑，我们采取Item-based协同过滤算法。同样由于矩阵的稀疏性，在数据量很大的情况下一般采用矩阵分解来减少运算量，采用PMF矩阵分解算法来完成这个目标。 采用的是surprise库中的SVD算法，但是我看了surprise库中的SVD算法介绍，其实更准确地说是PMF（Probabilistic Matrix Factorization）算法，即概率矩阵分解算法，所以这里对PMF进行相应的介绍。 假定每个用户u都有一个D维的向量，表示他对不同风格的电影的偏好，每个电影i也有一个D维的向量表示不同风格的用户对它的偏好。 于是电影的评分矩阵可以这样来估计： p 和q就是D维的向量。用梯度下降法训练p和q，迭代几十次就收敛了。但是这样的SVD很容易就过拟合，所以需要加入正则化项： 这样每次迭代的时候，更新公式为： 采用5折交叉验证 import pandas as pd import numpy as np from surprise import Reader, Dataset, SVD, evaluate from collections import defaultdict import warnings; warnings.simplefilter(&apos;ignore&apos;) reader = Reader() ratings = pd.read_csv(&apos;ratings_small.csv&apos;) #从DataFrame导入数据 data = Dataset.load_from_df(ratings[[&apos;userId&apos;, &apos;movieId&apos;, &apos;rating&apos;]], reader) data.split(n_folds=5) trainset = data.build_full_trainset() #SVD算法 algo = SVD() evaluate(algo, data, measures=[&apos;RMSE&apos;, &apos;MAE&apos;]) #训练模型 algo.train(trainset) #对用户未评价的电影生成测试集 testset = trainset.build_anti_testset() predictions = algo.test(testset) #预测测试集结果 def get_top_n(predictions, n=10): &apos;&apos;&apos;对预测结果中的每个用户，返回n部电影，默认n=10 返回值一个字典，包括： keys 为原始的userId，以及对应的values为一个元组 [(raw item id, rating estimation), ...]. &apos;&apos;&apos; # 预测结果取出，对应每个userId. top_n = defaultdict(list) for uid, iid, true_r, est, _ in predictions: top_n[uid].append((iid, est)) # 排序取出前n个 for uid, user_ratings in top_n.items(): user_ratings.sort(key=lambda x: x[1], reverse=True) top_n[uid] = user_ratings[:n] return top_n top_n = get_top_n(predictions, n=10) rec_result=np.zeros((671,11)) #定义二维矩阵来存放结果 i=0 for uid, user_ratings in top_n.items(): rec_result[i,0]=uid rec_result[i,1:]=[iid for (iid, _) in user_ratings] i=i+1 rec_result=rec_result.astype(&apos;int&apos;) #转变成DataFrame rec_result=pd.DataFrame(rec_result,columns=[&apos;userId&apos;,&apos;rec1&apos;,&apos;rec2&apos;,&apos;rec3&apos;,&apos;rec4&apos;,&apos;rec5&apos;, &apos;rec6&apos;,&apos;rec7&apos;,&apos;rec8&apos;,&apos;rec9&apos;,&apos;rec10&apos;]) 算法运行结果： 简单的电影点评网站构建整体框架 MySQL是一个关系型数据库管理系统，也是一种WEB应用最好的数据库。数据库作为中间件，搭建在寝室的主机，便于小组成员之间使用，其操纵代码： import pymysql import pandas as pd #连接数据库 conn = pymysql.connect(host=&apos;10.110.43.140&apos;,port= 3306,user = &apos;###&apos;,passwd=&apos;####&apos;,db=&apos;sys&apos;) #db：库名，用户名和密码这里我打了马赛克了，嘻嘻 #创建游标 cur = conn.cursor() df=pd.read_sql(&apos;SELECT * FROM db_movies.tb_movies;&apos;,conn) cur.close() conn.close() 小伙伴应用Django框架，是一个开放源代码的Web应用框架，由Python写，时间仓促的情况下赶出了一个还是很不错的页面，点赞。 详细代码可见个人github。]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>电影</tag>
        <tag>数据挖掘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网格搜索与Pipeline]]></title>
    <url>%2F2017%2F11%2F23%2F%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2%E4%B8%8E%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[学习机器学习有段时间了，第一参加了个比赛，京东JDD数据探索大赛，做了个登陆识行为识别。不得不说，在实际业务场景中用学的机器学习算法来解决问题，比想象中的难度还是大很多，毕竟实际问题其实比平时简单的算法应用复杂得多。虽然目前数据准确率还不是很高，这个数据集的正例和负例比例相差太大，而且数据上对于特征工程处理也有很大的难度。Anyway，毕竟是第一次参加这样的比赛，收获还是很大的，学到了很多新东西。比如网格搜索和Pipeline机制，以及一个神器Xgboost。先将网格搜索和交叉验证mark一下吧。 网格搜索实际机器学习应用场景中的一个利器，通俗点就是暴力搜索。机器学习在应用的的时候，调参是一个很重要的环节，而网格搜索就在于优化参数搜索选择，更直白地说，就是你选择可能的参数集给你的分类器，然后网格搜索把这些可能的参数情况都运行一遍，按照你设定的score计算方式，返回score最高的参数。 函数原型： GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’) 常用参数estimator：所使用的分类器，如estimator=RandomForestClassifier(min_samples_split=100,min_samples_leaf=20,max_depth=8,max_features=’sqrt’,random_state=10), 并且传入除需要确定最佳的参数之外的其他参数。每一个分类器都需要一个scoring参数，或者score方法。param_grid：值为字典或者列表，即需要最优化的参数的取值，param_grid =param_test1，param_test1 = {‘n_estimators’:range(10,71,10)}。我用的Xgboost算法，优化的参数集为： parameters = { &apos;max_depth&apos;:[4,6], &apos;learning_rate&apos;:[0.1,0.3], &apos;subsample&apos;:[0.8,1.0], &apos;gamma&apos;:[0,3,5] } scoring :准确度评价标准，默认None,这时需要使用score函数；或者如scoring=’roc_auc’，根据所选模型不同，评价准则不同。字符串（函数名），或是可调用对象，需要其函数签名形如：scorer(estimator, X, y)；如果是None，则使用estimator的误差估计函数。scoring官方给的参数选择为http://scikit-learn.org/stable/modules/model_evaluation.html，当然也可以自定义，我在比赛中就按照JDD给的评分要求自定义了： from sklearn.metrics import fbeta_score,make_scorer #评估函数 JdScore = make_scorer(fbeta_score,beta=0.1,greater_is_better=True) cv :交叉验证参数，默认None，使用三折交叉验证。指定fold数量，默认为3，也可以是yield训练/测试数据的生成器。verbose：日志冗长度，int：冗长度，0：不输出训练过程，1：偶尔输出，&gt;1：对每个子模型都输出。n_jobs: 并行数，int：个数,-1：跟CPU核数一致, 1:默认值。 一个完整的网格搜索： from xgboost.sklearn import XGBClassifier #xgb的配置 xgbFier = XGBClassifier( learning_rate =0.1, n_estimators=1000, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, objective= &apos;binary:logistic&apos;, scale_pos_weight=1, seed=27, silent=0 ) #网格搜索实验 from sklearn.model_selection import GridSearchCV parameters = { &apos;max_depth&apos;:[4,6], &apos;learning_rate&apos;:[0.1,0.3], &apos;subsample&apos;:[0.8,1.0], &apos;gamma&apos;:[0,3,5] } gSearch =GridSearchCV(xgbFier,parameters,n_jobs=-1,scoring=JdScore,cv=5) import time start =time.time() gSearch.fit(X_train,Y_train) runtime=time.time()-start print(&apos;run time:&apos;,runtime) print(gSearch.best_params_,gSearch.best_score_) 输出结果为： run time: 4109.730866909027 {&apos;gamma&apos;: 3, &apos;learning_rate&apos;: 0.1, &apos;max_depth&apos;: 6, &apos;subsample&apos;: 0.8} 0.738112481672 这样就找出了较优的参数，唉，现在只能得到0.78的线下score，还要继续修改啊。 Pipeline机制顾名思义就是管道机制，就是将机器学习整个流程流式化封装和管理，因为参数集在很多情况下对于测试集和训练集都是一样处理，他们有很多共同的步骤，这个机制就是便于这些步骤的共同使用。网上找到的一个很好解释的图如下，模型训练和预测过程中数据标准化、PCA降维之类的处理都可以通用，而且训练和预测用的是同一算法。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EVD、SVD以及PCA整理]]></title>
    <url>%2F2017%2F11%2F01%2FEVD%E3%80%81SVD%E4%BB%A5%E5%8F%8APCA%2F</url>
    <content type="text"><![CDATA[最近的机器学习算法学习到了主成分分析（PCA），在人脸识别中对样本数据进行了降维，借此对特征值分解（EVD）、奇异值分解（SVD）进行了梳理整理。 特征值分解（EVD)矩阵是一种线性变换，比如矩阵Ax=y中，矩阵A将向量x线性变换到另一个矩阵y，这个过程中包含3类效应：旋转、缩放以及投影。 对角矩阵对应缩放，比如 其对应的线性变换如下： 对与正交矩阵来说，对应的是向量的旋转，比如将向量OA从正交基e1e2中,到另一组正交基为e1’e2’中， 当矩阵A与x维度不一样时，得到的y的维度也与x不一样，即存在投影变换。 考虑一种特殊矩阵，对称阵的特征值分解，其实在机器学习中也经常是对XX’求特征向量，也就是对称阵。 其中： 这个时候用到对称阵的特性，U为正交矩阵，其逆矩阵等于转置。 即矩阵A将向量X转移到了U这组基的空间上，再进行缩放，而后又通过U正交基进行旋转，所以只有缩放，没有旋转和投影。 奇异值分解（SVD)奇异值分解其实类似于特征值分解，不过奇异值分解适用于更一般的矩阵，而不是方阵。 U、V都是一组正交基，表示一个向量从V这组正交基旋转到U这组正交基，同时也在每个方向进行缩放。 奇异值和特征值对应为： v即为式子中的右奇异向量，同时也可以得到： 在奇异值按从小到大排序的情况下，很多情况下，前面部分的奇异值就占所有奇异值和的99%以上，所以我们可以取前r个奇异值来近似描述矩阵，可以用来数据降维。 这样可以还原出A矩阵，减少数据存储。下面看如何利用SVD降维： 从而将A’从n m降到n r SVD常用于推荐系统，有基于用户的协同过滤（User CF)和基于物品的协同过滤（Item CF)。这里给出一个Item CF实现。 网上找的一个实现代码，找不到出处了。。。 #coding=utf-8 from numpy import * from numpy import linalg as la &apos;&apos;&apos;加载测试数据集&apos;&apos;&apos; def loadExData(): return mat([[0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 5], [0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 3], [0, 0, 0, 0, 4, 0, 0, 1, 0, 4, 0], [3, 3, 4, 0, 0, 0, 0, 2, 2, 0, 0], [5, 4, 5, 0, 0, 0, 0, 5, 5, 0, 0], [0, 0, 0, 0, 5, 0, 1, 0, 0, 5, 0], [4, 3, 4, 0, 0, 0, 0, 5, 5, 0, 1], [0, 0, 0, 4, 0, 4, 0, 0, 0, 0, 4], [0, 0, 0, 2, 0, 2, 5, 0, 0, 1, 2], [0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0], [1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0]]) &apos;&apos;&apos;以下是三种计算相似度的算法，分别是欧式距离、皮尔逊相关系数和余弦相似度, 注意三种计算方式的参数inA和inB都是列向量&apos;&apos;&apos; def ecludSim(inA,inB): return 1.0/(1.0+la.norm(inA-inB)) #范数的计算方法linalg.norm()，这里的1/(1+距离)表示将相似度的范围放在0与1之间 def pearsSim(inA,inB): if len(inA)&lt;3: return 1.0 return 0.5+0.5*corrcoef(inA,inB,rowvar=0)[0][1] #皮尔逊相关系数的计算方法corrcoef()，参数rowvar=0表示对列求相似度，这里的0.5+0.5*corrcoef()是为了将范围归一化放到0和1之间 def cosSim(inA,inB): num=float(inA.T*inB) denom=la.norm(inA)*la.norm(inB) return 0.5+0.5*(num/denom) #将相似度归一到0与1之间 &apos;&apos;&apos;按照前k个奇异值的平方和占总奇异值的平方和的百分比percentage来确定k的值, 后续计算SVD时需要将原始矩阵转换到k维空间&apos;&apos;&apos; def sigmaPct(sigma,percentage): sigma2=sigma**2 #对sigma求平方 sumsgm2=sum(sigma2) #求所有奇异值sigma的平方和 sumsgm3=0 #sumsgm3是前k个奇异值的平方和 k=0 for i in sigma: sumsgm3+=i**2 k+=1 if sumsgm3&gt;=sumsgm2*percentage: return k &apos;&apos;&apos;函数svdEst()的参数包含：数据矩阵、用户编号、物品编号和奇异值占比的阈值， 数据矩阵的行对应用户，列对应物品，函数的作用是基于item的相似性对用户未评过分的物品进行预测评分&apos;&apos;&apos; def svdEst(dataMat,user,simMeas,item,percentage): n=shape(dataMat)[1] simTotal=0.0;ratSimTotal=0.0 u,sigma,vt=la.svd(dataMat) k=sigmaPct(sigma,percentage) #确定了k的值 sigmaK=mat(eye(k)*sigma[:k]) #构建对角矩阵 xformedItems=dataMat.T*u[:,:k]*sigmaK.I #根据k的值将原始数据转换到k维空间(低维),xformedItems表示物品(item)在k维空间转换后的值 for j in range(n): userRating=dataMat[user,j] if userRating==0 or j==item:continue similarity=simMeas(xformedItems[item,:].T,xformedItems[j,:].T) #计算物品item与物品j之间的相似度 simTotal+=similarity #对所有相似度求和 ratSimTotal+=similarity*userRating #用&quot;物品item和物品j的相似度&quot;乘以&quot;用户对物品j的评分&quot;，并求和 if simTotal==0:return 0 else:return ratSimTotal/simTotal #得到对物品item的预测评分 &apos;&apos;&apos;函数recommend()产生预测评分最高的N个推荐结果，默认返回5个； 参数包括：数据矩阵、用户编号、相似度衡量的方法、预测评分的方法、以及奇异值占比的阈值； 数据矩阵的行对应用户，列对应物品，函数的作用是基于item的相似性对用户未评过分的物品进行预测评分； 相似度衡量的方法默认用余弦相似度&apos;&apos;&apos; def recommend(dataMat,user,N=5,simMeas=cosSim,estMethod=svdEst,percentage=0.9): unratedItems=nonzero(dataMat[user,:].A==0)[1] #建立一个用户未评分item的列表 print(unratedItems) if len(unratedItems)==0:return &apos;you rated everything&apos; #如果都已经评过分，则退出 itemScores=[] for item in unratedItems: #对于每个未评分的item，都计算其预测评分 estimatedScore=estMethod(dataMat,user,simMeas,item,percentage) itemScores.append((item,estimatedScore)) itemScores=sorted(itemScores,key=lambda x:x[1],reverse=True)#按照item的得分进行从大到小排序 return itemScores[:N] #返回前N大评分值的item名，及其预测评分值 testdata=loadExData() print(recommend(testdata,1,N=3,percentage=0.8))#对编号为1的用户推荐评分较高的3件商品 主成分分析（PCA）PCA也常用于数据降维，特别是在人脸识别对于图像数据的处理中，得到了广泛的运用。数据降维的原则是使得数据维度减小，即行向量方差尽可能大，但是同时信息保留最多，就要求行向量之间相关性尽量小，即行向量之间协方差为0.对于数据： 标准化处理先： 那么协方差矩阵： 希望降维后协方差矩阵对角元素极可能大，非对角元素尽可能为0，即成为对角矩阵，则可对X进行线性变换，Y=QX,那么： 所以，Q为CX的特征向量，其方差为特征值，进行降维一般取前r个特征值对应的特征向量，转换结果为： 另一种证明方式可见：http://blog.csdn.net/zhongkejingwang/article/details/42264479]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网易云音乐爬虫连载（1）之热门歌单音乐获取]]></title>
    <url>%2F2017%2F10%2F25%2F%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E7%88%AC%E8%99%AB%E8%BF%9E%E8%BD%BD%EF%BC%881%EF%BC%89%E4%B9%8B%E7%83%AD%E9%97%A8%E6%AD%8C%E5%8D%95%E9%9F%B3%E4%B9%90%E8%8E%B7%E5%8F%96%2F</url>
    <content type="text"><![CDATA[最近想做文本挖掘方面的工作，想到了获取网易云音乐平台的用户评论以及音乐数据，这可以作为一个文本挖掘以及推荐系统的很好的数据来源。诚然，获取大量的数据涉及到内容还是挺多的，因此从本文开始做一个连载，记录今后对网易云音乐数据的爬取，以及今后对于获取的数据进行分析，作为机器学习的素材进一步处理。 作为连载的第一篇，首先就是介绍基本的网易云音乐信息获取，以及音乐评论的获取。 为了获得大量的音乐数据，从网易云音乐首页的热门歌单中入手，获取音乐信息。 用谷歌开发者工具发现，其实获取热门歌单的时候，网易云的请求包中的网址并不是截图中浏览器的http://music.163.com/#/discover/playlist，而是http://music.163.com/discover/playlist 所以说爬虫的时候，不能单纯看浏览器的url，还是得看真实发送的请求包中的数据。 import requests from bs4 import BeautifulSoup import codecs url = &apos;http://music.163.com/discover/playlist&apos; url_top = &apos;http://music.163.com&apos; headers = { &apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&apos;, &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;, &apos;Host&apos;: &apos;music.163.com&apos;, &quot;User-Agent&quot;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3218.0 Safari/537.36&apos;, } 分析获取的html文档，采用的是Beautiful Soup，这个时候首先查看html文档，找到歌单数据所在位置。 发现一个id属性，id属性在一个html文档中是独一无二的，可以据此定位找出我们要的歌单信息。 a=requests.get(url,headers=headers) html = a.content soup=BeautifulSoup(html,&apos;lxml&apos;) playlist={} f=codecs.open(&apos;playlist.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;) PlaylistBlock = soup.select(&apos;#m-pl-container&apos;)[0].select(&apos;.msk&apos;) for piece in PlaylistBlock: playlist[piece.get(&apos;title&apos;)]=piece.get(&apos;href&apos;) f.write(piece.get(&apos;title&apos;)+&apos;: &apos;+piece.get(&apos;href&apos;)+&apos;\n&apos;) f.close() 现在仅仅是获取了第一页的热门歌单： 歌单的链接都是相对链接，只要加上http://music.163.com就可以访问到相应的具体歌单，来进一步获取歌单内的歌曲。 f=codecs.open(&apos;musiclist.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;) musiclist = [] for description,url_music in playlist.items(): html = requests.get(url_top+url_music,headers=headers).content soup = BeautifulSoup(html,&apos;lxml&apos;) songs= soup.find(&apos;ul&apos;,{&apos;class&apos;:&apos;f-hide&apos;}).find_all(&apos;a&apos;) music={} f.writelines(description+&apos;\n&apos;) for song in songs: music[song[&apos;href&apos;]] = song.string a = music_info_get(url_top+song[&apos;href&apos;],headers) f.write(song[&apos;href&apos;]+&apos;: &apos;+song.string+a+&apos;\n&apos;) musiclist.append(music) f.write(&apos;---------------------------------&apos;+&apos;\n&apos;) f.close() 由于在歌单页面没有查到歌曲的对应歌手、专辑信息（理论上应该有的，但是我并没有找到），所以考虑进一步进到歌曲页面，可以看到歌曲的详细信息，后期主要在歌曲页面进行信息获取，所以在这里先进到歌曲页面获取歌手、专辑信息。 以赵雷的《成都》为例，进入歌曲页面 提取出歌曲的详细信息： def music_info_get(url,headers): html = requests.get(url, headers=headers).content soup = BeautifulSoup(html, &apos;lxml&apos;) a = soup.find(&apos;meta&apos;, {&apos;name&apos;: &apos;description&apos;})[&apos;content&apos;] return a 《成都》的网页中包含歌词、评论等信息，但是在请求返回的数据包中并没有见到，刷新《成都》页面其实有很多请求，再仔细查看之后，在其他请求中看到了包括评论以及歌词信息。 在这个post请求包中，返回数据中有《成都》的音乐评论，post和get方式不同，post需要带参数，在request的header中可以看到有两个参数， 将这个数据带上，用request.post也确实得到了评论数据。 params = &apos;5iLo/oxg1fK3aTLbh99GhtE6AnWBnEGVKMt4iDi6Qm9ag54eFjI/XRn2rI6QOAk8Zj6u2eS7NkRu04mUakNwntZMQrf9f6cdN6PWZuB16f0CgA0N/5IOl7tUXKZCbsduXzfpYCExtIvLDlOeu9LkGpUksFW3O0zq5ZTjRc1MrB49sxRvF8NA+U9LIMvhJHmO&apos; encSecKey = &apos;3ae5b6afde65dede52224db59c2cc8e46aac937dd95915ba6538859aa0615cb6aa938a118fd6f473256fc5cf95d8c3821b07264d7189c07db922088b711a357e3f2092e5a10df5e3d6008a0314adcb8817fc3fe14a2ee657a0a2221597cc51a78534043a1429484a251e4b2b9128fe042d821b7e862114207773cbdba951c8a2&apos; data={&quot;params&quot;: params, &quot;encSecKey&quot;: encSecKey} a = requests.post(url,headers=headers,data=data) 但是post所带上的参数data，看起来应该是跟数据加密相关，每个请求应该不一样，在爬取大量音乐的时候没办法对每首歌的参数都去手动获得，这里在网上https://www.zhihu.com/question/36081767看到了一个方法，之后可以参照来实现。得到的评论数据：还有就是请求歌曲的评论数据的url，对《成都》来说是http://music.163.com/weapi/v1/resource/comments/R_SO_4_436514312?csrf_token=，其规律就是R_SO_4_之后的数字为歌曲对应的id，比如《成都》的URL：http://music.163.com/#/song?id=436514312 爬虫进行到这，仅仅是从歌单到歌曲，再到歌曲信息以及评论单纯地获取了一遍，对于今后大量歌单大规模的爬取，还需要考虑很多，比如多线程爬虫，结合数据库的爬虫数据存储，以及对于长时间爬虫如何应对发爬虫策略，仅仅是获取数据就还有这么多坑，先Mark一下，留着坑慢慢填。]]></content>
      <tags>
        <tag>爬虫</tag>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP网络及python实现]]></title>
    <url>%2F2017%2F10%2F23%2FBP%E7%BD%91%E7%BB%9C%E5%8F%8Apython%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[BP神经网络改变了感知器的结构，引入了新的隐含层以及误差反向传播，基本上能够解决非线性分类问题，也是神经网络的基础网络结构，在此对BP神经网络算法进行总结，并用python对其进行了实现。 BP神经网络的典型结构如下图所示： 隐含层通常为一层，也可以是多层，在BP网络中一般不超过2层。 正向传播正向传播的过程与感知器类似，都是输入与权重的点积，隐含层和输出层都包含一个激活函数，BP网络常用sigmod函数。 但是现在好像不常用了，更多地是Tanh或者是ReLU，好像最近又出了一个全新的激活函数，后续还得去了解。BP神经网络的误差函数是全局误差，将所有样本的误差都进行计算求和，所以在算法过程学习的时候，进行的是批量学习，等所有数据都进行批次计算之后，才进行权重调整。 反向传播过程这个可以说是BP网络比较精髓的部分了，也是BP网络能够从数据中学习的关键，误差的反向传播过程就是两种情况，要么输出层神经元，要么是隐含层神经元。 对于输出神经元，权重的梯度修正法则为： 即权重增量等于学习率、局域梯度、输出层输出结果的乘积，对于局域梯度，其计算如下： 即为误差信号乘于激活函数的导数，其中n表示第n次迭代。对于sigmod函数来说，其导数为： 对于隐藏层来说，情况更加复杂一点，需要经过上一层的误差传递。 隐藏层的局域梯度为： 上面式子的第一项，说明隐含层神经元j局域梯度的计算仅以来神经元j的激活函数的导数，但是第二项求和，是上一层神经元的局域梯度通过权重w进行了传递。 总的来说，反向传播算法中，权重的调整值规则为： （权值调整）=（学习率参数） X （局域梯度） X（神经元j的输入信号） BP算法中还有一个动量因子（mc），主要是网络调优，防止网络发生震荡或者收敛过慢，其基本思想就是在t时刻权重更新的时候考虑t-1时刻的梯度值。 self.out_wb = self.out_wb + (1-self.mc)*self.eta*dout_wb + self.mc*self.eta*dout_wbold self.hi_wb =self.hi_wb + (1-self.mc)*self.eta*dhi_wb + self.mc*self.eta*dhi_wbold BP网络分类算法首先构造的一个BP类 # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Mon Oct 23 09:12:46 2017 @author: lkj &quot;&quot;&quot; import numpy as np from numpy import * import matplotlib.pyplot as plt class BpNet(object): def __init__(self): # 以下参数需要手动设置 self.eb=0.01 # 误差容限，当误差小于这个值时，算法收敛，程序停止 self.eta=0.1 # 学习率 self.mc=0.3 # 动量因子：引入的一个调优参数，是主要的调优参数 self.maxiter=2000 # 最大迭代次数 self.errlist=[] # 误差列表 self.dataMat=0 # 训练集 self.classLabels=0 # 分类标签集 self.nSampNum=0 # 样本集行数 self.nSampDim=0 # 样本列数 self.nHidden=4 # 隐含层神经元 self.nOut=1 # 输出层个数 self.iterator=0 # 算法收敛时的迭代次数 #激活函数 def logistic(self,net): return 1.0/(1.0+exp(-net)) #反向传播激活函数的导数 def dlogistic(self,y): return (y*(1-y)) #全局误差函数 def errorfuc(self,x): return sum(x*x)*0.5 #加载数据集 def loadDataSet(self,FileName): data=np.loadtxt(FileName) m,n=shape(data) self.dataMat = np.ones((m,n)) self.dataMat[:,:-1] = data[:,:-1] #除数据外一列全为1的数据，与权重矩阵中的b相乘 self.nSampNum = m #样本数量 self.nSampDim = n-1 #样本维度 self.classLabels =data[:,-1] #数据集归一化，使得数据尽量处在同一量纲，这里采用了标准归一化 #数据归一化应该针对的是属性，而不是针对每条数据 def normalize(self,data): [m,n]=shape(data) for i in range(n-1): data[:,i]=(data[:,i]-mean(data[:,i]))/(std(data[:,i])+1.0e-10) return data #隐含层、输出层神经元权重初始化 def init_WB(self): #隐含层 self.hi_w = 2.0*(random.rand(self.nSampDim,self.nHidden)-0.5) self.hi_b = 2.0*(random.rand(1,self.nHidden)-0.5) self.hi_wb = vstack((self.hi_w,self.hi_b)) #输出层 self.out_w = 2.0*(random.rand(self.nHidden,self.nOut)-0.5) self.out_b = 2.0*(random.rand(1,self.nOut)-0.5) self.out_wb = vstack((self.out_w,self.out_b)) def BpTrain(self): SampIn = self.dataMat expected = self.classLabels dout_wbold = 0.0 dhi_wbold = 0.0 #记录隐含层和输出层前一次的权重值，初始化为0 self.init_WB() for i in range(self.maxiter): #信号正向传播 #输入层到隐含层 hi_input = np.dot(SampIn,self.hi_wb) hi_output = self.logistic(hi_input) hi2out = np.hstack((hi_output,np.ones((self.nSampNum,1)))) #隐含层到输出层 out_input=np.dot(hi2out,self.out_wb) out_output = self.logistic(out_input) #计算误差 error = expected.reshape(shape(out_output)) - out_output sse = self.errorfuc(error) self.errlist.append(sse) if sse&lt;=self.eb: self.iterator = i+1 break #误差反向传播 #DELTA输出层梯度 DELTA = error*self.dlogistic(out_output) #delta隐含层梯度 delta = self.dlogistic(hi_output)*np.dot(DELTA,self.out_wb[:-1,:].T) dout_wb = np.dot(hi2out.T,DELTA) dhi_wb = np.dot(SampIn.T,delta) #更新输出层和隐含层权值 if i==0: self.out_wb = self.out_wb + self.eta*dout_wb self.hi_wb = self.hi_wb + self.eta*dhi_wb else: #加入动量因子 self.out_wb = self.out_wb + (1-self.mc)*self.eta*dout_wb + self.mc*self.eta*dout_wbold self.hi_wb =self.hi_wb + (1-self.mc)*self.eta*dhi_wb + self.mc*self.eta*dhi_wbold dout_wbold = dout_wb dhi_wbold = dhi_wb ##输入测试点，输出分类结果 def BpClassfier(self,start,end,steps=30): x=linspace(start,end,steps) xx=np.ones((steps,steps)) xx[:,0:steps] = x yy = xx.T z = np.ones((steps,steps)) for i in range(steps): for j in range(steps): xi=array([xx[i,j],yy[i,j],1]) hi_input = np.dot(xi,self.hi_wb) hi_out = self.logistic(hi_input) hi_out = mat(hi_out) m,n=shape(hi_out) hi_b = ones((m,n+1)) hi_b[:,:n] = hi_out out_input = np.dot(hi_b,self.out_wb) out = self.logistic(out_input) z[i,j] = out return x,z def classfyLine(self,plt,x,z): #画出分类分隔曲线，用等高线画出 plt.contour(x,x,z,1,colors=&apos;black&apos;) def errorLine(self,plt,color=&apos;r&apos;): x=linspace(0,self.maxiter,self.maxiter) y=log2(self.errlist) #y=y.reshape(()) #print(shape(x),shape(y)) plt.plot(x,y,color) # 绘制数据散点图 def drawDataScatter(self,plt): i=0 for data in self.dataMat: if(self.classLabels[i]==0): plt.scatter(data[0],data[1],c=&apos;blue&apos;,marker=&apos;o&apos;) else: plt.scatter(data[0],data[1],c=&apos;red&apos;,marker=&apos;s&apos;) i=i+1 利用分类器执行分类： from BpNet import * import matplotlib.pyplot as plt # 数据集 bpnet = BpNet() bpnet.loadDataSet(&quot;testSet2.txt&quot;) bpnet.dataMat = bpnet.normalize(bpnet.dataMat) # 绘制数据集散点图 bpnet.drawDataScatter(plt) # BP神经网络进行数据分类 bpnet.BpTrain() print(bpnet.out_wb) print(bpnet.hi_wb) # 计算和绘制分类线 x,z = bpnet.BpClassfier(-3.0,3.0) bpnet.classfyLine(plt,x,z) plt.show() # 绘制误差曲线 bpnet.errorLine(plt) plt.show() 输出结果为： 误差输出结果： 可以看到在1000次左右迭代就已经出现了比较好的结果了。具体代码可见个人github仓库https://github.com/lkj1114889770/Machine-Leanring-Algorithm/tree/master/BpNet 除了分类，BP神经网络也常用在函数逼近，这时候输出层神经元激活函数一般就不会再采用sigmod函数了，通常采用线性函数。 【参考文献】《神经网络与机器学习》（第3版） （加） Simon Haykin 著；《机器学习算法原理与编程实践》 郑捷著；]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AdaBoost算法笔记]]></title>
    <url>%2F2017%2F10%2F22%2FAdaBoost%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[AdaBoost属于机器学习中的集成学习，其基本思想是基于“弱学习算法”集成强化为“强学习算法”，在分类中就是组合弱分类器得到强分类器。实际中很容易得到正确率不是非常高的弱分类器(当然，通常来说at least &gt;50%），通过Adaboost算法，来组合得到正确率很高的强分类器。从上述就可以知道，AdaBoost算法有两部分，顶层是主算法，底层是其他的分类算法，可以是决策树，SVM之类的算法 AdaBoost算法的核心思想就是：加大分类错误数据集的权重，以便迭代中进一步分类；加大正确率高的分类器在最终分类结果表决中的权重。 对算法进一步阐述，考虑简单的二分类问题。 初始化数据集的权值分布，初始化为相等的数值 使用训练集学习，得到基本分类器Gm,计算其分类误差率 计算分类器Gm的系数 am随着em增大而减小，这样分类器在最终组合分类器中权重会下降，同时还需要据此来更新数据集的权重。 更新数据集权重分布 其中Zm为规范化因子，是的Dm+1成一个概率分布。 构造弱分类器的组合通过权重值的线性组合得到强分类器 上述过程迭代M次，或者是分类精度达到要求]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>集成学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下完这场雨]]></title>
    <url>%2F2017%2F10%2F20%2F%E4%B8%8B%E5%AE%8C%E8%BF%99%E5%9C%BA%E9%9B%A8%2F</url>
    <content type="text"><![CDATA[偶然间网易云推送了这首《下完这场雨》，多久没有再听过后弦的歌了，这首17年的可以说是新歌，歌词一贯写得好，一如六七年前的清新中国风。江南烟雨中，伞下约无果；下完这场雨，此生难再遇。 仿佛又回到了六七年前，戴着耳机，揣着MP3，走在凤凰花园去学校的路上，穿过西厢，看过娃娃脸，有这样喜欢的清新中国风，有许嵩，有庐州月，断桥残雪，清明雨上，半城烟沙。。。真好。如果可以 别下完这场雨]]></content>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12306车次查询与短信提醒]]></title>
    <url>%2F2017%2F10%2F02%2F12306%E8%BD%A6%E6%AC%A1%E6%9F%A5%E8%AF%A2%E4%B8%8E%E7%9F%AD%E4%BF%A1%E6%8F%90%E9%86%92%2F</url>
    <content type="text"><![CDATA[正值国庆，不想出去玩看人，也无法在实验室知识的海洋里遨游整个假期，就干脆回家，无奈却买不到回来的票（国庆真是堪比春运啊），只能买到途径站的票。12306官方给的自动刷新车票的系统太渣，经常自己卡死停掉，因此想到用python爬取12306网站车票信息，利用Twilio在有票的情况下短信通知我。 首先打开12306的查票页面https://kyfw.12306.cn/otn/leftTicket/init 输入出发地和目的地进行搜索。下面就是常见的套路，对于谷歌浏览器按F12打开开发者工具，获取查询的时候的数据信息。按下查询之后，可以发现有两个数据请求： 显然第二个请求返回数据含有我们需要的车次信息，因此根据第二个请求的header来封装我们requests.get时候的请求包，以及如何封装cookies也可见之前的爬虫博客。 url = &apos;https://kyfw.12306.cn/otn/leftTicket/queryX?leftTicketDTO.train_date=2017-10-08&amp;leftTicketDTO.from_station=YTG&amp;leftTicketDTO.to_station=HZH&amp;purpose_codes=ADULT&apos; headers = { &apos;Accept&apos;: &apos;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.9&apos;, &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;, &apos;Host&apos;: &apos;kyfw.12306.cn&apos;, &quot;User-Agent&quot;: &apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3218.0 Safari/537.36&apos;, } 由于12306网站还有SSL验证，所以用常规的方法去get数据都会有SSLError，最简单的处理方式就是直接忽略这个验证。 a = requests.get(url, cookies=cookies,headers=headers,verify = False) 12306网站在访问的时候经常有时候请求不到数据，这个时候需要进行判别，以防止后续处理信息报错，有计算机网络知识就知道，正常的http response的状态code就是会返回200，可以据此来判别。 while (a.status_code !=200): time.sleep(10) a = requests.get(url, cookies=cookies, headers=headers, verify=False) 对返回的车次信息进行查看，返回的信息类似于json格式的文件，车次信息包含在里面。 通过json.load进行读取后返回字典格式文件，取出其中的车次此案次，存为csv文件后用excel打开，以便更加直观地分析。 data = json.loads(a.content.decode(&apos;utf-8&apos;,&apos;ignore&apos;)) train_infos = data[&apos;data&apos;][&apos;result&apos;] train_infos_csv=[] infos = train_infos for info in infos: train_infos_csv.append((info.replace(&apos;|&apos;,&apos;,&apos;))+&apos;\n&apos;) f = open(&apos;train_infos.csv&apos;,&apos;w&apos;) for info in train_infos_csv: f.write(info) f.close() csv_reader = csv.reader(open(&apos;train_infos.csv&apos;)) 下面需要取出所需要的信息，我要的是高铁或者动车的二等座，再进行一次过滤： HSR_infos=[] for info in csv_reader: if(&apos;G&apos; in info[3]): HSR_infos.append(info) elif(&apos;D&apos; in info[3]): HSR_infos.append(info) Ticket_avaliable=&apos;&apos; for info in HSR_infos: if(info[-6] != u&apos;无&apos;): Ticket_avaliable=Ticket_avaliable + info[3] +&apos;,&apos; Body=u&apos;这些车次还有票&apos; + Ticket_avaliable if(Ticket_avaliable ==&apos;&apos;): print(u&apos;好悲伤，没票了&apos;) time.sleep(5) else: print(Body) messeage = client.messages.create(to=To, from_=From, body=Body) time.sleep(600) 上面的client.messages.create就是发送短信模块，需要用到Twilio，首先需要到Twilio官方网站注册之后账号，有账户的SID 和TOKEN后进行配置，就能发送了 SID = &apos;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&apos; TOKEN = &apos;xxxxxxxxxxxxxxxxxxxxxxxxxxxxx&apos; client = Client(SID,TOKEN) To = &apos;+86xxxxxxxxxxxxxxx&apos; From = &apos;xxxxxxxxxxxxxx&apos; Body = u&apos;啦啦啦啦啦&apos; messeage = client.messages.create(to=To,from_=From,body=Body) 上面的xxxx部分都需要根据自己的账户替换自己的信息。这样就实现了有票自动提醒，由于Twilio接收短信比较麻烦，所以没法通过短信终止程序，只能在查到票之后先终止运行10分钟，其实可以考虑通过邮件来控制程序，这个还是比较好操作的。 完整代码可见Github.]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自组织特征映射神经网络（SOM）]]></title>
    <url>%2F2017%2F09%2F30%2F%E8%87%AA%E7%BB%84%E7%BB%87%E7%89%B9%E5%BE%81%E6%98%A0%E5%B0%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88SOM%EF%BC%89%2F</url>
    <content type="text"><![CDATA[自组织特征映射神经网络（SOM）设计思想基于人体大脑，外界信息输入时，大脑皮层对应区域的部分神经元会产生兴奋，位置临近的神经云也会有相近的刺激。大脑神经元的这种特点，不是先天安排好的，而是通过后天的自学习组织形成的。芬兰Helsinki大学的Kohonen教授提出了一种成为自组织特征映射的神经网络模型。 SOM介绍SOM与kmeans算法有点相似，其基本思想也是，将距离小的个体集合划分为同一类别，而将距离大的个体划分为不同的类别。 从结构上看，SOM比较简单，只有两层，输入层和竞争层，只有输入层到竞争层的权重向量需要训练，不同于其他神经网络，竞争层同层之间的神经元还有侧向连接，在学习的过程中还会相互影响。竞争层神经元的竞争通过神经元对应的权重向量和输入样本的距离比较，距离最近的神经元成为获胜节点。 常见的相互连接的调整方式有以下几种 墨西哥草帽函数：获胜节点，有最大的权值调整量，离获胜节点越远，调整量越小，甚至达到某一距离，调整量还会变为负值。如图a所示。 大礼帽函数：墨西哥草帽函数的简化，如图b所示。 厨师帽函数：大礼帽函数的简化，如图c所示。 SOM算法学习过程网络初始化输入层网络节点数与输入样本维度（列数）相同，通常需要进行数据归一化，常见的方法是标准归一化。竞争层网络根据数据维度以及分类类别数来确定，二维数据和4种分类的话，竞争层含4个节点，但是权重矩阵为4X2，权重矩阵的初始化一般·随机给一个0-1之间的随机值。对于分类类别数目不清楚的情况，可以定义竞争层多于可能的实际分类的节点，这样最后训练结果中不对应分类结果的节点始终不会收到刺激而兴奋，即抑制。 学习率会影响收敛速度，一般定义一个动态的学习率，随迭代次数增加而递减。优胜邻域半径也定义为一个动态收缩的，随着迭代次数增加而递减。 # 学习率和学习半径函数 def ratecalc(self,indx): lrate = self.lratemax-(float(indx)+1.0)/float(self.Steps)*(self.lratemax-self.lratemin) r = self.rmax-(float(indx)+1.0)/float(self.Steps)*(self.rmax-self.rmin) return lrate,r 网络训练训练过程如下： 随机抽取一个数据样本，计算竞争层中神经元对应的权重矩阵与数据样本的距离，找到距离最近的为获胜节点。 根据优胜邻域半径，找出此邻域内的所有节点。 根据学习率调整优胜邻域半径内的所有节点，然后回到步骤1进行迭代，直到到达相应的迭代次数 根据最终的迭代结果，为分类结果分配标签。 # 主算法 def train(self): #1 构建输入层网络 dm,dn = shape(self.dataMat) normDataset = self.normalize(self.dataMat) # 归一化数据x #2 构建分类网格 grid = self.init_grid() # 初始化第二层分类网格 #3 构建两层之间的权重向量 self.w = random.rand(dn,self.M*self.N); #随机初始化权值 w distM = self.distEclud # 确定距离公式 #4 迭代求解 if self.Steps &lt; 10*dm: self.Steps = 10*dm # 设定最小迭代次数 for i in range(self.Steps): lrate,r = self.ratecalc(i) # 计算学习率和分类半径 self.lratelist.append(lrate);self.rlist.append(r) # 随机生成样本索引，并抽取一个样本 k = random.randint(0,dm) mySample = normDataset[k,:] # 计算最优节点：返回最小距离的索引值 minIndx= (distM(mySample,self.w)).argmin() d1 = int(round(minIndx - r)); d2 = int(round(minIndx + r)); if(d1&lt;0): d1=0 if(d2&gt;(shape(self.w)[1]-1)): d2= shape(self.w)[1]-1 di=d1; #print(d1,d2) while(di&lt;=d2): self.w[:,di] = self.w[:,di]+lrate*(mySample[0]-self.w[:,di]) di=di+1 # 分配类别标签 for i in range(dm): self.classLabel.append(distM(normDataset[i,:],self.w).argmin()) self.classLabel = mat(self.classLabel) 具体实现代码可见：https://github.com/lkj1114889770/Machine-Leanring-Algorithm/tree/master/SOM 针对数据集的分类结果： 参考文献： 《机器学习算法与编程实践》 郑捷著；]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浓烟下的诗歌电台]]></title>
    <url>%2F2017%2F09%2F22%2F%E6%B5%93%E7%83%9F%E4%B8%8B%E7%9A%84%E8%AF%97%E6%AD%8C%E7%94%B5%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[诗化的语言堆砌的意向磁性的烟嗓浓烟下的诗歌电台 有颗远方的心，依然想去追寻。]]></content>
      <tags>
        <tag>音乐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K-means Clustering]]></title>
    <url>%2F2017%2F09%2F22%2FK_means%20Clustering%2F</url>
    <content type="text"><![CDATA[分类通常是一种监督式学习算法，事先都知道标签信息，但是实际上很多情况下都不知道标签信息，这个时候就经常用到聚类算法（Clustering），属于无监督学习的一种，本文介绍无监督学习中典型的一种k-means聚类算法。 conventional k-meansk-means聚类算法的思想很简单，就是将数据相似度最大的聚集在一起为一类，如何衡量数据之间的相似度，通常用欧几里得距离来表示： 有时候也用余弦向量来度量： 算法过程也比较简单： 从数据集D中随机取k个元素，作为初始k个簇的中心 计算剩下的元素到k个中心的距离，并将其归类到离自己最近的簇中心点对应的簇 重新计算每个簇的中心，采用簇中所有元素各个维度的算数平均数 若新的簇的中心不变，或者在变化阈值内，则聚类结束，否则重新回到第2步。 k-means++k-means算法的一个弊端就是，初始选取的随机k个中心会对最终实际聚类效果影响很大，基于此对于初始k个点选取进行了改进，即k-measn++算法。基本思想就是，选取的初始k个点的距离尽可能远。 首先随机选择一个点作为第一个簇中心点 计算其余点与最近的一个簇中心点的距离D(x)保存在一个数组，并累加得到和sum（D(X))。 再在（0，1）取一个随机值Random，sum*Random对应的D(x)区间即为选中的下一个聚类中心（因为D(X)越大，被选中的概率越大）。 重复2 3步骤知直到k个初始聚类中心都被找出来 再进行上面的k-means聚类算法。 Kernel k-means当数据无法线性可分的时候，k-means算法也无法进行分类，类似于SVM，将分类空间推广到更广义的度量空间，即为kernel k-means. 将点从原来的空间映射到更高维度的特征空间，则距离公式变成： 常见的核函数有：Linear Kernel: Polynomial Kernel: Gaussian Kernel：]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朴素贝叶斯分类]]></title>
    <url>%2F2017%2F09%2F19%2F%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[贝叶斯算法是分类算法的一种，算法的核心是概率论中的贝叶斯定理，而朴素贝叶斯则是贝叶斯分类算法中最简单的一种。 贝叶斯定理贝叶斯算法的核心就是贝叶斯定理： 而在分类算法中，B为某个类别，A为特征，P(B|A)为某个待分类个体的特征取不同类别的概率，显然是计算取不同类别的概率，取最大概率作为该个体的分类类别；上式右边的三个式子的取值通常可以根据已知数据集即训练集求取。 朴素贝叶斯朴素贝叶斯的“朴素”体现在样本的各个特征都是条件独立的，这样就极大地简化了算法，当然这是一个比较强的条件，在实际应用中不一定符合。算法流程如下： 样本x的特征集合{a1,a2,…am} 所有分类类别取值{y1,y2,…yn} 计算所有P(y1|x),P(y2|x)….,P(yn|x) 取3中最大概率对应的分类为x的分类 根据贝叶斯定理，可以转换成求解： 因为特征之间的独立性，那么有： 而对于P(yi)可以从样本中得到，分母特征的取值概率通常对于一组特定的特征组合为常数，可以不用求解，至此完成了朴素贝叶斯算法的介绍。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle入门：Predict survival on the Titanic]]></title>
    <url>%2F2017%2F09%2F12%2Fkaggle%E5%85%A5%E9%97%A8%EF%BC%9APredict-survival-on-the-Titanic%2F</url>
    <content type="text"><![CDATA[Kaggle是一个数据分析建模的应用竞赛平台，学习了机器学习的算法，这是个很好的应用平台。Predict survival on the Titanic作为kaggle入门级别的比赛，也是我接触kaggle的第一个实践项目，最后的结果虽然不够优秀，仅Top20%左右，但是还是将第一次的实践过程mark一下。 数据分析从kaggle的网站上下载好比赛数据（train.csv和test.csv），泰坦尼克号问题就是根据乘客的个人信息，分析是否能够活下来，训练集提供了乘客信息以及存活状况，测试集仅提供信息，需要预测能否存活，其实就是一个二分类问题。 下面读入训练集数据，开始初步分析。 import pandas as pd import numpy as np from pandas import Series,DataFrame data_train = pd.read_csv(&quot;train.csv&quot;) data_train.info() 可以看到数据信息： RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 714 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) 数据中存在缺项，其中不同的字段表示的信息为 PassengerId 乘客IDSurvived 是否存活Pclass 船舱等级Name 姓名Sex 性别Age 年龄SibSp 兄弟姐妹个数Parch 父母小孩个数Ticket 船票信息Fare 票价Cabin 船舱Embarked 登船港口 import matplotlib.pyplot as plt fig = plt.figure() fig.set(alpha=0.2) # 设定图表颜色alpha参数 data_train.Age[data_train.Survived == 0].plot(kind=&apos;kde&apos;) data_train.Age[data_train.Survived == 1].plot(kind=&apos;kde&apos;) plt.xlabel(u&quot;年龄&quot;) plt.ylabel(u&quot;密度&quot;) plt.title(u&quot;从年龄看获救情况&quot;) plt.legend((u&quot;未获救&quot;,u&quot;获救&quot;),loc=&apos;best&apos;) plt.show() 年龄越小，获救的概率还是越高的，小孩还是要优先嘛。 #看看各乘客等级的获救情况 fig = plt.figure() fig.set(alpha=0.2) Survived_0 = data_train.Pclass[data_train.Survived == 0].value_counts() Survived_1 = data_train.Pclass[data_train.Survived == 1].value_counts() df=pd.DataFrame({u&apos;获救&apos;:Survived_1, u&apos;未获救&apos;:Survived_0}) df.plot(kind=&apos;bar&apos;, stacked=True) plt.title(u&quot;各乘客等级的获救情况&quot;) plt.xlabel(u&quot;乘客等级&quot;) plt.ylabel(u&quot;人数&quot;) plt.show() 船舱等级越高，获救概率也是越高，还是上层社会的人容易获救啊。 #看看各性别的获救情况 fig = plt.figure() fig.set(alpha=0.2) Survived_m = data_train.Survived[data_train.Sex == &apos;male&apos;].value_counts() Survived_f = data_train.Survived[data_train.Sex == &apos;female&apos;].value_counts() df=pd.DataFrame({u&apos;男性&apos;:Survived_m, u&apos;女性&apos;:Survived_f}) df.plot(kind=&apos;bar&apos;, stacked=True) plt.title(u&quot;按性别看获救情况&quot;) plt.xlabel(u&quot;性别&quot;) plt.ylabel(u&quot;人数&quot;) plt.show() 女性获救概率更高，嗯，Lady first. 姓名中含有一些称谓信息，也代表着乘客的身份以及社会地位。 data_train.groupby(data_train[&apos;Name&apos;].apply(lambda x: x.split(&apos;, &apos;)[1]).apply(lambda x: x.split(&apos;.&apos;)[0]))[&apos;Survived&apos;].mean() 得到的结果如下： Name Capt 0.000000 Col 0.500000 Don 0.000000 Dr 0.428571 Jonkheer 0.000000 Lady 1.000000 Major 0.500000 Master 0.575000 Miss 0.697802 Mlle 1.000000 Mme 1.000000 Mr 0.156673 Mrs 0.792000 Ms 1.000000 Rev 0.000000 Sir 1.000000 the Countess 1.000000 Name: Survived, dtype: float64 还是要看身份的，有身份的人容易获救啊。 #信息中船舱有无对于获救情况影响 fig = plt.figure() fig.set(alpha=0.2) Cabin_Has= data_train.Survived[data_train.Cabin.notnull()].value_counts() Cabin_None = data_train.Survived[data_train.Cabin.isnull()].value_counts() df=pd.DataFrame({u&apos;有船舱号&apos;:Cabin_Has, u&apos;无船舱号&apos;:Cabin_None}) df.plot(kind=&apos;bar&apos;, stacked=True) plt.title(u&quot;有无船舱号的获救情况&quot;) plt.xlabel(u&quot;船舱号有无&quot;) plt.ylabel(u&quot;人数&quot;) plt.show() 看起来有船舱号的人获救概率高一点。 #信息中Embarked登船港口的影响 fig = plt.figure() fig.set(alpha=0.2) Survived_0 = data_train.Embarked[data_train.Survived == 0].value_counts() Survived_1 = data_train.Embarked[data_train.Survived == 1].value_counts() df=pd.DataFrame({u&apos;获救&apos;:Survived_1, u&apos;未获救&apos;:Survived_0}) df.plot(kind=&apos;bar&apos;, stacked=True) plt.title(u&quot;不同登船港口的获救情况&quot;) plt.xlabel(u&quot;乘客等级&quot;) plt.ylabel(u&quot;人数&quot;) plt.show() C港口获救概率高一点。 数据处理下面就需要对训练集以及测试集的数据进行处理，以便算法的处理。 data_test = pd.read_csv(&apos;test.csv&apos;) data_test[&apos;Survived&apos;]=3 #为了能够合并在一起，test数据添加Suvrvived一列，不过数值为不存在的3 data_combine=pd.concat([data_train,data_test]) data_combine.info() 可以看到合并数据信息： Int64Index: 1309 entries, 0 to 417 Data columns (total 12 columns): Age 1046 non-null float64 Cabin 295 non-null object Embarked 1307 non-null object Fare 1308 non-null float64 Name 1309 non-null object Parch 1309 non-null int64 PassengerId 1309 non-null int64 Pclass 1309 non-null int64 Sex 1309 non-null object SibSp 1309 non-null int64 Survived 1309 non-null int64 Ticket 1309 non-null object dtypes: float64(2), int64(5), object(5) 缺省数据的处理上面信息中可以看到Age、Cabin、Embarked、Fare有数据缺失，下面需要进行处理。 Cabin缺失数据很多，可以将有无Cabin记录为特征；Embarked仅缺失2个，可以取取值最多的来填补。 #对船舱号缺值进行处理，有船舱号标识为1，无船舱号标识为0 data_combine.loc[(data_combine.Cabin.notnull()), &apos;Cabin&apos; ] = 1 data_combine.loc[(data_combine.Cabin.isnull()), &apos;Cabin&apos; ] = 0 #有两行数据缺失Embarked值，补全为Embarked的最多取值S data_combine.loc[(data_combine.Embarked.isnull()),&apos;Embarked&apos;] = &apos;S&apos; Fare有一个缺值，取所有Fare的平均值来填补。 data_combine.Fare.fillna(data_combine.Fare.mean(), inplace=True) #Fare有一个缺值，用均值填充 Age缺省数值也是不多，但是不像Fare和Embarked那么少，考虑使用算法来拟合，采用随机森林的回归进行预测拟合填补。 from sklearn.ensemble import RandomForestRegressor ### 使用 RandomForestClassifier 填补缺失的年龄属性 def set_missing_ages(df): # 把已有的数值型特征取出来丢进Random Forest Regressor中 age_df = df[[&apos;Age&apos;,&apos;Fare&apos;, &apos;Parch&apos;, &apos;SibSp&apos;, &apos;Pclass&apos;]] # 乘客分成已知年龄和未知年龄两部分 known_age = age_df[age_df.Age.notnull()].as_matrix() unknown_age = age_df[age_df.Age.isnull()].as_matrix() # y即目标年龄 y = known_age[:, 0] # X即特征属性值 X = known_age[:, 1:] # fit到RandomForestRegressor之中 rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1) rfr.fit(X, y) # 用得到的模型进行未知年龄结果预测 predictedAges = rfr.predict(unknown_age[:, 1::]) # 用得到的预测结果填补原缺失数据 df.loc[ (df.Age.isnull()), &apos;Age&apos; ] = predictedAges return df, rfr data_combine, rfr = set_missing_ages(data_combine) 特征处理对名字可以提取到称谓作为一个特征，根据SibSp和Parch可以知道家庭情况，再添加一个FamilySize特征。 data_combine[&apos;title&apos;]=data_combine[&apos;Name&apos;].apply(lambda x: x.split(&apos;, &apos;)[1]).apply(lambda x: x.split(&apos;.&apos;)[0]) data_combine[&apos;FamilySize&apos;]=data_combine[&apos;SibSp&apos;] + data_combine[&apos;Parch&apos;] 下面将一些特征取值为文本的转化成数值取值。 #将所有特征转换成数值型编码 # Sex df = pd.get_dummies(data_combine[&apos;Sex&apos;],prefix=&apos;Sex&apos;) data_combine = pd.concat([data_combine,df],axis=1).drop(&apos;Sex&apos;,axis=1) # Embarked df = pd.get_dummies(data_combine[&apos;Embarked&apos;],prefix=&apos;Embarked&apos;) data_combine = pd.concat([data_combine,df],axis=1).drop(&apos;Embarked&apos;,axis=1) # title data_combine[&apos;title&apos;]=data_combine[&apos;title&apos;].astype(&apos;category&apos;) data_combine[&apos;title&apos;]=data_combine[&apos;title&apos;].cat.codes # Pclass df = pd.get_dummies(data_combine[&apos;Pclass&apos;],prefix=&apos;Pclass&apos;) data_combine = pd.concat([data_combine,df],axis=1).drop(&apos;Pclass&apos;,axis=1) data_combine.drop([&apos;Name&apos;,&apos;SibSp&apos;,&apos;Parch&apos;,&apos;Ticket&apos;],axis=1,inplace=True) 算法预测预测算法采用集成学习中的随机森林，作一个典型的二分类。 from sklearn.ensemble import RandomForestClassifier X_train = data_combine.iloc[:891,:].drop([&quot;PassengerId&quot;,&quot;Survived&quot;], axis=1) Y_train = data_combine.iloc[:891,:][&quot;Survived&quot;] X_test = data_combine.iloc[891:,:].drop([&quot;PassengerId&quot;,&quot;Survived&quot;], axis=1) clf = RandomForestClassifier(n_estimators=300,min_samples_leaf=4) clf.fit(X_train, Y_train) Y_test = clf.predict(X_test) gender_submission = pd.DataFrame({&apos;PassengerId&apos;:data_test.iloc[:,0],&apos;Survived&apos;:Y_test}) gender_submission.to_csv(&apos;gender_submission.csv&apos;, index=None) submission将保存的gender_submission.csv文件提交到kaggle，得到的0.79904，毕竟第一次实践，进入了Top20%，虽然不够优秀，也还可以，算法继续学习之后还待改进。]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据处理—Encoding Categorical Value]]></title>
    <url>%2F2017%2F08%2F30%2F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E2%80%94Encoding-Categorical-Value%2F</url>
    <content type="text"><![CDATA[在机器学习的数据处理中，常常有些特征的值为类型变量（categorical variable），即这些特征对应的值是一些文本，为了便于后期的模型建立，常常将这些文本属性的值转换成数值，即对categorical variable的编码处理。 Data Set数据集假设为： import pandas as pd df = pd.DataFrame([ [&apos;green&apos;, &apos;M&apos;, 11], [&apos;red&apos;, &apos;L&apos;, 22], [&apos;blue&apos;, &apos;XL&apos;, 33]]) df.columns = [&apos;color&apos;, &apos;size&apos;, &apos;prize&apos;] color size prize 0 green M 11 1 red L 22 2 blue XL 33 Replace一种方法是使用DataFrame的自带函数功能，替换函数replace。 encoding_num={&quot;color&quot;:{&quot;green&quot;:0,&quot;red&quot;:1,&quot;blue&quot;:2},&quot;size&quot;:{&quot;M&quot;:0,&quot;L&quot;:1,&quot;XL&quot;:2}} df.replace(encoding_num,inplace=True) df Out: color size prize 0 0 0 10.1 1 1 1 13.5 2 2 2 15.3 One Hot EncodingOne-hot Encoding，又称为一位有效编码，即对每个状态采取一位进行编码。假设某个特征有N个特征值，则需要N位进行编码，且任意时候只有一位有效。 pd.get_dummies(df) Out[28]: prize color_blue color_green color_red size_L size_M size_XL 0 11 0 1 0 0 1 0 1 22 0 0 1 1 0 0 2 33 1 0 0 0 0 1 这种编码方式弊端就是，当某个特征对应特征值很多时，就需要很多位进行编码，使得数据列数过大。 Label Encoding这种编码方式，主要是基于pandas的Categorical模块，将某一列转换成category类型，然后使用category value来编码。 df[&quot;color&quot;]=df[&quot;color&quot;].astype(&apos;category&apos;) df[&quot;size&quot;]=df[&quot;size&quot;].astype(&apos;category&apos;) df[&quot;color&quot;]=df[&quot;color&quot;].cat.codes df[&quot;size&quot;]=df[&quot;size&quot;].cat.codes df Out[37]: color size prize 0 1 1 11 1 2 0 22 2 0 2 33]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从决策树到随机森林]]></title>
    <url>%2F2017%2F08%2F24%2F%E4%BB%8E%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%B0%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%2F</url>
    <content type="text"><![CDATA[学习了决策树算法之后又接触到了随机森林，随机森林可以说是决策树算法的集成加强版。从分类上来说，随机森林属于机器学习中的集成学习，所谓集成学习，顾名思义就是集成一些方法一起来学习，随机森林就是集成很多决策树来实现其分类或者回归的功能。 随机森林之“森林”“森林”表示有很多决策树，每棵决策树都是一个分类器，对于一个输入测试样本，经过森林中的每棵树都会有相应的预测值或者标签，而最终的结果就取决于这些树之间的投票结果作为最终预测结果。每棵随机树都是一个弱分类器，但是通过投票选择，最终组成一个强分类器。 随机森林之“随机”随机森林的随机体现在两个地方：一个是构建单棵决策树时的样本选择随机，一个是决策树分裂的时候选择的特征集随机。 假设有N个样本，那么构建某一棵随机数时，放回抽样选择N个样本，称为bootstrap，这样每棵树的训练集都是不同的，当然也会包括重复样本。 在决策树分类的时候，假设每个样本含有M个特征，对于每一棵树，随机抽取m&lt;&lt;M(有不同的取法，常见的有log2（M)，sqrt（M）等）个特征，在每一次进行树枝分裂的时候都从这m个特征中选取最优分裂点。 随机森林经典python实现及API总结python的sklearn模块集成了众多的机器学习算法，其中也包括随机森林（RandomTree），再结合pandas模块，就可以实现随机森林算法的分类或者回归。 from sklearn.datasets import load_iris from sklearn.ensemble import RandomForestClassifier import pandas as pd import numpy as np iris = load_iris() #导入鸢尾植物数据集 df = pd.DataFrame(iris.data, columns=iris.feature_names) df[&apos;is_train&apos;] = np.random.uniform(0, 1, len(df)) &lt;= .75 #随机选取训练节，大概取3/4 df[&apos;species&apos;] = pd.Categorical.from_codes(iris.target, iris.target_names) #添加从分类变量解码的分类值 train, test = df[df[&apos;is_train&apos;]==True], df[df[&apos;is_train&apos;]==False] features = df.columns[:4] clf = RandomForestClassifier(n_jobs=2) y, _ = pd.factorize(train[&apos;species&apos;]) #将分类结果编码成数值 clf.fit(train[features], y) preds = iris.target_names[clf.predict(test[features])] #将实际结果与预测结果合并成交叉列表输出 print(pd.crosstab(test[&apos;species&apos;], preds, rownames=[&apos;actual&apos;], colnames=[&apos;preds&apos;])) 最终的预测结果如下图： preds setosa versicolor virginica actual setosa 16 0 0 versicolor 0 15 1 virginca 0 3 16 当然，每次运行最终预测结果是不一样的，因为测试集和训练集都是每次随机选取的。 iris = load_iris() #导入鸢尾植物数据集 sklearn模块含有一些机器学习经典的数据集，这里导入了鸢尾植物数据集，导入后iris为字典数据类型，存储了其萼片和花瓣的长宽，一共4个属性，鸢尾植物又分三类。与之相对，iris里有两个属性iris.data，iris.target，data里是一个矩阵，每一列代表了萼片或花瓣的长宽，一共4列，每一列代表某个被测量的鸢尾植物，一共采样了150条记录。 然后又碰到了pandas的一个模块，pandas.Categorical，将一些label转变成categorical variable（分类变量） Categorical.from_codes(codes, categories, ordered=False) 这个函数产生一个categorical type根据codes和categories。 pandas.factorizes 则与之相反，Encode input values as an enumerated type or categorical variable。 返回的结果中：labels : the indexer to the original arrayuniques : ndarray (1-d) or Index python机器学习模块sklearn中的RandomForestClassifier sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=’gini’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None) n_estimators : integer, optional (default=10)&emsp;&emsp;森林中树木数目 criterion : string, optional (default=”gini”)&emsp;&emsp;树枝分裂算法，gini和entropy max_features : int, float, string or None, optional (default=”auto”)&emsp;&emsp;寻找最优分裂点计算采用的特征数目If int, then consider max_features features at each split.If float, then max_features is a percentage and int(max_features * n_features) features are considered at each split.If “auto”, then max_features=sqrt(n_features).If “sqrt”, then max_features=sqrt(n_features) (same as “auto”).If “log2”, then max_features=log2(n_features).If None, then max_features=n_features.Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than max_features features. max_depth : integer or None, optional (default=None)&emsp;&emsp;树的最大深度The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. min_samples_split : int, float, optional (default=2)The minimum number of samples required to split an internal node:If int, then consider min_samples_split as the minimum number.If float, then min_samples_split is a percentage and ceil(min_samples_split * n_samples) are the minimum number of samples for each split.Changed in version 0.18: Added float values for percentages. min_samples_leaf : int, float, optional (default=1)The minimum number of samples required to be at a leaf node:If int, then consider min_samples_leaf as the minimum number.If float, then min_samples_leaf is a percentage and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node.Changed in version 0.18: Added float values for percentages. min_weight_fraction_leaf : float, optional (default=0.)The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided. max_leaf_nodes : int or None, optional (default=None)Grow trees with max_leaf_nodes in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes. min_impurity_split : float,Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf.Deprecated since version 0.19: min_impurity_split has been deprecated in favor of min_impurity_decrease in 0.19 and will be removed in 0.21. Use min_impurity_decrease instead. min_impurity_decrease : float, optional (default=0.)A node will be split if this split induces a decrease of the impurity greater than or equal to this value.The weighted impurity decrease equation is the following: N_t / N (impurity - N_t_R / N_t right_impurity - N_t_L / N_t * left_impurity) where N is the total number of samples, N_t is the number of samples at the current node, N_t_L is the number of samples in the left child, and N_t_R is the number of samples in the right child.N, N_t, N_t_R and N_t_L all refer to the weighted sum, if sample_weight is passed.New in version 0.19. bootstrap : boolean, optional (default=True)Whether bootstrap samples are used when building trees.oob_score : bool (default=False)Whether to use out-of-bag samples to estimate the generalization accuracy. n_jobs : integer, optional (default=1)The number of jobs to run in parallel for both fit and predict. If -1, then the number of jobs is set to the number of cores. random_state : int, RandomState instance or None, optional (default=None)If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random. verbose : int, optional (default=0)Controls the verbosity of the tree building process.warm_start : bool, optional (default=False)When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest. class_weight : dict, list of dicts, “balanced”,“balanced_subsample” or None, optional (default=None) Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y.Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}].The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))The “balanced_subsample” mode is the same as “balanced” except that weights are computed based on the bootstrap sample for every tree grown.For multi-output, the weights of each column of y will be multiplied.Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified. 其余函数： function description apply(X) Apply trees in the forest to X, return leaf indices. decision_path(X) Return the decision path in the forest fit(X, y[, sample_weight]) Build a forest of trees from the training set (X, y). get_params([deep]) Get parameters for this estimator. predict(X) Predict class for X. predict_log_proba(X) Predict class log-probabilities for X. predict_proba(X) Predict class probabilities for X. score(X, y[, sample_weight]) Returns the mean accuracy on the given test data and labels. set_params(**params) Set the parameters of this estimator.]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[决策树算法介绍及python实现]]></title>
    <url>%2F2017%2F08%2F22%2F%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8Apython%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[决策树算法是机器学习中经典的算法之一，既可以作为分类算法，也可以作为回归算法。在做开始入门机器学习这方面内容时，自然就接触到了这方面的知识。因此，本文对决策树算法进行了一些整理，首先对决策树算法的原理进行介绍，并且用python对决策树算法进行代码实现。 决策树算法的概述决策树算法的思想很类似于我们写代码经常用到的if，else if，else，用什么特征来判断if，这就是决策树算法的精髓所在。 上图是一个结构简单的决策树，用于判断贷款用户是否具备偿款能力，根据不同的条件，从根节点拥有房产开始，根据特征不断判断不断分裂到子节点，叶子节点代表最终的分类结果，树枝分裂的地方就是要根据特征来判断。由此可知，决策树最关键的地方在于树枝分叉的地方，即合理选择特征，从根节点开始，经历子节点的分支后，最终到达叶子。从上面来说，决策树算法的基本步骤为：1.从根节点开始2.遍历所有特征作为一种分裂方式，找到最好的分裂特征3.分类成两个或者多个节点4.对子节点同样进行2-3的操作，其实就是第一个递归建树的操作，直到到达叶子节点，即得到分类结果。常见的决策树算法有ID3、C4.5、CART等，下面将分别进行介绍。## ID3算法 ##理论上来说，其实可以有很多种树能够完成这个分类问题，但是如何将这个分类做的比较优呢？有个叫昆兰的大牛将信息论中的熵引入到决策树算法，解决了这个问题。首先，什么是熵？熵的概念源于在物理的热力学，主要是用于描述一个热力学系统的无序程度。信息论的创始人香农将熵引入信息论中，表示不确定性的度量，直观理解为信息含量越多，熵越大，也就是分布越无序。熵的数值定义为：X为样例的集合，P(xi)为样例xi的出现概率。分类特征的选择应该使得分类后更加有序，熵减小，在这里引入了熵的增益这个概念。其中，Sv为采用特征A分类后的，某一个类别样例数占原有的样例数的比例，H(Sv)该分类后类别的熵，用原来的上减去特征A分类后的每个类别的熵乘于比例权重之后的和。这个时候便得到了选取分类特征的方法，即选取使得熵的增益为最大的特征A作为树枝分裂的特征。ID3就是基于熵增益最大的决策树算法。### ID3算法计算实例 ###下面以一个经典的打网球的例子说明如何构建决策树。例子中打网球（play）主要由天气（outlook)、温度（temperature）、湿度（humidity)、风（windy）来确定，样本数据如下： 在本例中S有14个样例，目标变量是是否打球，play=yes or no,yes有9个样例，no有5个样例，首先计算从根节点的信息熵：H(S)=-(9/14log(9/14))-(5/14log(5/14))=0.28305从根节点开始，有四个特征（outlook temperature humidity windy)可以用来进行树枝分裂，首先需要计算这四个特征的信息熵增益，以outlook为例进行计算。特征A（outlook）有三个不同的取值{sunny,overcast,rainy}，这样将原先的数据集S分为3类，其中sunnny有5个样本，2个play=yes，3个play=noovercast有4个样本，4个play=yesrainy有5个样本，3个play=yes，2个play=no根据上面的公式，按outlook分类后的熵为：H（S,A)=5/14sunny熵+4/14overcast熵+5/14rainy熵&emsp;&emsp;&emsp;&emsp;=5/14（-2/5log(2/5)-3/5log(3/5))+4/14(-1log1)+5/14(-3/5log(3/5)-2/5log(2/5))=0.20878所以对于outlook的信息熵增益为G(S,outlook)=H(S)-H(S,A)=0.07427用类似的方法，算出，A取其他三个特征时候的信息熵增益分别为：G(S,temperature)=0.00879G(S,humidity)=0.04567G(S,windy)=0.01448显然，用outlook作为特征A时候，熵增益最大，因此作为第一个节点，即为根节点。这样，S就换分为3个子集，sunny，overcast，rainy，其中overcast熵为0，已经分好类，直接作为叶子节点，而sunny，rainy熵都大于0，采取类似于上述的过程继续选择特征，最后可得决策树为： ID3算法的python代码实现import pandas as pd import math def Tree_building(dataSet): tree = [] if(Calculate_Entropy(dataSet) == 0): #熵为0说明分类已经到达叶子节点 if(dataSet[&apos;play&apos;].sum()==0): #根据play的值到达0或者1叶子节点 tree.append(0) else: tree.append(1) return tree numSamples=len(dataSet) #样例数 Feature_Entropy={} #记录按特征A分类后的熵值的字典 for i in range(1,len(dataSet.columns)-1): Set=dict(list(dataSet.groupby(dataSet.columns[i]))) #取出不同的特征 Entropy=0.0 for key,subSet in Set.items(): Entropy+=(len(subSet)/numSamples)*Calculate_Entropy(subSet) #计算熵 Feature_Entropy[dataSet.columns[i]]=Entropy #选最小熵值的特征分类点，这样熵值增益最大 Feature = min(zip(Feature_Entropy.values(),Feature_Entropy.keys()))[1] Set=dict(list(dataSet.groupby(Feature))) for key,value in Set.items(): subTree=[] subTree.append(Feature) subTree.append(key) subTree.append(Tree_building(value)) #树枝扩展函数的迭代 tree.append(subTree) return tree def Calculate_Entropy(data): numSamples=len(data) #样本总数 P=data.sum()[&apos;play&apos;] #正例数量 N=numSamples-P #反例数量 if((N==0)or(P==0)): Entropy=0 return Entropy Entropy = -P/numSamples*math.log(P/numSamples)-N/numSamples*math.log(N/numSamples) return Entropy if __name__ == &apos;__main__&apos;: data=pd.read_csv(&apos;tennis.csv&apos;) tree=Tree_building(data) print(tree) 具体代码源文件可见我的github。 C4.5 和CART算法C4.5算法ID3算法有一个弊端，因为是选择信息增益最大的特征来分裂，所以更偏向于具有大量属性的特征进行分裂，这样做其实有时候是没有意义的，针对此，有了C4.5算法，对ID3进行了改进。C4.5采用信息增益率来选择分裂特征即：gr(S,A)=gain(S,A)/H(S,A),其中，gain(S,A)为ID3算法的熵的增益，H(S,A)为取特征为A进行分类的的信息熵取A为outlook即为H（S,outlook），H(S,A)=H(S,outlook)= -(5/14)log(5/14) - (5/14)log(5/14) - (4/14)*log(4/14) C4.5算法采用的熵信息增益率，因为分母采用了基于属性A分裂后的信息熵，从而抵消了如果信息A属性取值数目过大带来的影响。 C4.5算法还可以应用于处理连续性的属性则按属性A的取值递增排序，将每对相邻值的中点看作可能的分裂点，对每个可能的分裂点，计算： SL和SR分别对应A属性分类点划分出的两个子集，取使得划分后信息熵最小的取值作为A属性的最佳分裂点，参与后面的运算，不够感觉这样计算量有点多的orz CART算法CART算法的划分基于递归建立二叉树，对于一个变量属性来说，它的划分点是一对连续变量属性值的中点。假设m个样本的集合一个属性有m个连续的值，那么则会有m-1个分裂点，每个分裂点为相邻两个连续值的均值。每个属性的划分按照能减少的杂质的量来进行排序，而杂质的减少量定义为划分前的杂质减去划分后的每个节点的杂质量划分所占比率之和。而杂质度量方法常用Gini指标，假设一个样本共有C类，那么一个节点的Gini不纯度可定义为 那么，按属性A的某个属性值t分裂最后的Gini值为： 分别计算属性A不同属性值的Gini值，取最小的作为A的最佳分类点，然后对于S集此时所有的属性进行上述运算之后，取具有最小的Gini作为分裂属性，其最小的Gini值的属性值作为分裂点。 CART还可以用于作为回归树，但是此时Gini值的算法就不一样，采用的是总方差： 回归树的叶节点所含样本中，其输出变量的平均值就是预测结果。]]></content>
      <tags>
        <tag>机器学习</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[也看战狼2：爬取豆瓣影评做词云]]></title>
    <url>%2F2017%2F08%2F08%2F%E4%B9%9F%E7%9C%8B%E6%88%98%E7%8B%BC2%EF%BC%9A%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E5%BD%B1%E8%AF%84%E5%81%9A%E8%AF%8D%E4%BA%91%2F</url>
    <content type="text"><![CDATA[《战狼2》上映的第二天就去看了，当时觉得还不错，不管是打斗场景还是故事情节，看的都很过瘾，个人觉得可以给4星半。但是这段时间一直看到晚上对《战狼2》各种各样的不同的评论，因此闲暇之余，用爬虫获取了截止于2017.8.8号的豆瓣用户的近14万的评论，对其中的关键词做成了词云。 python爬虫爬取评论代码import requests from bs4 import BeautifulSoup import codecs import time absolute_url = &apos;https://movie.douban.com/subject/26363254/comments&apos; url = &apos;https://movie.douban.com/subject/26363254/comments?start={}&amp;limit=20&amp;sort=new_score&amp;status=P&apos; header={&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:54.0) Gecko/20100101 Firefox/54.0&apos;,&apos;Connection&apos;:&apos;keep-alive&apos;} def html_prase(html, struct): soup=BeautifulSoup(html,&apos;lxml&apos;) comment_nodes = [] comment_nodes = soup.select(struct) xiangdui_link_nodes= soup.select(&apos;#paginator &gt; a&apos;)[0].get(&apos;href&apos;) return comment_nodes,xiangdui_link_nodes if __name__ == &apos;__main__&apos;: #读取cookie数据 f_cookies = open(&apos;cookie.txt&apos;, &apos;r&apos;) cookies = {} for line in f_cookies.read().split(&apos;;&apos;): name, value = line.strip().split(&apos;=&apos;, 1) cookies[name] = value f = codecs.open(&quot;comments.txt&quot;, &apos;a&apos;, encoding=&apos;utf-8&apos;) html = requests.get(url, cookies=cookies, headers=header).content comment_nodes=[] xiangdui_links=[] #获取评论 comment_nodes,xiangdui_link_nodes = html_prase(html , &apos;.comment &gt; p&apos;) soup = BeautifulSoup(html, &apos;lxml&apos;) comment_list = [] for node in comment_nodes: comment_list.append(node.get_text().strip().replace(&quot;\n&quot;, &quot;&quot;) + u&apos;\n&apos;) while(xiangdui_link_nodes!=[]):#每次查看是否有后页，即不断往深处挖掘，获取数据 xiangdui_link = soup.select(&apos;#paginator &gt; a&apos;)[0].get(&apos;href&apos;) #取出后页的相对链接 xiangdui_links.append(xiangdui_link) time.sleep(1) html = requests.get(absolute_url+xiangdui_link_nodes, cookies=cookies, headers=header).content soup = BeautifulSoup(html, &apos;lxml&apos;) comment_nodes, xiangdui_link_nodes = html_prase(html, &apos;.comment &gt; p&apos;) for node in comment_nodes: comment = node.get_text().strip().replace(&quot;\n&quot;, &quot;&quot;) + u&apos;\n&apos; comment_list.append(comment) f.writelines(comment) 在抓取豆瓣影评的时候，一开始我是直接对URL爬虫，仅仅是加了一个header，抓取一段时间，豆瓣的反爬虫策略就将我的IP封掉了，所以我又加入了cookie字段。cookie是一个字典类型的数据，可以以比较简单的方式获取。打开要浏览的豆瓣页面，点击登陆页面后，打开Chrome的开发者模式，开始监听登陆时候的http请求和响应。 这个时候，在Cookie字段可以找到cookie数据，复制后存为txt文件，然后写代码读取txt文件，并存为字典格式数据。 f_cookies = open(&apos;cookie.txt&apos;, &apos;r&apos;) cookies = {} for line in f_cookies.read().split(&apos;;&apos;): name, value = line.strip().split(&apos;=&apos;, 1) cookies[name] = value 用requests对网页进行爬虫抓取之后，此后就是利用Beautifulsoup对获取的html进行解析，获取豆瓣用户评论，以及后页的链接。 对《战狼2》的豆瓣影评链接进行分析，发现每一页链接都是如上图的组成，网页解析可以获取后面的红色字段，实现不断向后页爬虫。最后爬虫结果得到18M左右的数据。 jieba模块提取评论内容关键词# -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Wed Aug 9 09:51:51 2017 @author: lkj &quot;&quot;&quot; import codecs import jieba import matplotlib.pyplot as plt import matplotlib as mpl import numpy as np from collections import Counter zhfont1 = mpl.font_manager.FontProperties(fname=&apos;C:\Windows\Fonts\simsun.ttc&apos;) def draw_bar(labels,quants): width = 0.4 ind = np.linspace(0.5,9.5,10) # make a square figure fig = plt.figure(1) ax = fig.add_subplot(111) # Bar Plot ax.bar(ind-width/2,quants,width,color=&apos;green&apos;) # Set the ticks on x-axis ax.set_xticks(ind) ax.set_xticklabels(labels,fontproperties=zhfont1) # labels ax.set_xlabel(u&apos;关键词&apos;,fontproperties=zhfont1) ax.set_ylabel(u&apos;评论数量&apos;,fontproperties=zhfont1) # title ax.set_title(u&apos;筛选后的TOP10关键词&apos;, bbox={&apos;facecolor&apos;:&apos;0.8&apos;, &apos;pad&apos;:5},fontproperties=zhfont1) #plt.legend(prop=zhfont1) plt.grid(True) plt.show() word_lists = [] # 关键词列表 with codecs.open(&apos;comments.txt&apos;, &apos;r&apos;, encoding=&apos;utf-8&apos;) as f: Lists = f.readlines() # 文本列表 for List in Lists: cut_list = list(jieba.cut(List)) for word in cut_list: word_lists.append(word) word_lists_set = set(word_lists) # 去除重复元素 sort_count = [] word_lists_set = list(word_lists_set) length = len(word_lists_set) print(u&quot;共有%d个关键词&quot; %length) k = 1 for w in word_lists_set: sort_count.append(w + u&apos;:&apos; + str(word_lists.count(w)) + u&quot;次\n&quot;) print (u&quot;%d---&quot; % k + w + u&quot;:&quot; + str(word_lists.count(w)) + u&quot;次&quot;) k += 1 with codecs.open(&apos;count_word.txt&apos;, &apos;w&apos;, encoding=&apos;utf-8&apos;) as f: f.writelines(sort_count) #先取出前100关键词，再进行人为筛选 key_words_TOP100=[] key_words_TOP100=Counter(word_lists).most_common(100) key_words_shaixuan=[key_words_TOP100[6],key_words_TOP100[24],key_words_TOP100[25], key_words_TOP100[30],key_words_TOP100[39],key_words_TOP100[52], key_words_TOP100[60],key_words_TOP100[77],key_words_TOP100[78], key_words_TOP100[94]] labels = [] quants = [] for i in range(10): labels.append(key_words_shaixuan[i][0]) quants.append(key_words_shaixuan[i][1]) draw_bar(labels,quants) 绘制柱形图的时候需要指定字体，不然会出现中文乱码。对关键词TOP100需要进行人为筛选，因为jieba分词会出现很多诸如“我们”之类的在这里无意义的词汇，人为筛选出TOP10关键词如下： 从关键词来看，大多数网友还是看好这部电影的，认为这是大场面的动作戏，达到了好莱坞大片水平，当然也不乏网友认为这是满足吴京个人英雄主义的意淫。 绘制词云# -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Aug 8 21:46:04 2017 @author: lkj &quot;&quot;&quot; # -*- coding:utf-8 -*- import codecs import jieba from scipy.misc import imread from wordcloud import WordCloud # 绘制词云 def save_jieba_result(): # 设置多线程切割 #jieba.enable_parallel(4) with codecs.open(&apos;comments.txt&apos;, encoding=&apos;utf-8&apos;) as f: comment_text = f.read() cut_text = &quot; &quot;.join(jieba.cut(comment_text)) # 将jieba分词得到的关键词用空格连接成为字符串 with codecs.open(&apos;jieba.txt&apos;, &apos;a&apos;, encoding=&apos;utf-8&apos;) as f: f.write(cut_text) def draw_wordcloud2(): with codecs.open(&apos;jieba.txt&apos;, encoding=&apos;utf-8&apos;) as f: comment_text = f.read() color_mask = imread(&quot;zhanlang2.jpg&quot;) # 读取背景图片 stopwords = [u&apos;就是&apos;, u&apos;电影&apos;, u&apos;你们&apos;, u&apos;这么&apos;, u&apos;不过&apos;, u&apos;但是&apos;, u&apos;什么&apos;, u&apos;没有&apos;, u&apos;这个&apos;, u&apos;那个&apos;, u&apos;大家&apos;, u&apos;比较&apos;, u&apos;看到&apos;, u&apos;真是&apos;, u&apos;除了&apos;, u&apos;时候&apos;, u&apos;已经&apos;, u&apos;可以&apos;,u&apos;湄公河&apos;] cloud = WordCloud(font_path=&quot;MSYH.TTF&quot;, background_color=&apos;white&apos;, max_words=2000, max_font_size=200, min_font_size=4, mask=color_mask,stopwords=stopwords) word_cloud = cloud.generate(comment_text) # 产生词云 word_cloud.to_file(&quot;zhanlang2_cloud.jpg&quot;) save_jieba_result() draw_wordcloud2() 词云的绘制需要需要指定font_path，不然会出现中文乱码，我在网上下好微软雅黑的字体（.TTF文件）一并放在目录下调用。 也想说两句电影的后面，红旗飘扬，进过敌战区的吴京身披五星红旗大摇大摆经过，那一刻真的为作为一个中国人而感到自豪。有人觉得看的剧情尴尬，完全是吴京个人英雄主义的表现，但是在《看速度与激情》一个人干翻整个俄罗斯核基地为什么不觉得尴尬呢？我们接受了太多的美国大片以及美国的个人英雄主义的意识形态的输出，有美国队长能够拯救世界，为什么中国队长不行呢？现在我们的国家也是越来越强大，很欣慰能有《湄公河行动》、《战狼2》这样的主旋律大片，虽然有很多不好的声音，也有越来越多的人被感染，而认同，《战狼2》上映两周就登顶国内票房冠军就印证了这一切。 不可否认，在调动自然流露爱国情愫上，《战狼2》是成功的，它在我不知不觉的情感代入里推揉了我的泪腺。当舰长青筋怒暴将憋在心中已久的爱国情感汇成一句“开火”时，男主冷锋独自潜入暴乱的非洲国家拼尽全力解救侨胞、身处险境孤立无援的那种英雄悲凉绝望感，瞬间倾倒而出。祖国，在这一刻，有了最真切感受。 当然，《战狼2》还是存在很多瑕疵，但是也为国产电影树立了一个新的标杆，相信国产大片也会越来越好，期待有更多像《战狼2》这样优秀的电影。 最后，很喜欢这部电影的结尾，中华人民共和国的护照。]]></content>
      <tags>
        <tag>爬虫</tag>
        <tag>电影</tag>
        <tag>python</tag>
      </tags>
  </entry>
</search>
