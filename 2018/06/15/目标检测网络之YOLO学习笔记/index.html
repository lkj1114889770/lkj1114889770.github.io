<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="深度学习,目标检测,CV," />





  <link rel="alternate" href="/atom.xml" title="听歌的小孩" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.2" />






<meta name="description" content="YOLO是一种全新的，与R-CNN思想截然不同的目标检测的方法。R-CNN系列网络是通过proposal region产生可能包含目标物体的bounding box，再通分类器判断是否包含物品以及物品类别，用regression对bounding的坐标、大小进行修正。YOLO则是一种end to end的方式，用一个神经网络，实现了预测出bounding box 的坐标、box中包含物体的置信度和">
<meta name="keywords" content="深度学习,目标检测,CV">
<meta property="og:type" content="article">
<meta property="og:title" content="目标检测网络之YOLO学习笔记">
<meta property="og:url" content="http://yoursite.com/2018/06/15/目标检测网络之YOLO学习笔记/index.html">
<meta property="og:site_name" content="听歌的小孩">
<meta property="og:description" content="YOLO是一种全新的，与R-CNN思想截然不同的目标检测的方法。R-CNN系列网络是通过proposal region产生可能包含目标物体的bounding box，再通分类器判断是否包含物品以及物品类别，用regression对bounding的坐标、大小进行修正。YOLO则是一种end to end的方式，用一个神经网络，实现了预测出bounding box 的坐标、box中包含物体的置信度和">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://i.imgur.com/KVhyOJE.png">
<meta property="og:image" content="https://i.imgur.com/6vox4OO.png">
<meta property="og:image" content="https://i.imgur.com/VgNV9Rc.png">
<meta property="og:image" content="https://i.imgur.com/sehftW1.png">
<meta property="og:image" content="https://i.imgur.com/u90BPbt.png">
<meta property="og:image" content="https://i.imgur.com/BmDEK3e.png">
<meta property="og:image" content="https://i.imgur.com/CsmNs9B.png">
<meta property="og:image" content="https://i.imgur.com/F8AsPNZ.png">
<meta property="og:image" content="https://i.imgur.com/EkQOmSz.png">
<meta property="og:image" content="https://i.imgur.com/XShUyy1.png">
<meta property="og:image" content="https://i.imgur.com/21a8YXR.png">
<meta property="og:image" content="https://i.imgur.com/LCahDqp.png">
<meta property="og:image" content="https://i.imgur.com/zdvKkpA.png">
<meta property="og:image" content="https://i.imgur.com/TnEqUtA.png">
<meta property="og:image" content="https://i.imgur.com/XShUyy1.png">
<meta property="og:image" content="https://i.imgur.com/AYQngjv.png">
<meta property="og:image" content="https://i.imgur.com/ZxUzfO8.png">
<meta property="og:updated_time" content="2018-09-20T08:01:32.814Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="目标检测网络之YOLO学习笔记">
<meta name="twitter:description" content="YOLO是一种全新的，与R-CNN思想截然不同的目标检测的方法。R-CNN系列网络是通过proposal region产生可能包含目标物体的bounding box，再通分类器判断是否包含物品以及物品类别，用regression对bounding的坐标、大小进行修正。YOLO则是一种end to end的方式，用一个神经网络，实现了预测出bounding box 的坐标、box中包含物体的置信度和">
<meta name="twitter:image" content="https://i.imgur.com/KVhyOJE.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/06/15/目标检测网络之YOLO学习笔记/"/>





  <title>目标检测网络之YOLO学习笔记 | 听歌的小孩</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>
	<a href="https://github.com/lkj1114889770"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">听歌的小孩</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">好好学习，好好科研</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/15/目标检测网络之YOLO学习笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="听歌的小孩">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/touxiang.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="听歌的小孩">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">目标检测网络之YOLO学习笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-15T14:59:34+08:00">
                2018-06-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  5k
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>YOLO是一种全新的，与R-CNN思想截然不同的目标检测的方法。R-CNN系列网络是通过proposal region产生可能包含目标物体的bounding box，再通分类器判断是否包含物品以及物品类别，用regression对bounding的坐标、大小进行修正。YOLO则是一种end to end的方式，用一个神经网络，实现了预测出bounding box 的坐标、box中包含物体的置信度和物体的probabilities，因此检测速度更快，训练相对更加简单，当然相对来说也带来一些其他缺点。<br><a id="more"></a></p>
<p>YOLO项目主页<a href="https://pjreddie.com/yolo/" target="_blank" rel="external">地址</a><br>YOLO1 <a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="external">论文</a><br>YOLO2 <a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="external">论文</a><br>YOLO3 <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="external">论文</a></p>
<h2 id="YOLO-v1"><a href="#YOLO-v1" class="headerlink" title="YOLO v1"></a>YOLO v1</h2><p>YOLO使用来自整张图片的feature map来预测bounding box和class，因此可以保持较高的精度。YOLO将整张图片分成S×S的网格，如果一个目标的中心落入到网格单元中，那么这个网格单元负责这个目标的检测。</p>
<div align="center"><br>    <img src="https://i.imgur.com/KVhyOJE.png" width="300" height="300"><br></div><br>每个网格单元预测B个bounding box和confidence score，confidence score反应了box包含目标的可信度，论文中将可confidence score定义为：<br><div align="center"><br>    <img src="https://i.imgur.com/6vox4OO.png" height="30"><br></div><br>，因此，如果没有目标存在confidence score为0，否则应该为IOU(intersection over union)，即真实框和预测框的交集部分。所以每个bounding box的预测值包括(x,y,w,h.confidence score). (x,y)表示预测的box中心相对于网格单元的的位置，(w,h)是用整个图片大小进行归一化的宽度和高度，另外，针对C个类别，每个类别需要预测一个条件概率，即：<br><div align="center"><br>    <img src="https://i.imgur.com/VgNV9Rc.png" height="30"><br></div><br>最终得到box中包含某个特定物品的概率为：<br><div align="center"><br>    <img src="https://i.imgur.com/sehftW1.png" height="40"><br></div><br>整个过程如下图所示。<br><div align="center"><br>    <img src="https://i.imgur.com/u90BPbt.png" width="700" height="400"><br></div>

<p>总结来说，YOLO网络将检测问题转换成regression，首先将整张图片转换成S×S的网格，并且每个网格单元预测<br>B个边界框，这些边界框的(x,y,w,h,confidence score)以及C个类别概率,这些预测被编码为S×S×(B*5+C)<br>的张量。</p>
<h3 id="Network-Design"><a href="#Network-Design" class="headerlink" title="Network Design"></a>Network Design</h3><p>YOLO1的网络结构设计借鉴了GoodLeNet模型，包含了24个卷积层和2个全连接层，YOLO未使用inception module，而是使用1x1卷积层和）3x3卷积层简单替代，交替出现的1x1卷积层实现了跨通道信息融合以及通道数目降低。</p>
<div align="center"><br>    <img src="https://i.imgur.com/BmDEK3e.png"><br></div>

<h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><ol>
<li>使用 ImageNet 1000 类数据训练YOLO网络的前20个卷积层+1个average池化层+1个全连接层。</li>
<li>用上面得到的前20个卷积层网络参数来初始化YOLO模型前20个卷积层的网络参数，加入后面的4层卷积层以及2层全连接层进行detection的训练，detection通常需要有细密纹理的视觉信息,所以为提高图像精度，在训练检测模型时，将输入图像分辨率从224 × 224 resize到448x448。</li>
<li>最后一层预测类概率和边界框坐标。我们通过图像宽度和高度来规范(w,h)，使它们落在0和1之间。我们将边界框(x,y)坐标参数化为特定网格单元位置的偏移量，所以它们边界也在0和1之间。</li>
</ol>
<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>YOLO1的误差计算对于分类误差和定位误差用了不同的权重，对包含与不包含物品的box的误差权重也进行了区分。具体来说，论文中增加了边界框坐标预测损失，并减少了不包含目标边界框的置信度预测损失，使用两个参数λcoord和λnoobj来完成这个工作，论文中设置了λcoord=5和λnoobj=0.5。<br>另一个问题是平方和误差权重在大框和小框中进行了区分。相同的误差下，小框误差的重要性肯定更好，论文中用了一个很巧妙的方法，<strong>直接预测边界框宽度和高度的平方根，而不是宽度和高度</strong>。根据y=x^1/2的函数就可以知道，函数斜率是随着x的增大而减小的，这样就可以提高小框的误差权重，真的巧妙。<br>YOLO每个网格单元预测多个box。在训练时，每个目标我们只需要一个box来负责，选定的原则是与真实框具有最大的IOU。</p>
<div align="center"><br>    <img src="https://i.imgur.com/CsmNs9B.png"><br></div>

<h3 id="Shortcoming"><a href="#Shortcoming" class="headerlink" title="Shortcoming"></a>Shortcoming</h3><p>YOLO对边界框预测强加空间约束，因为每个网格单元只预测两个盒子，只能有一个类别。这个空间约束限制了我们的模型可以预测的邻近目标的数量，因此在小物品的检测上比较局限。</p>
<h2 id="YOLO-v2"><a href="#YOLO-v2" class="headerlink" title="YOLO v2"></a>YOLO v2</h2><p>为提高物体定位精准性和召回率，YOLO2对网络结构的设计进行了改进，输出层使用卷积层替代YOLO的全连接层，联合使用coco物体检测标注数据和imagenet物体分类标注数据训练物体检测模型。相比YOLO，YOLO9000在识别种类、精度、速度、和定位准确性等方面都有大大提升。</p>
<h3 id="Better"><a href="#Better" class="headerlink" title="Better"></a>Better</h3><h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><p>YOLO2取消了dropout，在所有的卷积层中加入Batch Normalization。</p>
<h4 id="High-Resolution-Classifier"><a href="#High-Resolution-Classifier" class="headerlink" title="High Resolution Classifier"></a>High Resolution Classifier</h4><p>YOLO2将ImageNet以448×448 的分辨率微调最初的分类网络，迭代10 epochs。</p>
<h4 id="Convolutional-With-Anchor-Boxes"><a href="#Convolutional-With-Anchor-Boxes" class="headerlink" title="Convolutional With Anchor Boxes"></a>Convolutional With Anchor Boxes</h4><p>借鉴faster R-CNN的思想，引入anchor box，取消全连接层来进行预测，改用卷积层作为预测层对anchor box的offset和confidence进行预测。去除了一个池化层，使得输出特征具有更高的分辨率，将图片输入尺寸resize为416而非448，使得特征图大小为奇数，所以有一个中心单元格。目标，特别是大目标，倾向于占据图像的中心，所以在中心有一个单一的位置可以很好的预测这些目标，而不是四个位置都在中心附近。YOLO的卷积层将图像下采样32倍，所以通过使用输入图像416，我们得到13×13的输出特征图。同时，使用anchor box进行预测的时候，解耦空间位置预测与类别预测，对每个anchor box都预测object和class，仍然沿用YOLO1，目标检测仍然是预测proposed box和ground truth的IOU，类别预测（class predictions）仍然是存在object下的条件概率。</p>
<h4 id="Dimension-Clusters"><a href="#Dimension-Clusters" class="headerlink" title="Dimension Clusters"></a>Dimension Clusters</h4><p>YOLO2不再采用手动挑选的box尺寸，而是对训练集的box尺寸进行k-means聚类，因为聚类的目的是想要更好的IOU，所以聚类的距离使用下列公式：</p>
<div align="center"><br>    <img src="https://i.imgur.com/F8AsPNZ.png" height="40"><br></div><br>对不同的k值采用k-means聚类算法，即对数据集的ground truth聚类，在VOC和COCO数据集上的bounding box得到的结果如下图：<br><div align="center"><br>    <img src="https://i.imgur.com/EkQOmSz.png"><br></div>

<p>根据上图，k=5的时候，模型的复杂度和IOU能够得到一个不错的trade off。</p>
<h4 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a>Direct location prediction</h4><p>对于位置坐标，YOLO2没有采用R-CNN的预测偏移，而是仍然类似于YOLO1中的，他预测相对于网格单元的位置坐标，将ground truth也限制在0-1之间，使用logistic activation 来实现。网络为每个边界框预测tx，ty，th，tw和to这5个坐标。如果网格单元从图像的左上角偏移（Cx，Cy），给定的anchor的宽度，高度分比为Pw，Ph那么预测结果为：</p>
<div align="center"><br>    <img src="https://i.imgur.com/XShUyy1.png"><br></div><br><div align="center"><br>    <img src="https://i.imgur.com/21a8YXR.png"><br></div>

<h4 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a>Fine-Grained Features</h4><p>在13×13特征图上检测可以很容易检测到大目标，从更小粒度的特征图中可以更好地检测小物体，YOLO2添加一个passthrough layer从前一层26×26的特征图进行融合。传递层通过将相邻特征堆叠到不同的通道而不是堆叠到空间位置，将较高分辨率特征与低分辨率特征相连，类似于ResNet中的标识映射。这将26×26×512特征映射转换为13×13×2048特征映射，其可以与原始特征连接。</p>
<h4 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h4><p>添加anchor box后，YOLO2将分辨率更改为416×416。然而，由于模型只使用卷积层和池化层，它可以在运行中调整大小。为了使YOLOv2能够在不同大小的图像上运行，相比于固定输入图像大小，YOLO2每隔几次迭代更改网络。每迭代10个batch网络随机选择一个新的图像尺寸大小。因为模型以32的因子下采样，YOLO2从以下32的倍数中抽取：{320,352，…，608}。因此，最小的选项是320×320，最大的是608×608.调整网络的大小，并继续训练。<br>这种训练方法迫使网络学习在各种输入维度上很好地预测。这意味着相同的网络可以预测不同分辨率的检测。网络在更小的尺寸下运行更快，因此YOLO2在速度和精度之间提供了一个简单的折衷。</p>
<h3 id="Faster"><a href="#Faster" class="headerlink" title="Faster"></a>Faster</h3><h4 id="Darknet-19"><a href="#Darknet-19" class="headerlink" title="Darknet-19"></a>Darknet-19</h4><p>YOLO2大多数3×3的过滤器，并在每个池化步骤后将通道数量加倍，使用全局平均池进行预测，使用1×1滤波器以压缩3×3卷积之间的特征，最终模型，称为Darknet-19，有19卷积层和5个最大池化层，详见下图。</p>
<div align="center"><br>    <img src="https://i.imgur.com/LCahDqp.png"><br></div>

<h4 id="Training-for-classification"><a href="#Training-for-classification" class="headerlink" title="Training for classification"></a>Training for classification</h4><p>使用Darknet19在标准ImageNet 1000类分类数据集上训练，在训练期间，使用数据增强技巧。</p>
<h4 id="Training-for-detection"><a href="#Training-for-detection" class="headerlink" title="Training for detection"></a>Training for detection</h4><p>为了训练检测器，修改上面的网络，移除最后的卷积层，添加3个3×3卷积层，最后增加1×1卷积层，其输出为我们需要的检测维度，如对于VOC数据集，预测5个box，每个具有5个坐标，每个box20个类，因此125个过滤器。还添加了从最后的3×3×512层到第二到最后的卷积层的传递层passthrough layer，使得模型可以使用细粒度特征。</p>
<h3 id="Stronger"><a href="#Stronger" class="headerlink" title="Stronger"></a>Stronger</h3><p>构建了一种分层分类模型（WordTree），提出了一种关于分类和检测数据的联合训练机制。</p>
<div align="center"><br>    <img src="https://i.imgur.com/zdvKkpA.png"><br></div><br><div align="center"><br>    <img src="https://i.imgur.com/TnEqUtA.png"><br></div>

<p>ImageNet数据量更大，用于训练分类，COCO和VOC用于训练检测，ImageN对应分类有9000多种，COCO只有80种对应目标检测，通过wordTree来combine，来自分类的图片只计算分类的loss，来自检测集的图片计算完整的loss。</p>
<h2 id="YOLO-v3"><a href="#YOLO-v3" class="headerlink" title="YOLO v3"></a>YOLO v3</h2><p>YOLO3 对于YOLO2有了一些改进，总的来说有几点：加深了网络，用了上采样，残差网络，多尺度预测，下面详细说明。</p>
<h3 id="Bounding-Box-Prediction"><a href="#Bounding-Box-Prediction" class="headerlink" title="Bounding Box Prediction"></a>Bounding Box Prediction</h3><p>坐标预测仍然沿用YOLO2的，yolov3对每个bounding box预测四个坐标值(tx, ty, tw, th)，对于预测的cell根据图像左上角的偏移(cx, cy)，以及之前得到bounding box的宽和高pw, ph可以对bounding box按如下的方式进行预测：</p>
<div align="center"><br>    <img src="https://i.imgur.com/XShUyy1.png"><br></div>

<p>训练的时候，loss的计算采用sum of squared error loss（平方和距离误差损失），yolov3对每个bounding box通过逻辑回归预测一个物体的得分，如果预测的这个bounding box与真实的边框值大部分重合且比其他所有预测的要好，那么这个值就为1.如果overlap没有达到一个阈值（yolov3中这里设定的阈值是0.5），那么这个预测的bounding box将会被忽略。YOLO3论文中使用的阈值是0.5.每个object只会分配一个bounding box，所以对应没有分配有ground truth object的box，其坐标损失和预测损失不需要计入，只需考虑objectness loss。If a bounding box prior is not assigned to a ground truth object it incurs no loss for coordinate or class predictions, only objectness.</p>
<h3 id="Class-Prediction"><a href="#Class-Prediction" class="headerlink" title="Class Prediction"></a>Class Prediction</h3><p>每个框预测分类，bounding box使用多标签分类（multi-label classification）。论文中说没有使用softmax分类，只是使用了简单的逻辑回归进行分类，采用的二值交叉熵损失（binary cross-entropy loss）。<br>Each box predicts the classes the bounding box may contain using multilabel classification. We do not use a softmax as we have found it is unnecessary for good performance, instead we simply use independent logistic classifiers. During training we use binary cross-entropy loss for the class predictions.<br>This formulation helps when we move to more complex domains like the Open Images Dataset. In this dataset there are many overlapping labels (i.e. Woman and Person). Using a softmax imposes the assumption that each box has exactly one class which is often not the case. A multilabel approach better models the data.</p>
<h3 id="Predictions-Across-Scales"><a href="#Predictions-Across-Scales" class="headerlink" title="Predictions Across Scales"></a>Predictions Across Scales</h3><p>YOLO3在三种不同尺度来预测box，应用一个类似于特征金字塔网络（feature pyramid network）上提取特征，如下图：</p>
<div align="center"><br>    <img src="https://i.imgur.com/AYQngjv.png"><br></div>

<p>对于第一个scale的预测，即base feature extractor，最后预测得到一个3-d tensor，包含bounding box,objectness,class prediction.比如在COCO数据集中有80类物品，每一个scale预测3个box，所以tensor得到为（N×N×[3*(4+1+80)]）。<br>next scale，从上一步2 layer previous的feature map中进行上采样，然后从特征提取网络中的取earlier feature 与上采样后的进行合并，得到更多信息的语义，以及从earlier feature map可以得到更细粒度的特征。最后的scale采用前述类似的方法进行。可能实际代码更能体现这个过程，如下：<br>三种跨尺度预测</p>
<pre><code>predict boxes at 3 different scales
&apos;&apos;&apos;
def build(self, feat_ex, res18, res10):
    self.conv52 = self.conv_layer(feat_ex, 1, 1, 1024, 512, True, &apos;conv_head_52&apos;)          # 13x512
    self.conv53 = self.conv_layer(self.conv52, 3, 1, 512, 1024, True, &apos;conv_head_53&apos;)   # 13x1024
    self.conv54 = self.conv_layer(self.conv53, 1, 1, 1024, 512, True, &apos;conv_head_54&apos;)   # 13x512
    self.conv55 = self.conv_layer(self.conv54, 3, 1, 512, 1024, True, &apos;conv_head_55&apos;)   # 13x1024
    self.conv56 = self.conv_layer(self.conv55, 1, 1, 1024, 512, True, &apos;conv_head_56&apos;)   # 13x512
    self.conv57 = self.conv_layer(self.conv56, 3, 1, 512, 1024, True, &apos;conv_head_57&apos;)   # 13x1024
    self.conv58 = self.conv_layer(self.conv57, 1, 1, 1024, 75, False, &apos;conv_head_58&apos;)   # 13x75
    # follow yolo layer mask = 6,7,8
    self.conv59 = self.conv_layer(self.conv56, 1, 1, 512, 256, True, &apos;conv_head_59&apos;)    # 13x256
    size = tf.shape(self.conv59)[1]
    self.upsample0 = tf.image.resize_nearest_neighbor(self.conv59, [2*size, 2*size],    # 上采样
                                                      name=&apos;upsample_0&apos;)                # 26x256
    self.route0 = tf.concat([self.upsample0, res18], axis=-1, name=&apos;route_0&apos;)           # 26x768
    self.conv60 = self.conv_layer(self.route0, 1, 1, 768, 256, True, &apos;conv_head_60&apos;)    # 26x256
    self.conv61 = self.conv_layer(self.conv60, 3, 1, 256, 512, True, &apos;conv_head_61&apos;)    # 26x512
    self.conv62 = self.conv_layer(self.conv61, 1, 1, 512, 256, True, &apos;conv_head_62&apos;)    # 26x256
    self.conv63 = self.conv_layer(self.conv62, 3, 1, 256, 512, True, &apos;conv_head_63&apos;)    # 26x512
    self.conv64 = self.conv_layer(self.conv63, 1, 1, 512, 256, True, &apos;conv_head_64&apos;)    # 26x256
    self.conv65 = self.conv_layer(self.conv64, 3, 1, 256, 512, True, &apos;conv_head_65&apos;)    # 26x512
    self.conv66 = self.conv_layer(self.conv65, 1, 1, 512, 75, False, &apos;conv_head_66&apos;)    # 26x75
    # follow yolo layer mask = 3,4,5
    self.conv67 = self.conv_layer(self.conv64, 1, 1, 256, 128, True, &apos;conv_head_67&apos;)    # 26x128
    size = tf.shape(self.conv67)[1]
    self.upsample1 = tf.image.resize_nearest_neighbor(self.conv67, [2 * size, 2 * size],
                                                      name=&apos;upsample_1&apos;)                # 52x128
    self.route1 = tf.concat([self.upsample1, res10], axis=-1, name=&apos;route_1&apos;)           # 52x384
    self.conv68 = self.conv_layer(self.route1, 1, 1, 384, 128, True, &apos;conv_head_68&apos;)    # 52x128
    self.conv69 = self.conv_layer(self.conv68, 3, 1, 128, 256, True, &apos;conv_head_69&apos;)    # 52x256
    self.conv70 = self.conv_layer(self.conv69, 1, 1, 256, 128, True, &apos;conv_head_70&apos;)    # 52x128
    self.conv71 = self.conv_layer(self.conv70, 3, 1, 128, 256, True, &apos;conv_head_71&apos;)    # 52x256
    self.conv72 = self.conv_layer(self.conv71, 1, 1, 256, 128, True, &apos;conv_head_72&apos;)    # 52x128
    self.conv73 = self.conv_layer(self.conv72, 3, 1, 128, 256, True, &apos;conv_head_73&apos;)    # 52x256
    self.conv74 = self.conv_layer(self.conv73, 1, 1, 256, 75, False, &apos;conv_head_74&apos;)    # 52x75
    # follow yolo layer mask = 0,1,2

    return self.conv74, self.conv66, self.conv58
</code></pre><p>上面是最后的预测部分，需要输入的三个特征从Darknet-53网络中得到的，输出地方做了注释，Darknet-53网络结构如下：</p>
<pre><code>def build(self, img, istraining, decay_bn=0.99):
   self.phase_train = istraining
   self.decay_bn = decay_bn
   self.conv0 = self.conv_layer(bottom=img, size=3, stride=1, in_channels=3,   # 416x3
                                out_channels=32, name=&apos;conv_0&apos;)                # 416x32
   self.conv1 = self.conv_layer(bottom=self.conv0, size=3, stride=2, in_channels=32,
                                out_channels=64, name=&apos;conv_1&apos;)                # 208x64
   self.conv2 = self.conv_layer(bottom=self.conv1, size=1, stride=1, in_channels=64,
                                out_channels=32, name=&apos;conv_2&apos;)                # 208x32
   self.conv3 = self.conv_layer(bottom=self.conv2, size=3, stride=1, in_channels=32,
                                out_channels=64, name=&apos;conv_3&apos;)                # 208x64
   self.res0 = self.conv3 + self.conv1                                         # 208x64
   self.conv4 = self.conv_layer(bottom=self.res0, size=3, stride=2, in_channels=64,
                                out_channels=128, name=&apos;conv_4&apos;)               # 104x128
   self.conv5 = self.conv_layer(bottom=self.conv4, size=1, stride=1, in_channels=128,
                                out_channels=64, name=&apos;conv_5&apos;)                # 104x64
   self.conv6 = self.conv_layer(bottom=self.conv5, size=3, stride=1, in_channels=64,
                                out_channels=128, name=&apos;conv_6&apos;)               # 104x128
   self.res1 = self.conv6 + self.conv4     # 128                               # 104x128
   self.conv7 = self.conv_layer(bottom=self.res1, size=1, stride=1, in_channels=128,
                                out_channels=64, name=&apos;conv_7&apos;)                # 104x64
   self.conv8 = self.conv_layer(bottom=self.conv7, size=3, stride=1, in_channels=64,
                                out_channels=128, name=&apos;conv_8&apos;)               # 104x128
   self.res2 = self.conv8 + self.res1      # 128                               # 104x128
   self.conv9 = self.conv_layer(bottom=self.res2, size=3, stride=2, in_channels=128,
                                out_channels=256, name=&apos;conv_9&apos;)               # 52x256
   self.conv10 = self.conv_layer(bottom=self.conv9, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_10&apos;)             # 52x128
   self.conv11 = self.conv_layer(bottom=self.conv10, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_11&apos;)             # 52x256
   self.res3 = self.conv11 + self.conv9                                        # 52x256
   self.conv12 = self.conv_layer(bottom=self.res3, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_12&apos;)             # 52x128
   self.conv13 = self.conv_layer(bottom=self.conv12, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_13&apos;)             # 52x256
   self.res4 = self.conv13 + self.res3                                         # 52x256
   self.conv14 = self.conv_layer(bottom=self.res4, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_14&apos;)             # 52x128
   self.conv15 = self.conv_layer(bottom=self.conv14, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_15&apos;)             # 52x256
   self.res5 = self.conv15 + self.res4                                         # 52x256
   self.conv16 = self.conv_layer(bottom=self.res5, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_16&apos;)             # 52x128
   self.conv17 = self.conv_layer(bottom=self.conv16, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_17&apos;)             # 52x256
   self.res6 = self.conv17 + self.res5                                         # 52x256
   self.conv18 = self.conv_layer(bottom=self.res6, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_18&apos;)             # 52x128
   self.conv19 = self.conv_layer(bottom=self.conv18, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_19&apos;)             # 52x256
   self.res7 = self.conv19 + self.res6                                         # 52x256
   self.conv20 = self.conv_layer(bottom=self.res7, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_20&apos;)             # 52x128
   self.conv21 = self.conv_layer(bottom=self.conv20, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_21&apos;)             # 52x256
   self.res8 = self.conv21 + self.res7                                         # 52x256
   self.conv22 = self.conv_layer(bottom=self.res8, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_22&apos;)             # 52x128
   self.conv23 = self.conv_layer(bottom=self.conv22, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_23&apos;)             # 52x256
   self.res9 = self.conv23 + self.res8                                         # 52x256
   self.conv24 = self.conv_layer(bottom=self.res9, size=1, stride=1, in_channels=256,
                                 out_channels=128, name=&apos;conv_24&apos;)             # 52x128
   self.conv25 = self.conv_layer(bottom=self.conv24, size=3, stride=1, in_channels=128,
                                 out_channels=256, name=&apos;conv_25&apos;)             # 52x256
   self.res10 = self.conv25 + self.res9                                        # 52x256 一个输出的特征尺度
   self.conv26 = self.conv_layer(bottom=self.res10, size=3, stride=2, in_channels=256,
                                 out_channels=512, name=&apos;conv_26&apos;)             # 26x512
   self.conv27 = self.conv_layer(bottom=self.conv26, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_27&apos;)             # 26x256
   self.conv28 = self.conv_layer(bottom=self.conv27, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_28&apos;)             # 26x512
   self.res11 = self.conv28 + self.conv26                                      # 26x512
   self.conv29 = self.conv_layer(bottom=self.res11, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_29&apos;)             # 26x256
   self.conv30 = self.conv_layer(bottom=self.conv29, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_30&apos;)             # 26x512
   self.res12 = self.conv30 + self.res11                                       # 26x512
   self.conv31 = self.conv_layer(bottom=self.res12, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_31&apos;)             # 26x256
   self.conv32 = self.conv_layer(bottom=self.conv31, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_32&apos;)             # 26x512
   self.res13 = self.conv32 + self.res12                                       # 26x512
   self.conv33 = self.conv_layer(bottom=self.res13, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_33&apos;)             # 26x256
   self.conv34 = self.conv_layer(bottom=self.conv33, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_34&apos;)             # 26x512
   self.res14 = self.conv34 + self.res13                                       # 26x512
   self.conv35 = self.conv_layer(bottom=self.res14, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_35&apos;)             # 26x256
   self.conv36 = self.conv_layer(bottom=self.conv35, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_36&apos;)             # 26x512
   self.res15 = self.conv36 + self.res14                                       # 26x512
   self.conv37 = self.conv_layer(bottom=self.res15, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_37&apos;)             # 26x256
   self.conv38 = self.conv_layer(bottom=self.conv37, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_38&apos;)             # 26x512
   self.res16 = self.conv38 + self.res15                                       # 26x512
   self.conv39 = self.conv_layer(bottom=self.res16, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_39&apos;)             # 26x256
   self.conv40 = self.conv_layer(bottom=self.conv39, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_40&apos;)             # 26x512
   self.res17 = self.conv40 + self.res16                                       # 26x512
   self.conv41 = self.conv_layer(bottom=self.res17, size=1, stride=1, in_channels=512,
                                 out_channels=256, name=&apos;conv_41&apos;)             # 26x256
   self.conv42 = self.conv_layer(bottom=self.conv41, size=3, stride=1, in_channels=256,
                                 out_channels=512, name=&apos;conv_42&apos;)             # 26x512
   self.res18 = self.conv42 + self.res17                                       # 26x512，一个输出的特征尺度
   self.conv43 = self.conv_layer(bottom=self.res18, size=3, stride=2, in_channels=512,
                                 out_channels=1024, name=&apos;conv_43&apos;)            # 13x1024
   self.conv44 = self.conv_layer(bottom=self.conv43, size=1, stride=1, in_channels=1024,
                                 out_channels=512, name=&apos;conv_44&apos;)             # 13x512
   self.conv45 = self.conv_layer(bottom=self.conv44, size=3, stride=1, in_channels=512,
                                 out_channels=1024, name=&apos;conv_45&apos;)            # 13x1024
   self.res19 = self.conv45 + self.conv43                                      # 13x1024
   self.conv46 = self.conv_layer(bottom=self.res19, size=1, stride=1, in_channels=1024,
                                 out_channels=512, name=&apos;conv_46&apos;)             # 13x512
   self.conv47 = self.conv_layer(bottom=self.conv44, size=3, stride=1, in_channels=512,
                                 out_channels=1024, name=&apos;conv_47&apos;)            # 13x1024
   self.res20 = self.conv47 + self.res19                                       # 13x1024
   self.conv48 = self.conv_layer(bottom=self.res20, size=1, stride=1, in_channels=1024,
                                 out_channels=512, name=&apos;conv_48&apos;)             # 13x512
   self.conv49 = self.conv_layer(bottom=self.conv48, size=3, stride=1, in_channels=512,
                                 out_channels=1024, name=&apos;conv_49&apos;)            # 13x1024
   self.res21 = self.conv49 + self.res20                                       # 13x1024
   self.conv50 = self.conv_layer(bottom=self.res21, size=1, stride=1, in_channels=1024,
                                 out_channels=512, name=&apos;conv_50&apos;)             # 13x512
   self.conv51 = self.conv_layer(bottom=self.conv50, size=3, stride=1, in_channels=512,
                                 out_channels=1024, name=&apos;conv_51&apos;)            # 13x1024
   self.res23 = self.conv51 + self.res21                                       # 13x1024
   return self.res23  # 最后输出特征
</code></pre><p>同样采用k-means聚类的到anchor box的尺寸。选取了9种，3中不同的scale：(10×13); (16×30); (33×23); (30×61); (62×45); (59×119); (116 × 90); (156 × 198); (373 × 326).</p>
<h3 id="Feature-Extractor"><a href="#Feature-Extractor" class="headerlink" title="Feature Extractor"></a>Feature Extractor</h3><p>YOLO3的新的更深的网络，Darknet-53，实现细节可参见上面的代码</p>
<div align="center"><br>    <img src="https://i.imgur.com/ZxUzfO8.png"><br></div>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/目标检测/" rel="tag"># 目标检测</a>
          
            <a href="/tags/CV/" rel="tag"># CV</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/05/11/PCL的python库安装for-Ubuntu16-04/" rel="next" title="PCL的python库安装for Ubuntu16.04">
                <i class="fa fa-chevron-left"></i> PCL的python库安装for Ubuntu16.04
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/07/表扬一下pycharm/" rel="prev" title="表扬一下pycharm">
                表扬一下pycharm <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
  <a class="jiathis_button_tsina"></a>
  <a class="jiathis_button_tqq"></a>
  <a class="jiathis_button_weixin"></a>
  <a class="jiathis_button_cqq"></a>
  <a class="jiathis_button_douban"></a>
  <a class="jiathis_button_renren"></a>
  <a class="jiathis_button_qzone"></a>
  <a class="jiathis_button_kaixin001"></a>
  <a class="jiathis_button_copy"></a>
  <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank"></a>
  <a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" >
  var jiathis_config={
    hideMore:false
  }
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js" charset="utf-8"></script>
<!-- JiaThis Button END -->

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/touxiang.jpg"
               alt="听歌的小孩" />
          <p class="site-author-name" itemprop="name">听歌的小孩</p>
           
              <p class="site-description motion-element" itemprop="description">瞎捣鼓的小空间  Email:kaijianliu@qq.com</p>
          
        </div>
		
		<div id="music163player">
			<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=22650708&auto=0&height=66">
			</iframe>
		</div>
		
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">30</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com//lkj1114889770" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                    
                      GitHub
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/3313734867" target="_blank" title="新浪微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                    
                      新浪微博
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://bloger.5pipi.win/" title="皮皮鲁" target="_blank">皮皮鲁</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://blog.kusuri.cc" title="Kusuri's Blog" target="_blank">Kusuri's Blog</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://rogoso.info/" title="rogoso's Blog" target="_blank">rogoso's Blog</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLO-v1"><span class="nav-number">1.</span> <span class="nav-text">YOLO v1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Network-Design"><span class="nav-number">1.1.</span> <span class="nav-text">Network Design</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Training"><span class="nav-number">1.2.</span> <span class="nav-text">Training</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Loss"><span class="nav-number">1.3.</span> <span class="nav-text">Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shortcoming"><span class="nav-number">1.4.</span> <span class="nav-text">Shortcoming</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLO-v2"><span class="nav-number">2.</span> <span class="nav-text">YOLO v2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Better"><span class="nav-number">2.1.</span> <span class="nav-text">Better</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Batch-Normalization"><span class="nav-number">2.1.1.</span> <span class="nav-text">Batch Normalization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#High-Resolution-Classifier"><span class="nav-number">2.1.2.</span> <span class="nav-text">High Resolution Classifier</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Convolutional-With-Anchor-Boxes"><span class="nav-number">2.1.3.</span> <span class="nav-text">Convolutional With Anchor Boxes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dimension-Clusters"><span class="nav-number">2.1.4.</span> <span class="nav-text">Dimension Clusters</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Direct-location-prediction"><span class="nav-number">2.1.5.</span> <span class="nav-text">Direct location prediction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Fine-Grained-Features"><span class="nav-number">2.1.6.</span> <span class="nav-text">Fine-Grained Features</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Multi-Scale-Training"><span class="nav-number">2.1.7.</span> <span class="nav-text">Multi-Scale Training</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Faster"><span class="nav-number">2.2.</span> <span class="nav-text">Faster</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Darknet-19"><span class="nav-number">2.2.1.</span> <span class="nav-text">Darknet-19</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-for-classification"><span class="nav-number">2.2.2.</span> <span class="nav-text">Training for classification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Training-for-detection"><span class="nav-number">2.2.3.</span> <span class="nav-text">Training for detection</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stronger"><span class="nav-number">2.3.</span> <span class="nav-text">Stronger</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLO-v3"><span class="nav-number">3.</span> <span class="nav-text">YOLO v3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Bounding-Box-Prediction"><span class="nav-number">3.1.</span> <span class="nav-text">Bounding Box Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Class-Prediction"><span class="nav-number">3.2.</span> <span class="nav-text">Class Prediction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Predictions-Across-Scales"><span class="nav-number">3.3.</span> <span class="nav-text">Predictions Across Scales</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Extractor"><span class="nav-number">3.4.</span> <span class="nav-text">Feature Extractor</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">听歌的小孩</span>
</div>
<div class="powered-by">
   Powerd by Kaijian Liu
  <span id="busuanzi_container_site_uv"> 
  本站访问量：<span id="busuanzi_value_site_pv"></span>人次
  </span>
</div>


<!-- <div class="powered-by">
  <span id="busuanzi_container_site_uv"> 
  本站访问量：<span id="busuanzi_value_site_pv"></span>人次
  </span>
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>
-->


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->





  

  

  

  

  

  

</body>
</html>
